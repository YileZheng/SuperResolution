{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import wandb\n",
    "\n",
    "import ColorLog as debug\n",
    "\n",
    "from load_data import labelFpsDataLoader, labelTestDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mleleleooonnn\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "/media/largeHDD/yile/.conda/envs/tradt/lib/python3.6/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.27 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">glad-energy-12</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/leleleooonnn/plateRecog_crnn\" target=\"_blank\">https://wandb.ai/leleleooonnn/plateRecog_crnn</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/leleleooonnn/plateRecog_crnn/runs/28e9du5s\" target=\"_blank\">https://wandb.ai/leleleooonnn/plateRecog_crnn/runs/28e9du5s</a><br/>\n",
       "                Run data is saved locally in <code>/media/largeHDD/yile/00-data/git/SuperResolution/wandb/run-20210427_153403-28e9du5s</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='plateRecog_crnn', entity='leleleooonnn')\n",
    "config = wandb.config\n",
    "\n",
    "# DEVICE = \"cuda\"\n",
    "provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"O\"]\n",
    "alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
    "             'X', 'Y', 'Z', 'O']\n",
    "ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
    "       'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']\n",
    "chars = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\", \"豫\", \n",
    "         \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", 'A', \n",
    "         'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', \n",
    "         'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']\n",
    "\n",
    "NUM_PROV = len(provinces)\n",
    "NUM_ALPB = len(alphabets)\n",
    "NUM_ADS = len(ads)\n",
    "NUM_CHAR = len(chars)\n",
    "\n",
    "\n",
    "PLATESIZE = (100,32)\n",
    "\n",
    "TRAINDIR = ['CCPD2019/train']\n",
    "TESTDIR = ['CCPD2019/test']\n",
    "VALDIR = ['CCPD2019/val']\n",
    "VALTXT = \"CCPD2019/splits/val.txt\"\n",
    "TRAINTXT = \"CCPD2019/splits/train.txt\"\n",
    "TESTTXT = \"CCPD2019/splits/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading \n",
    "# image size 720x1160x3 \n",
    "\n",
    "\n",
    "image_types = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "\n",
    "def persp_crop(img, corners, height, width):\n",
    "    dst_points = np.array([(width, height), (0, height), (0, 0), (width, 0)], np.float32)\n",
    "    transform_matrix = cv2.getPerspectiveTransform(corners, dst_points)\n",
    "    dst = cv2.warpPerspective(img, transform_matrix, (width, height),flags=cv2.INTER_CUBIC)\n",
    "#     dst = cv2.cvtColor(dst, cv2.COLOR_BGR2YUV)\n",
    "#     dst[:,:,0] = cv2.equalizeHist(dst[:,:,0])\n",
    "#     dst = cv2.cvtColor(dst, cv2.COLOR_YUV2BGR)\n",
    "    return dst\n",
    "\n",
    "def decode(preds):\n",
    "    char_list = []\n",
    "    code_list = []\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] != NUM_CHAR-1 and (not (i>0 and preds[i] == preds[i-1])):\n",
    "            char_list.append(chars[preds[i]])\n",
    "            code_list.append(preds[i])\n",
    "    return code_list, char_list\n",
    "    \n",
    "def label_trans(label_list):\n",
    "    assert len(label_list)==7\n",
    "    out = [0]*7\n",
    "    for ii, el in enumerate(label_list):\n",
    "        if ii==0:\n",
    "            out[ii] = int(el)\n",
    "            if out[ii] == NUM_PROV-1:\n",
    "                out[ii] = NUM_CHAR-1\n",
    "        elif ii ==1:\n",
    "            out[ii] = int(el)+NUM_PROV-1\n",
    "            if out[ii] == NUM_ALPB-1:\n",
    "                out[ii] = NUM_CHAR-1\n",
    "        else:\n",
    "            out[ii] = int(el)+NUM_PROV-1\n",
    "            if out[ii] == NUM_ADS-1:\n",
    "                out[ii] = NUM_CHAR-1\n",
    "    return out\n",
    "\n",
    "\n",
    "def list_images(basePath, contains=None):\n",
    "    # return the set of files that are valid\n",
    "    print(debug.INFO+\"Loading data under %s\"%basePath)\n",
    "    return list_files(basePath, validExts=image_types, contains=contains)\n",
    "\n",
    "\n",
    "def list_files(basePath, validExts=None, contains=None):\n",
    "    # loop over the directory structure\n",
    "    for (rootDir, dirNames, filenames) in os.walk(basePath):\n",
    "        # loop over the filenames in the current directory\n",
    "        for filename in filenames:\n",
    "            # if the contains string is not none and the filename does not contain\n",
    "            # the supplied string, then ignore the file\n",
    "            if contains is not None and filename.find(contains) == -1:\n",
    "                continue\n",
    "\n",
    "            # determine the file extension of the current file\n",
    "            ext = filename[filename.rfind(\".\"):].lower()\n",
    "\n",
    "            # check to see if the file is an image and should be processed\n",
    "            if validExts is None or ext.endswith(validExts):\n",
    "                # construct the path to the image and yield it\n",
    "                imagePath = os.path.join(rootDir, filename)\n",
    "                yield imagePath\n",
    "                \n",
    "class labelFpsDataLoader(Data.Dataset):\n",
    "    def __init__(self, img_dir, imgSize, is_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_paths = []\n",
    "        for i in range(len(img_dir)):\n",
    "            self.img_paths += [el for el in list_images(img_dir[i])]\n",
    "        # self.img_paths = os.listdir(img_dir)\n",
    "        # print self.img_paths\n",
    "        self.img_size = imgSize\n",
    "        self.is_transform = is_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.img_paths[index]\n",
    "        img = cv2.imread(img_name)\n",
    "#         plt.imshow(img[:,:,::-1])\n",
    "#         plt.show()\n",
    "        # img = img.astype('float32')\n",
    "        lbl = img_name.split('/')[-1].rsplit('.', 1)[0].split('-')[-3]\n",
    "\n",
    "        iname = img_name.rsplit('/', 1)[-1].rsplit('.', 1)[0].split('-')\n",
    "        # fps = [[int(eel) for eel in el.split('&')] for el in iname[3].split('_')]\n",
    "        # leftUp, rightDown = [min([fps[el][0] for el in range(4)]), min([fps[el][1] for el in range(4)])], [\n",
    "        #     max([fps[el][0] for el in range(4)]), max([fps[el][1] for el in range(4)])]\n",
    "        \n",
    "#         print(debug.DEBUG,iname)\n",
    "        \n",
    "        [leftUp, rightDown] = [[int(eel) for eel in el.split('&')] for el in iname[2].split('_')]\n",
    "        ori_w, ori_h = [float(int(el)) for el in [img.shape[1], img.shape[0]]]\n",
    "        new_labels = [(leftUp[0] + rightDown[0]) / (2 * ori_w), (leftUp[1] + rightDown[1]) / (2 * ori_h),\n",
    "                      (rightDown[0] - leftUp[0]) / ori_w, (rightDown[1] - leftUp[1]) / ori_h]\n",
    "        croppedImage = img[leftUp[1]:rightDown[1],leftUp[0]:rightDown[0]]\n",
    "        resizedImage = cv2.resize(croppedImage, self.img_size)\n",
    "#         cv2.imshow('plate',resizedImage)\n",
    "#         cv2.waitKey(0)\n",
    "#         print(resizedImage.shape)\n",
    "        resizedImage = np.transpose(resizedImage, (2,0,1))\n",
    "        resizedImage = resizedImage.astype('float32')\n",
    "        resizedImage /= 255.0\n",
    "#         plt.imshow(np.transpose(resizedImage, (1,2,0)))\n",
    "#         plt.show()\n",
    "        \n",
    "#         cv2.imshow('plate',np.transpose(resizedImage, (1,2,0)))\n",
    "#         cv2.waitKey(0)\n",
    "        \n",
    "        return resizedImage, new_labels, lbl, img_name, iname\n",
    "             \n",
    "class labelFpsPathDataLoader(Data.Dataset):\n",
    "    def __init__(self, pathtxt, baseDir, imgSize, is_transform=None):\n",
    "#         self.img_dir = img_dir\n",
    "#         self.img_paths = []\n",
    "#         for i in range(len(img_dir)):\n",
    "#             self.img_paths += [el for el in list_images(img_dir[i])]\n",
    "        # self.img_paths = os.listdir(img_dir)\n",
    "        # print self.img_paths\n",
    "        print(debug.INFO+\"Loading data under %s\"%pathtxt)\n",
    "        f = open(pathtxt)\n",
    "        self.img_paths = [os.path.join(baseDir, line.rstrip('\\n')) for line in f.readlines()]\n",
    "        f.close()\n",
    "#         print(\"init\")\n",
    "#         print(self.img_paths)\n",
    "        \n",
    "        self.img_size = imgSize\n",
    "        self.is_transform = is_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.img_paths[index]\n",
    "#         img = cv2.imread(img_name)\n",
    "        img = cv2.imread(img_name,cv2.IMREAD_GRAYSCALE)\n",
    "#         img_gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "        # img = img.astype('float32')\n",
    "        lbl = img_name.split('/')[-1].rsplit('.', 1)[0].split('-')[-3]\n",
    "#         old_lbl = lbl.split('_')[:7]\n",
    "#         print(\"lbl\",len(old_lbl))\n",
    "#         new_lbl = label_trans(lbl.split('_')[:7])\n",
    "#         print([chars[x] for x in new_lbl])\n",
    "        iname = img_name.rsplit('/', 1)[-1].rsplit('.', 1)[0].split('-')\n",
    "        \n",
    "#         plt.imshow(img[:,:,::-1])\n",
    "#         plt.imshow(img)\n",
    "#         plt.show()\n",
    "#         input()\n",
    "        # fps = [[int(eel) for eel in el.split('&')] for el in iname[3].split('_')]\n",
    "        # leftUp, rightDown = [min([fps[el][0] for el in range(4)]), min([fps[el][1] for el in range(4)])], [\n",
    "        #     max([fps[el][0] for el in range(4)]), max([fps[el][1] for el in range(4)])]\n",
    "        \n",
    "#         print(debug.DEBUG,iname)\n",
    "        \n",
    "        [leftUp, rightDown] = [[int(eel) for eel in el.split('&')] for el in iname[2].split('_')]\n",
    "        ori_w, ori_h = [float(int(el)) for el in [img.shape[1], img.shape[0]]]\n",
    "        new_labels = [(leftUp[0] + rightDown[0]) / (2 * ori_w), (leftUp[1] + rightDown[1]) / (2 * ori_h),\n",
    "                      (rightDown[0] - leftUp[0]) / ori_w, (rightDown[1] - leftUp[1]) / ori_h]\n",
    "#         print(img.shape)\n",
    "        croppedImage = img[leftUp[1]:rightDown[1],leftUp[0]:rightDown[0]]\n",
    "#         print(croppedImage.shape)\n",
    "        resizedImage = cv2.resize(croppedImage, self.img_size)\n",
    "        resizedImage = np.expand_dims(resizedImage,0)\n",
    "#         cv2.imshow('plate',resizedImage)\n",
    "#         cv2.waitKey(0)\n",
    "#         print(resizedImage.shape)\n",
    "#         resizedImage = np.transpose(resizedImage, (2,0,1))\n",
    "        resizedImage = resizedImage.astype('float32')\n",
    "        resizedImage /= 255.0\n",
    "#         plt.imshow(np.transpose(resizedImage, (1,2,0)))\n",
    "#         plt.show()\n",
    "        \n",
    "#         cv2.imshow('plate',np.transpose(resizedImage, (1,2,0)))\n",
    "#         cv2.waitKey(0)\n",
    "        \n",
    "        return resizedImage, new_labels, lbl, img_name, iname\n",
    "      \n",
    "class labelLoader(Data.Dataset):\n",
    "    def __init__(self, img_dir, imgSize, is_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_paths = []\n",
    "        for i in range(len(img_dir)):\n",
    "            self.img_paths += [el for el in list_images(img_dir[i])]\n",
    "        # self.img_paths = os.listdir(img_dir)\n",
    "        # print self.img_paths\n",
    "        self.img_size = imgSize\n",
    "        self.is_transform = is_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.img_paths[index]\n",
    "#         img = cv2.imread(img_name)\n",
    "#         # img = img.astype('float32')\n",
    "#         resizedImage = cv2.resize(img, self.img_size)\n",
    "#         resizedImage = np.transpose(resizedImage, (2,0,1))\n",
    "#         resizedImage = resizedImage.astype('float32')\n",
    "#         resizedImage /= 255.0\n",
    "        lbl = img_name.split('/')[-1].rsplit('.', 1)[0].split('-')[-3]\n",
    "\n",
    "        iname = img_name.rsplit('/', 1)[-1].rsplit('.', 1)[0].split('-')\n",
    "        # fps = [[int(eel) for eel in el.split('&')] for el in iname[3].split('_')]\n",
    "        # leftUp, rightDown = [min([fps[el][0] for el in range(4)]), min([fps[el][1] for el in range(4)])], [\n",
    "        #     max([fps[el][0] for el in range(4)]), max([fps[el][1] for el in range(4)])]\n",
    "        \n",
    "#         print(debug.DEBUG,iname)\n",
    "        \n",
    "        [leftUp, rightDown] = [[int(eel) for eel in el.split('&')] for el in iname[2].split('_')]\n",
    "#         ori_w, ori_h = [float(int(el)) for el in [img.shape[1], img.shape[0]]]\n",
    "#         new_labels = [(leftUp[0] + rightDown[0]) / (2 * ori_w), (leftUp[1] + rightDown[1]) / (2 * ori_h),\n",
    "#                       (rightDown[0] - leftUp[0]) / ori_w, (rightDown[1] - leftUp[1]) / ori_h]\n",
    "\n",
    "        return lbl, img_name, iname\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- Start loading dataset...\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n",
      "init\n",
      "[\u001b[37;1mINFO\u001b[0m] -- finish loading\n",
      "99996\n",
      "(1160, 720)\n",
      "(79, 252)\n",
      "(1, 64, 192)\n",
      "(1160, 720)\n",
      "(67, 288)\n",
      "(1, 64, 192)\n",
      "i\n",
      "(1, 64, 192)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 192)\n"
     ]
    }
   ],
   "source": [
    "path = \"CCPD2019/ccpd_base\"\n",
    "imgsize = (480,480)\n",
    "platesize = (256,96)\n",
    "# print(debug.INFO+\"start loading data...\")\n",
    "# dst = labelFpsDataLoader([path],platesize)\n",
    "\n",
    "print(debug.INFO+\"Start loading dataset...\")\n",
    "# dst = labelFpsDataLoader(TRAINDIR, (256,96))\n",
    "\n",
    "dst = labelFpsPathDataLoader(\"CCPD2019/splits/val.txt\",\"CCPD2019\", (192,64))\n",
    "# print(debug.INFO+\"Got dataset size %d\"%len(dst))\n",
    "# trainloader = Data.DataLoader(dst, batch_size=BATCHSIZE, shuffle=True, num_workers=8)\n",
    "\n",
    "# dst = labelLoader([path],imgsize)\n",
    "print(debug.INFO+\"finish loading\")\n",
    "print(len(dst))\n",
    "# sizes = []\n",
    "# for _,_,iname in dst:\n",
    "#     [leftUp, rightDown] = [[int(eel) for eel in el.split('&')] \n",
    "#                        for el in iname[2].split('_')]\n",
    "#     sizes.append([leftUp[0]-rightDown[0],leftUp[1]-rightDown[1]])\n",
    "\n",
    "# mean, std = np.mean(sizes, axis=0),np.std(sizes, axis=0)\n",
    "# print(mean,std)\n",
    "#     [-252.62252245  -94.97832957] [61.46956803 27.42365916]\n",
    "img,_,_,_,iname = dst[random.randint(0,100)]\n",
    "\n",
    "\n",
    "for img,_,_,_,iname in dst:\n",
    "    print(\"i\")\n",
    "    print(img.shape)\n",
    "#     img =np.transpose(img*255, (1,2,0)).astype(\"int\")\n",
    "#     img = img[:,:,::-1]\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()\n",
    "#     print(img)\n",
    "    print(img.shape)\n",
    "#     cv2.imshow('plate',img)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitRecog(nn.Module): \n",
    "    def __init__(self, imgSize):\n",
    "\n",
    "        super(DigitRecog, self).__init__()\n",
    "        self.name = \"DigitRecog\"\n",
    "        \n",
    "        self.stack1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.stack2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.stack3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.stack4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.stack5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.activations = nn.Sequential(\n",
    "            self.stack1,\n",
    "            self.stack2,\n",
    "            self.stack3,\n",
    "            self.stack4,\n",
    "            self.stack5\n",
    "        )\n",
    "        self.Length = int((imgSize[0]/(2**5))*(imgSize[1]/(2**5)))*512\n",
    "        interft = 4096\n",
    "        self.classifier1 = nn.Sequential(\n",
    "            nn.Linear(self.Length, interft),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(interft, interft),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(interft, NUM_PROV)\n",
    "        )\n",
    "        self.classifier2 = nn.Sequential(\n",
    "            nn.Linear(self.Length, interft),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(interft, interft),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(interft, NUM_ALPB)\n",
    "        )\n",
    "        \n",
    "        self.classifier3 = nn.Sequential(\n",
    "            nn.Linear(self.Length, interft),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(interft, interft),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(interft, NUM_ADS)\n",
    "        )\n",
    "        self.classifier4 = nn.Sequential(\n",
    "            nn.Linear(self.Length, interft),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(interft, interft),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(interft, NUM_ADS)\n",
    "        )\n",
    "        self.classifier5 = nn.Sequential(\n",
    "            nn.Linear(self.Length, interft),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(interft, interft),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(interft, NUM_ADS)\n",
    "        )\n",
    "        self.classifier6 = nn.Sequential(\n",
    "            nn.Linear(self.Length, interft),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(interft, interft),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(interft, NUM_ADS)\n",
    "        )\n",
    "        self.classifier7 = nn.Sequential(\n",
    "            nn.Linear(self.Length, interft),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(interft, interft),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(interft, NUM_ADS)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "#         x = self.activations(x)\n",
    "#         print(x.shape)\n",
    "        x = self.stack1(x)\n",
    "#         print(x.shape)\n",
    "        x = self.stack2(x)\n",
    "#         print(x.shape)\n",
    "        x = self.stack3(x)\n",
    "#         print(x.shape)\n",
    "        x = self.stack4(x)\n",
    "#         print(x.shape)\n",
    "        x = self.stack5(x)\n",
    "#         print(x.shape)\n",
    "        \n",
    "        x = x.view(x.size(0),-1)\n",
    "#         print(self.Length, x.shape)\n",
    "        prov = self.classifier1(x)\n",
    "        alpb = self.classifier2(x)\n",
    "        ads1 = self.classifier3(x)\n",
    "        ads2 = self.classifier4(x)\n",
    "        ads3 = self.classifier5(x)\n",
    "        ads4 = self.classifier6(x)\n",
    "        ads5 = self.classifier7(x)\n",
    "        return prov,alpb,ads1,ads2,ads3,ads4,ads5   \n",
    "\n",
    "    \n",
    "# class DigitRecog(nn.Module): \n",
    "#     def __init__(self, imgSize):\n",
    "\n",
    "#         super(DigitRecog, self).__init__()\n",
    "#         self.name = \"DigitRecog\"\n",
    "        \n",
    "#         self.stack1 = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(num_features=64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(num_features=64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "#             nn.Dropout(0.2)\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, nIn, nHidden, nOut):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n",
    "        self.embedding = nn.Linear(nHidden * 2, nOut)\n",
    "\n",
    "    def forward(self, input):\n",
    "        recurrent, _ = self.rnn(input)\n",
    "        T, b, h = recurrent.size()\n",
    "        t_rec = recurrent.view(T * b, h)\n",
    "\n",
    "        output = self.embedding(t_rec)  # [T * b, nOut]\n",
    "        output = output.view(T, b, -1)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, imgH, nc, nclass, nh, n_rnn=2, leakyRelu=False):\n",
    "        super(CRNN, self).__init__()\n",
    "        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n",
    "\n",
    "        ks = [3, 3, 3, 3, 3, 3, 2]\n",
    "        ps = [1, 1, 1, 1, 1, 1, 0]\n",
    "        ss = [1, 1, 1, 1, 1, 1, 1]\n",
    "        nm = [64, 128, 256, 256, 512, 512, 512]\n",
    "\n",
    "        cnn = nn.Sequential()\n",
    "\n",
    "        def convRelu(i, batchNormalization=False):\n",
    "            nIn = nc if i == 0 else nm[i - 1]\n",
    "            nOut = nm[i]\n",
    "            cnn.add_module('conv{0}'.format(i),\n",
    "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
    "            if batchNormalization:\n",
    "                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n",
    "            if leakyRelu:\n",
    "                cnn.add_module('relu{0}'.format(i),\n",
    "                               nn.LeakyReLU(0.2, inplace=True))\n",
    "            else:\n",
    "                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n",
    "\n",
    "        convRelu(0)\n",
    "        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d(2, 2))  # 64x16x64\n",
    "        convRelu(1)\n",
    "        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d(2, 2))  # 128x8x32\n",
    "        convRelu(2, True)\n",
    "        convRelu(3)\n",
    "        cnn.add_module('pooling{0}'.format(2),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 256x4x16\n",
    "        convRelu(4, True)\n",
    "        convRelu(5)\n",
    "        cnn.add_module('pooling{0}'.format(3),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 512x2x16\n",
    "        convRelu(6, True)  # 512x1x16\n",
    "\n",
    "        self.cnn = cnn\n",
    "        self.rnn = nn.Sequential(\n",
    "            BidirectionalLSTM(512, nh, nh),\n",
    "            BidirectionalLSTM(nh, nh, nclass))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # conv features\n",
    "        conv = self.cnn(input)\n",
    "        b, c, h, w = conv.size()\n",
    "        assert h == 1, \"the height of conv must be 1\"\n",
    "        conv = conv.squeeze(2)\n",
    "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
    "\n",
    "        # rnn features\n",
    "        output = self.rnn(conv)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval(model, test_tar):\n",
    "    use_gpu = True\n",
    "    count, error, correct = 0, 0, 0\n",
    "    dst = labelFpsPathDataLoader(test_tar,\"CCPD2019\", PLATESIZE)\n",
    "#     dst = labelFpsDataLoader(test_tar, PLATESIZE)\n",
    "    bsz = 16\n",
    "    testloader = Data.DataLoader(dst, batch_size=bsz, shuffle=True, num_workers=8)\n",
    "    start = time()\n",
    "#     corrs_eachchar = np.zeros((7))\n",
    "    corrs_eachinst =[]\n",
    "    for i, (XI,_, labels, ims, _) in enumerate(testloader):\n",
    "        \n",
    "        corr_eachinst =[]\n",
    "#         assert len(labels) == bsz\n",
    "        count += len(labels)\n",
    "#         YI = [[int(ee) for ee in el.split('_')[:7]] for el in labels]\n",
    "#         labelGT = np.array([[int(ee) for ee in el.split('_')[:7]] for el in labels])\n",
    "        YI = np.array([label_trans(el.split('_')[:7]) for el in labels])\n",
    "        if use_gpu:\n",
    "            x = Variable(XI.cuda(0))\n",
    "            lbl = Variable(torch.LongTensor(YI).cuda())\n",
    "        else:\n",
    "            x = Variable(XI)\n",
    "            lbl = Variable(torch.LongTensor(YI))\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "\n",
    "        y_pred = model(x)\n",
    "#         print(y_pred.shape)\n",
    "#         input()\n",
    "#         outputY = [el.data.cpu().numpy().tolist() for el in y_pred]\n",
    "#         labelPred = [t[0].index(max(t[0])) for each in btch for btch in outputY]\n",
    "        \n",
    "        _, preds = y_pred.max(2)\n",
    "        preds = preds.transpose(1, 0).contiguous()\n",
    "        for i in range(lbl.shape[0]):\n",
    "            n_correct = 0\n",
    "            sim_preds, _ = decode(preds[i].data)\n",
    "#             print(sim_preds,lbl[i].data)\n",
    "            for pred, target in zip(sim_preds, lbl[i].data):\n",
    "                if pred == target:\n",
    "                    n_correct += 1\n",
    "            corr_eachinst.append(n_correct)\n",
    "            \n",
    "\n",
    "#         labelPred = np.array([np.argmax(branch, axis=1) for branch in outputY])\n",
    "#         print(labelPred)\n",
    "#         scoreboard = (labelPred.T == labelGT)\n",
    "#         corr_eachinst = np.sum(scoreboard, axis=1)\n",
    "#         corr_eachchar = np.sum(scoreboard, axis=0)\n",
    "#         print(corr_eachinst,len(corr_eachinst))\n",
    "#         assert len(corr_eachinst) == bsz\n",
    "#         assert len(corr_eachchar) == 7\n",
    "        corrs_eachinst = np.append(corrs_eachinst,corr_eachinst)\n",
    "#         corrs_eachchar = corrs_eachchar+corr_eachchar\n",
    "        \n",
    "#         tmp = corr_eachchar/len(labels)\n",
    "#         table = wandb.Table(data=list(corr_eachchar/len(labels)),columns=['1','2','3','4','5','6','7'])\n",
    "        \n",
    "        \n",
    "        if i%10 ==1:\n",
    "            print(debug.INFO+\"image: {}, inst:{}\".format(count,np.mean(corrs_eachinst)))#, corrs_eachchar/count))\n",
    "#         def isEqual(labelGT, labelP):\n",
    "#             compare = [1 if int(labelGT[i]) == int(labelP[i]) else 0 for i in range(7)]\n",
    "#             # print(sum(compare))\n",
    "#             return sum(compare)\n",
    "\n",
    "#         #   compare YI, outputY\n",
    "#         try:\n",
    "#             if isEqual(labelPred, YI[0]) == 7:\n",
    "#                 correct += 1\n",
    "#             else:\n",
    "#                 pass\n",
    "#         except:\n",
    "#             print(debug.WARN+\"val fails\")\n",
    "#             error += 1\n",
    "# correct, error, float(correct) / count,\n",
    "    wandb.log({'val':{\n",
    "        'image#':count,\n",
    "        'corr_in_instance':np.mean(corrs_eachinst),\n",
    "        'accu_instance':np.mean(corrs_eachinst)/7,\n",
    "        'accu_all_corr':len(corrs_eachinst[corrs_eachinst==7]),\n",
    "        'corr_distrb':wandb.Histogram(corrs_eachinst),\n",
    "        'corr_inst':corrs_eachinst\n",
    "              }})  \n",
    "    \n",
    "    return count, corrs_eachinst, np.mean(corrs_eachinst)/7, (time()-start) / count\n",
    "\n",
    "\n",
    "def train_model(model, trainloader, criterion, optimizer,batchSize, testDirs,storeName, num_epochs=25, logFile=\"./train_log.txt\"):\n",
    "    # since = time.time()\n",
    "    use_gpu = True\n",
    "    lrScheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1, verbose=True)\n",
    "    cnt = 0\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        lossAver = []\n",
    "        model.train(True)\n",
    "        lrScheduler.step()\n",
    "        start = time()\n",
    "        print(debug.INFO+\"Epoch {} started at {}\".format(epoch,start))\n",
    "\n",
    "        for i, (XI, _, labels, _, _) in enumerate(trainloader):\n",
    "            cnt +=1\n",
    "            if not len(XI) == batchSize:\n",
    "                \n",
    "                continue\n",
    "                        \n",
    "            YI = [label_trans(el.split('_')[:7]) for el in labels]\n",
    "#             Y = np.array([el.numpy() for el in Y]).T\n",
    "            if use_gpu:\n",
    "                x = Variable(XI.cuda())\n",
    "                lbl = Variable(torch.LongTensor(YI).cuda())\n",
    "#                 y = Variable(torch.FloatTensor(Y).cuda(), requires_grad=False)\n",
    "            else:\n",
    "                x = Variable(XI)\n",
    "                lbl = Variable(torch.LongTensor(YI))\n",
    "    \n",
    "#             print(debug.INFO+\"input shape {}\".format(x.shape))\n",
    "            y_pred = model(x)\n",
    "#             print(debug.INFO+\"output size:\",y_pred.shape)\n",
    "#             print(debug.INFO+\"output shape {}\".format([yy.shape for yy in y_pred]))\n",
    "#             try:\n",
    "#                 y_pred = model(x)\n",
    "#                 print(debug.INFO+\"output shape {}\".format(y_pred.shape))\n",
    "                \n",
    "#             except:\n",
    "#                 print(debug.WARN+\"iter %d model prediction fails\"%i)\n",
    "#                 continue\n",
    "                \n",
    "            # Compute and print loss\n",
    "#             loss = 0.0\n",
    "#             train_correct = []\n",
    "#             loss += 0.8 * nn.L1Loss().cuda()(fps_pred[:][:2], y[:][:2])\n",
    "#             loss += 0.2 * nn.L1Loss().cuda()(fps_pred[:][2:], y[:][2:])\n",
    "            y_pred = F.log_softmax(y_pred,dim=2)\n",
    "            preds_size = Variable(torch.IntTensor([y_pred.size(0)] * batchSize))\n",
    "            tars_size = Variable(torch.IntTensor([7] * batchSize))\n",
    "#             print(\"loss input\",y_pred,lbl,preds_size,tars_size)\n",
    "            loss  = criterion(y_pred,lbl,preds_size,tars_size)\n",
    "#             for j in range(7):\n",
    "#                 l = lbl[:,j]\n",
    "#                 loss += criterion(y_pred[j], l)\n",
    "#                 train_correct.append(np.argmax(y_pred[j],axis=1))\n",
    "#                 acc = len(train_correct[train_correct==0])/len(train_correct)\n",
    "\n",
    "#             def isEqual(labelGT, labelP):\n",
    "#                 compare = [1 if int(labelGT[i]) == int(labelP[i]) else 0 for i in range(7)]\n",
    "#                 # print(sum(compare))\n",
    "#                 return sum(compare)\n",
    "            \n",
    "#             for ii in range(batchSize):\n",
    "#                 if isEqual(labelPred, YI[ii]) == 7:\n",
    "#                     correct += 1\n",
    "\n",
    "\n",
    "                    \n",
    "            # Zero gradients, perform a backward pass, and update the weights.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             print(loss)\n",
    "            lossAver.append(loss.item())\n",
    "\n",
    "#             try:\n",
    "#                 print(loss)\n",
    "#                 lossAver.append(loss.data[0])\n",
    "#             except:\n",
    "#                 print(debug.ERR+\"iter %d lossAver append error\"%i)\n",
    "            if cnt % 100 == 0:\n",
    "                wandb.log({'train':{\n",
    "                    'cur_loss':loss,\n",
    "                    'ave_loss':np.mean(lossAver)\n",
    "                          }})  \n",
    "            \n",
    "            if i % 50 == 1:\n",
    "                print('trained %s images, use %s seconds, loss %s\\n' % (i*batchSize, time() - start, sum(lossAver) / len(lossAver) if len(lossAver)>0 else 'NoLoss'))\n",
    "                with open(logFile, 'a') as outF:\n",
    "                    outF.write('trained %s images, use %s seconds, loss %s\\n' % (i*batchSize, time() - start, sum(lossAver) / len(lossAver) if len(lossAver)>0 else 'NoLoss'))\n",
    "                torch.save(model.state_dict(), storeName)\n",
    "        print ('*************Epoch %s Avrg Training loss %s Elapsed %s\\n' % (epoch, sum(lossAver) / len(lossAver), time()-start))\n",
    "        \n",
    "        model.eval()\n",
    "        count, correct, precision, avgTime = eval(model, testDirs)\n",
    "        with open(logFile, 'a') as outF:\n",
    "            outF.write('Epoch %s Avrg Training loss %s Elapsed %s\\n' % (epoch, sum(lossAver) / len(lossAver), time() - start))\n",
    "            outF.write('************* Validation: total %s precision %s avgTime %s\\n' % (count, precision, avgTime))\n",
    "        torch.save(model.state_dict(), storeName + str(epoch))\n",
    "        print('************* Validation: total %s precision %s avgTime %s\\n' % (count, precision, avgTime))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- Start loading dataset...\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/train.txt\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Got dataset size 100000\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Done loading dataset\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Start training\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 0 started at 1619458112.2549222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/largeHDD/yile/.conda/envs/tradt/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 16 images, use 2.1929969787597656 seconds, loss 12.21277904510498\n",
      "\n",
      "trained 816 images, use 7.8445422649383545 seconds, loss 3.7211217146653395\n",
      "\n",
      "trained 1616 images, use 13.907752752304077 seconds, loss 3.2029084013957605\n",
      "\n",
      "trained 2416 images, use 18.95317530632019 seconds, loss 2.983241740025972\n",
      "\n",
      "trained 3216 images, use 24.33391046524048 seconds, loss 2.875131326146645\n",
      "\n",
      "trained 4016 images, use 28.79421877861023 seconds, loss 2.8042495004714483\n",
      "\n",
      "trained 4816 images, use 33.81403207778931 seconds, loss 2.75149752762144\n",
      "\n",
      "trained 5616 images, use 38.37854886054993 seconds, loss 2.7146155217831787\n",
      "\n",
      "trained 6416 images, use 42.83934426307678 seconds, loss 2.684877956091468\n",
      "\n",
      "trained 7216 images, use 47.912712812423706 seconds, loss 2.6620673711320997\n",
      "\n",
      "trained 8016 images, use 52.5118887424469 seconds, loss 2.644578522894962\n",
      "\n",
      "trained 8816 images, use 57.33748412132263 seconds, loss 2.625894702863002\n",
      "\n",
      "trained 9616 images, use 62.09454035758972 seconds, loss 2.6084792899134945\n",
      "\n",
      "trained 10416 images, use 67.12164878845215 seconds, loss 2.586285625498719\n",
      "\n",
      "trained 11216 images, use 72.12520384788513 seconds, loss 2.5673706035668356\n",
      "\n",
      "trained 12016 images, use 76.6097457408905 seconds, loss 2.5452302703832057\n",
      "\n",
      "trained 12816 images, use 81.92739868164062 seconds, loss 2.5177006161123736\n",
      "\n",
      "trained 13616 images, use 86.8838198184967 seconds, loss 2.488742239178626\n",
      "\n",
      "trained 14416 images, use 92.02967810630798 seconds, loss 2.453632607163981\n",
      "\n",
      "trained 15216 images, use 97.00879955291748 seconds, loss 2.4151537548594115\n",
      "\n",
      "trained 16016 images, use 101.90310573577881 seconds, loss 2.3779903389736563\n",
      "\n",
      "trained 16816 images, use 106.58270907402039 seconds, loss 2.3354412253818584\n",
      "\n",
      "trained 17616 images, use 111.23760676383972 seconds, loss 2.2922938252966545\n",
      "\n",
      "trained 18416 images, use 116.03357481956482 seconds, loss 2.2493067698346243\n",
      "\n",
      "trained 19216 images, use 121.34135866165161 seconds, loss 2.205203620695235\n",
      "\n",
      "trained 20016 images, use 126.09498834609985 seconds, loss 2.162672440893353\n",
      "\n",
      "trained 20816 images, use 130.4591360092163 seconds, loss 2.1195498520877503\n",
      "\n",
      "trained 21616 images, use 135.17053604125977 seconds, loss 2.0755082551808752\n",
      "\n",
      "trained 22416 images, use 139.76198506355286 seconds, loss 2.0316488022215866\n",
      "\n",
      "trained 23216 images, use 144.38315200805664 seconds, loss 1.9892687733508339\n",
      "\n",
      "trained 24016 images, use 149.36123991012573 seconds, loss 1.9470351936813994\n",
      "\n",
      "trained 24816 images, use 154.05664348602295 seconds, loss 1.9047123715089462\n",
      "\n",
      "trained 25616 images, use 158.33884501457214 seconds, loss 1.8639128597525323\n",
      "\n",
      "trained 26416 images, use 163.2357256412506 seconds, loss 1.8240974962567014\n",
      "\n",
      "trained 27216 images, use 167.88894605636597 seconds, loss 1.7845599311464122\n",
      "\n",
      "trained 28016 images, use 172.56246280670166 seconds, loss 1.7456703231282975\n",
      "\n",
      "trained 28816 images, use 177.5498628616333 seconds, loss 1.7085367172840698\n",
      "\n",
      "trained 29616 images, use 181.79067492485046 seconds, loss 1.6737505140479003\n",
      "\n",
      "trained 30416 images, use 187.09617519378662 seconds, loss 1.6405235532941502\n",
      "\n",
      "trained 31216 images, use 191.5966637134552 seconds, loss 1.6073115781545029\n",
      "\n",
      "trained 32016 images, use 196.49436950683594 seconds, loss 1.5758813553593018\n",
      "\n",
      "trained 32816 images, use 201.10314846038818 seconds, loss 1.5454041448151274\n",
      "\n",
      "trained 33616 images, use 205.4710819721222 seconds, loss 1.5165404109984324\n",
      "\n",
      "trained 34416 images, use 210.03207111358643 seconds, loss 1.4874890159510878\n",
      "\n",
      "trained 35216 images, use 214.5241584777832 seconds, loss 1.4597055468095854\n",
      "\n",
      "trained 36016 images, use 219.06256413459778 seconds, loss 1.4319128892955173\n",
      "\n",
      "trained 36816 images, use 223.50360083580017 seconds, loss 1.4062358746555943\n",
      "\n",
      "trained 37616 images, use 227.74641346931458 seconds, loss 1.3810969794907157\n",
      "\n",
      "trained 38416 images, use 232.17749309539795 seconds, loss 1.3569080551386772\n",
      "\n",
      "trained 39216 images, use 236.72591614723206 seconds, loss 1.3330034766434335\n",
      "\n",
      "trained 40016 images, use 241.2446210384369 seconds, loss 1.3095661466643453\n",
      "\n",
      "trained 40816 images, use 246.5801842212677 seconds, loss 1.2873378880723412\n",
      "\n",
      "trained 41616 images, use 250.39004468917847 seconds, loss 1.265627317623787\n",
      "\n",
      "trained 42416 images, use 254.9934582710266 seconds, loss 1.2450752555551414\n",
      "\n",
      "trained 43216 images, use 259.9952371120453 seconds, loss 1.2246829111881825\n",
      "\n",
      "trained 44016 images, use 264.56558752059937 seconds, loss 1.2045806702808477\n",
      "\n",
      "trained 44816 images, use 269.4293327331543 seconds, loss 1.1855215437824622\n",
      "\n",
      "trained 45616 images, use 274.12060737609863 seconds, loss 1.1666785837640936\n",
      "\n",
      "trained 46416 images, use 279.5050151348114 seconds, loss 1.1485738975344435\n",
      "\n",
      "trained 47216 images, use 284.23477053642273 seconds, loss 1.1308704695290808\n",
      "\n",
      "trained 48016 images, use 288.7062864303589 seconds, loss 1.113748198059908\n",
      "\n",
      "trained 48816 images, use 293.64518904685974 seconds, loss 1.0972254131160808\n",
      "\n",
      "trained 49616 images, use 298.9558458328247 seconds, loss 1.0810892763955917\n",
      "\n",
      "trained 50416 images, use 303.4834771156311 seconds, loss 1.0654653641980303\n",
      "\n",
      "trained 51216 images, use 308.08807373046875 seconds, loss 1.0499562335722403\n",
      "\n",
      "trained 52016 images, use 312.6538197994232 seconds, loss 1.0350724538295044\n",
      "\n",
      "trained 52816 images, use 317.12733602523804 seconds, loss 1.0206336274512928\n",
      "\n",
      "trained 53616 images, use 321.7789680957794 seconds, loss 1.0066119775324416\n",
      "\n",
      "trained 54416 images, use 326.1331741809845 seconds, loss 0.9930576523022671\n",
      "\n",
      "trained 55216 images, use 330.29707860946655 seconds, loss 0.9799923947827485\n",
      "\n",
      "trained 56016 images, use 335.104825258255 seconds, loss 0.9670247680496696\n",
      "\n",
      "trained 56816 images, use 339.8755078315735 seconds, loss 0.954364675151049\n",
      "\n",
      "trained 57616 images, use 344.19035506248474 seconds, loss 0.9421094225293339\n",
      "\n",
      "trained 58416 images, use 348.36467838287354 seconds, loss 0.9302341435050417\n",
      "\n",
      "trained 59216 images, use 353.01640796661377 seconds, loss 0.9188439573386085\n",
      "\n",
      "trained 60016 images, use 357.3752853870392 seconds, loss 0.9073963915859821\n",
      "\n",
      "trained 60816 images, use 362.34207940101624 seconds, loss 0.8963297342998282\n",
      "\n",
      "trained 61616 images, use 366.59303641319275 seconds, loss 0.8854861155494798\n",
      "\n",
      "trained 62416 images, use 370.75211238861084 seconds, loss 0.8746348187481452\n",
      "\n",
      "trained 63216 images, use 375.2048954963684 seconds, loss 0.864292848550256\n",
      "\n",
      "trained 64016 images, use 379.78351283073425 seconds, loss 0.8538365560834636\n",
      "\n",
      "trained 64816 images, use 384.275678396225 seconds, loss 0.8440092112372564\n",
      "\n",
      "trained 65616 images, use 388.16184639930725 seconds, loss 0.8345155356676526\n",
      "\n",
      "trained 66416 images, use 392.5943067073822 seconds, loss 0.8250490541526485\n",
      "\n",
      "trained 67216 images, use 397.1196537017822 seconds, loss 0.8158325787342979\n",
      "\n",
      "trained 68016 images, use 401.3974668979645 seconds, loss 0.8068504546732713\n",
      "\n",
      "trained 68816 images, use 405.62293696403503 seconds, loss 0.7978469001703282\n",
      "\n",
      "trained 69616 images, use 409.9268527030945 seconds, loss 0.7892903850717952\n",
      "\n",
      "trained 70416 images, use 414.4189920425415 seconds, loss 0.7810398661915504\n",
      "\n",
      "trained 71216 images, use 418.4233536720276 seconds, loss 0.7727063499498394\n",
      "\n",
      "trained 72016 images, use 422.8130393028259 seconds, loss 0.7644745902593157\n",
      "\n",
      "trained 72816 images, use 427.50367617607117 seconds, loss 0.7563637715831042\n",
      "\n",
      "trained 73616 images, use 431.838636636734 seconds, loss 0.7487216121742262\n",
      "\n",
      "trained 74416 images, use 436.3989112377167 seconds, loss 0.7412442677347122\n",
      "\n",
      "trained 75216 images, use 440.45599818229675 seconds, loss 0.7337267691108982\n",
      "\n",
      "trained 76016 images, use 445.2869510650635 seconds, loss 0.7264641315123299\n",
      "\n",
      "trained 76816 images, use 449.497816324234 seconds, loss 0.719199189148426\n",
      "\n",
      "trained 77616 images, use 455.1526880264282 seconds, loss 0.7122575081539358\n",
      "\n",
      "trained 78416 images, use 459.09041810035706 seconds, loss 0.7054630277012651\n",
      "\n",
      "trained 79216 images, use 463.3870310783386 seconds, loss 0.6986486510336414\n",
      "\n",
      "trained 80016 images, use 468.06689286231995 seconds, loss 0.6919170346452532\n",
      "\n",
      "trained 80816 images, use 472.9751019477844 seconds, loss 0.6855476233851598\n",
      "\n",
      "trained 81616 images, use 477.4023199081421 seconds, loss 0.6792207112798145\n",
      "\n",
      "trained 82416 images, use 481.97135376930237 seconds, loss 0.6731424489894973\n",
      "\n",
      "trained 83216 images, use 486.27161955833435 seconds, loss 0.6671355689582349\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 84016 images, use 490.908686876297 seconds, loss 0.6609762347515592\n",
      "\n",
      "trained 84816 images, use 495.46973609924316 seconds, loss 0.6549752895000645\n",
      "\n",
      "trained 85616 images, use 499.7852499485016 seconds, loss 0.6492358161752866\n",
      "\n",
      "trained 86416 images, use 505.0869801044464 seconds, loss 0.6433656252393936\n",
      "\n",
      "trained 87216 images, use 509.65105676651 seconds, loss 0.6377209586229535\n",
      "\n",
      "trained 88016 images, use 515.0532627105713 seconds, loss 0.6323557689658835\n",
      "\n",
      "trained 88816 images, use 519.5434823036194 seconds, loss 0.6268271957213791\n",
      "\n",
      "trained 89616 images, use 524.5155968666077 seconds, loss 0.6213584189310783\n",
      "\n",
      "trained 90416 images, use 529.0786483287811 seconds, loss 0.6160475593034509\n",
      "\n",
      "trained 91216 images, use 534.3454384803772 seconds, loss 0.6109456057499685\n",
      "\n",
      "trained 92016 images, use 539.0115280151367 seconds, loss 0.6057386638922544\n",
      "\n",
      "trained 92816 images, use 543.7485902309418 seconds, loss 0.6005762374658073\n",
      "\n",
      "trained 93616 images, use 548.4094924926758 seconds, loss 0.5956666533458176\n",
      "\n",
      "trained 94416 images, use 552.9975438117981 seconds, loss 0.5908998733683491\n",
      "\n",
      "trained 95216 images, use 557.6961324214935 seconds, loss 0.5863325302356688\n",
      "\n",
      "trained 96016 images, use 562.2964158058167 seconds, loss 0.5816440115321354\n",
      "\n",
      "trained 96816 images, use 567.0117666721344 seconds, loss 0.5770066967585069\n",
      "\n",
      "trained 97616 images, use 571.8841545581818 seconds, loss 0.5724908852353277\n",
      "\n",
      "trained 98416 images, use 576.2859916687012 seconds, loss 0.5680422689083701\n",
      "\n",
      "trained 99216 images, use 580.6565911769867 seconds, loss 0.5637274984389264\n",
      "\n",
      "*************Epoch 0 Avrg Training loss 0.5595090071823448 Elapsed 584.7367024421692\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.704178167126685\n",
      "************* Validation: total 99996 precision 0.9577397381609549 avgTime 0.006347344245351387\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 1 started at 1619459332.0251627\n",
      "trained 16 images, use 1.073909044265747 seconds, loss -0.0019346005283296108\n",
      "\n",
      "trained 816 images, use 5.477415084838867 seconds, loss 0.000399648514128505\n",
      "\n",
      "trained 1616 images, use 9.984659194946289 seconds, loss 0.01678889948651012\n",
      "\n",
      "trained 2416 images, use 13.98099660873413 seconds, loss 0.013508893392434785\n",
      "\n",
      "trained 3216 images, use 18.482407569885254 seconds, loss 0.016115454363862587\n",
      "\n",
      "trained 4016 images, use 22.99678921699524 seconds, loss 0.018936905673139597\n",
      "\n",
      "trained 4816 images, use 27.63501811027527 seconds, loss 0.019126069002294455\n",
      "\n",
      "trained 5616 images, use 31.74067497253418 seconds, loss 0.019420424384654987\n",
      "\n",
      "trained 6416 images, use 36.22854399681091 seconds, loss 0.019977382193979765\n",
      "\n",
      "trained 7216 images, use 41.15202355384827 seconds, loss 0.019554878363284834\n",
      "\n",
      "trained 8016 images, use 45.27224278450012 seconds, loss 0.019448040120268382\n",
      "\n",
      "trained 8816 images, use 49.41449785232544 seconds, loss 0.01926557813029554\n",
      "\n",
      "trained 9616 images, use 53.961864948272705 seconds, loss 0.02008988341278678\n",
      "\n",
      "trained 10416 images, use 58.43913412094116 seconds, loss 0.019554205289706188\n",
      "\n",
      "trained 11216 images, use 62.81272888183594 seconds, loss 0.019919582872294644\n",
      "\n",
      "trained 12016 images, use 67.73300385475159 seconds, loss 0.019762256339550307\n",
      "\n",
      "trained 12816 images, use 71.73224663734436 seconds, loss 0.018575882740194522\n",
      "\n",
      "trained 13616 images, use 76.75607967376709 seconds, loss 0.017964571484439994\n",
      "\n",
      "trained 14416 images, use 81.10537648200989 seconds, loss 0.01766205405077676\n",
      "\n",
      "trained 15216 images, use 85.76386380195618 seconds, loss 0.01651689833425819\n",
      "\n",
      "trained 16016 images, use 90.08874177932739 seconds, loss 0.016758392066178945\n",
      "\n",
      "trained 16816 images, use 95.04665470123291 seconds, loss 0.01687894207671083\n",
      "\n",
      "trained 17616 images, use 99.51886367797852 seconds, loss 0.016733201018119648\n",
      "\n",
      "trained 18416 images, use 104.20588564872742 seconds, loss 0.016794230337937834\n",
      "\n",
      "trained 19216 images, use 108.18138766288757 seconds, loss 0.01626529044732405\n",
      "\n",
      "trained 20016 images, use 112.5859751701355 seconds, loss 0.01658733589706731\n",
      "\n",
      "trained 20816 images, use 117.43819856643677 seconds, loss 0.016559497247354917\n",
      "\n",
      "trained 21616 images, use 121.71629977226257 seconds, loss 0.01689337663811951\n",
      "\n",
      "trained 22416 images, use 125.84699320793152 seconds, loss 0.016820317893368745\n",
      "\n",
      "trained 23216 images, use 130.7936749458313 seconds, loss 0.01718148387139201\n",
      "\n",
      "trained 24016 images, use 135.29787492752075 seconds, loss 0.01697668355465501\n",
      "\n",
      "trained 24816 images, use 140.1483244895935 seconds, loss 0.01671077579514306\n",
      "\n",
      "trained 25616 images, use 144.10878705978394 seconds, loss 0.016483633561419107\n",
      "\n",
      "trained 26416 images, use 148.59289932250977 seconds, loss 0.016551556049470652\n",
      "\n",
      "trained 27216 images, use 152.9902651309967 seconds, loss 0.016226715601561536\n",
      "\n",
      "trained 28016 images, use 157.60639882087708 seconds, loss 0.016384311630757372\n",
      "\n",
      "trained 28816 images, use 162.06088948249817 seconds, loss 0.016253782171894538\n",
      "\n",
      "trained 29616 images, use 166.53445887565613 seconds, loss 0.016043538262438508\n",
      "\n",
      "trained 30416 images, use 171.2824728488922 seconds, loss 0.015482090053001182\n",
      "\n",
      "trained 31216 images, use 175.73675298690796 seconds, loss 0.016246375510028704\n",
      "\n",
      "trained 32016 images, use 180.27741980552673 seconds, loss 0.016709918959252817\n",
      "\n",
      "trained 32816 images, use 184.51372647285461 seconds, loss 0.016420440224748645\n",
      "\n",
      "trained 33616 images, use 189.47599577903748 seconds, loss 0.01595380262908819\n",
      "\n",
      "trained 34416 images, use 193.9324541091919 seconds, loss 0.015836002883331705\n",
      "\n",
      "trained 35216 images, use 198.9089047908783 seconds, loss 0.015821304245023808\n",
      "\n",
      "trained 36016 images, use 202.81054520606995 seconds, loss 0.015506355862896625\n",
      "\n",
      "trained 36816 images, use 207.62884902954102 seconds, loss 0.01527742365894327\n",
      "\n",
      "trained 37616 images, use 212.15082502365112 seconds, loss 0.0150822302762672\n",
      "\n",
      "trained 38416 images, use 216.9122440814972 seconds, loss 0.01513465234641351\n",
      "\n",
      "trained 39216 images, use 221.69412660598755 seconds, loss 0.015268283906664515\n",
      "\n",
      "trained 40016 images, use 226.50359463691711 seconds, loss 0.01507121536396924\n",
      "\n",
      "trained 40816 images, use 230.40208101272583 seconds, loss 0.0147948539752207\n",
      "\n",
      "trained 41616 images, use 235.57391619682312 seconds, loss 0.01455129341402293\n",
      "\n",
      "trained 42416 images, use 240.12479639053345 seconds, loss 0.014458047845877594\n",
      "\n",
      "trained 43216 images, use 244.45659518241882 seconds, loss 0.01451531479114561\n",
      "\n",
      "trained 44016 images, use 249.26465344429016 seconds, loss 0.014408602729819777\n",
      "\n",
      "trained 44816 images, use 253.2488317489624 seconds, loss 0.014125926797092094\n",
      "\n",
      "trained 45616 images, use 258.0332338809967 seconds, loss 0.014044624106358634\n",
      "\n",
      "trained 46416 images, use 263.56350898742676 seconds, loss 0.014069520764341379\n",
      "\n",
      "trained 47216 images, use 268.0096080303192 seconds, loss 0.013991261329842596\n",
      "\n",
      "trained 48016 images, use 272.52437567710876 seconds, loss 0.013818809973284774\n",
      "\n",
      "trained 48816 images, use 277.33092641830444 seconds, loss 0.013741849656886608\n",
      "\n",
      "trained 49616 images, use 282.08815026283264 seconds, loss 0.013784582741181158\n",
      "\n",
      "trained 50416 images, use 286.4506335258484 seconds, loss 0.013620286738329513\n",
      "\n",
      "trained 51216 images, use 290.92628383636475 seconds, loss 0.013595913860388158\n",
      "\n",
      "trained 52016 images, use 295.21198081970215 seconds, loss 0.013448163867211553\n",
      "\n",
      "trained 52816 images, use 300.288028717041 seconds, loss 0.013377002571933118\n",
      "\n",
      "trained 53616 images, use 304.74624967575073 seconds, loss 0.013242284861830317\n",
      "\n",
      "trained 54416 images, use 309.1684081554413 seconds, loss 0.013038325884602832\n",
      "\n",
      "trained 55216 images, use 313.8829538822174 seconds, loss 0.013076565141866775\n",
      "\n",
      "trained 56016 images, use 318.75567507743835 seconds, loss 0.01314241296061496\n",
      "\n",
      "trained 56816 images, use 322.9528295993805 seconds, loss 0.013198003648695859\n",
      "\n",
      "trained 57616 images, use 327.5738298892975 seconds, loss 0.013371938657595247\n",
      "\n",
      "trained 58416 images, use 332.0516445636749 seconds, loss 0.013542593997536708\n",
      "\n",
      "trained 59216 images, use 336.90656638145447 seconds, loss 0.013446387136826742\n",
      "\n",
      "trained 60016 images, use 341.94630312919617 seconds, loss 0.013124755877410191\n",
      "\n",
      "trained 60816 images, use 346.11944675445557 seconds, loss 0.013073845250913672\n",
      "\n",
      "trained 61616 images, use 350.9801754951477 seconds, loss 0.013053671588550872\n",
      "\n",
      "trained 62416 images, use 355.26221776008606 seconds, loss 0.012956516031214756\n",
      "\n",
      "trained 63216 images, use 359.4215590953827 seconds, loss 0.012731519682885021\n",
      "\n",
      "trained 64016 images, use 364.5803961753845 seconds, loss 0.012835916046561419\n",
      "\n",
      "trained 64816 images, use 368.85028553009033 seconds, loss 0.012820428790837647\n",
      "\n",
      "trained 65616 images, use 373.50994396209717 seconds, loss 0.012552283938757545\n",
      "\n",
      "trained 66416 images, use 378.11473536491394 seconds, loss 0.012487342510860717\n",
      "\n",
      "trained 67216 images, use 382.8238775730133 seconds, loss 0.012468210736533201\n",
      "\n",
      "trained 68016 images, use 387.49175906181335 seconds, loss 0.012373261972383516\n",
      "\n",
      "trained 68816 images, use 391.92891573905945 seconds, loss 0.012118969666892822\n",
      "\n",
      "trained 69616 images, use 397.4242465496063 seconds, loss 0.012113610822833673\n",
      "\n",
      "trained 70416 images, use 401.35380840301514 seconds, loss 0.012230317301864989\n",
      "\n",
      "trained 71216 images, use 406.2708556652069 seconds, loss 0.012265540793571983\n",
      "\n",
      "trained 72016 images, use 411.08007431030273 seconds, loss 0.01206645922228402\n",
      "\n",
      "trained 72816 images, use 415.0333082675934 seconds, loss 0.011960073220406485\n",
      "\n",
      "trained 73616 images, use 420.1442868709564 seconds, loss 0.011871843096542729\n",
      "\n",
      "trained 74416 images, use 424.7962784767151 seconds, loss 0.011911844346351579\n",
      "\n",
      "trained 75216 images, use 429.07534980773926 seconds, loss 0.011740892013918761\n",
      "\n",
      "trained 76016 images, use 433.232946395874 seconds, loss 0.011639242834232823\n",
      "\n",
      "trained 76816 images, use 437.71346831321716 seconds, loss 0.011609031391934784\n",
      "\n",
      "trained 77616 images, use 442.27258110046387 seconds, loss 0.011430581777614924\n",
      "\n",
      "trained 78416 images, use 447.30908608436584 seconds, loss 0.01138096786764257\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 452.65717816352844 seconds, loss 0.01126582238193423\n",
      "\n",
      "trained 80016 images, use 458.1374430656433 seconds, loss 0.011119532165199392\n",
      "\n",
      "trained 80816 images, use 462.90202498435974 seconds, loss 0.011092643080276373\n",
      "\n",
      "trained 81616 images, use 467.7132661342621 seconds, loss 0.010962817875666307\n",
      "\n",
      "trained 82416 images, use 472.5462131500244 seconds, loss 0.010941379473224967\n",
      "\n",
      "trained 83216 images, use 477.08877897262573 seconds, loss 0.010824507945956146\n",
      "\n",
      "trained 84016 images, use 481.6532349586487 seconds, loss 0.01078372724105211\n",
      "\n",
      "trained 84816 images, use 486.49200320243835 seconds, loss 0.010664408691694239\n",
      "\n",
      "trained 85616 images, use 491.0672700405121 seconds, loss 0.010641382378945841\n",
      "\n",
      "trained 86416 images, use 495.74180269241333 seconds, loss 0.01064342305246992\n",
      "\n",
      "trained 87216 images, use 500.70397758483887 seconds, loss 0.010537388641912502\n",
      "\n",
      "trained 88016 images, use 505.4090919494629 seconds, loss 0.0105216774530658\n",
      "\n",
      "trained 88816 images, use 509.76024436950684 seconds, loss 0.010489706498926697\n",
      "\n",
      "trained 89616 images, use 514.4973249435425 seconds, loss 0.010470927441229173\n",
      "\n",
      "trained 90416 images, use 519.0253586769104 seconds, loss 0.010324312521863013\n",
      "\n",
      "trained 91216 images, use 523.6703193187714 seconds, loss 0.010286490639023416\n",
      "\n",
      "trained 92016 images, use 528.5272619724274 seconds, loss 0.010480556232732157\n",
      "\n",
      "trained 92816 images, use 532.8447775840759 seconds, loss 0.010502213200732266\n",
      "\n",
      "trained 93616 images, use 537.777370929718 seconds, loss 0.010506636001263897\n",
      "\n",
      "trained 94416 images, use 542.4669086933136 seconds, loss 0.010353986728132928\n",
      "\n",
      "trained 95216 images, use 546.9775500297546 seconds, loss 0.010281775708438457\n",
      "\n",
      "trained 96016 images, use 551.76833152771 seconds, loss 0.010199072635370272\n",
      "\n",
      "trained 96816 images, use 556.291579246521 seconds, loss 0.01007313977844871\n",
      "\n",
      "trained 97616 images, use 560.6499042510986 seconds, loss 0.010003510708608538\n",
      "\n",
      "trained 98416 images, use 565.2605550289154 seconds, loss 0.009968784313160116\n",
      "\n",
      "trained 99216 images, use 569.9799399375916 seconds, loss 0.009860174233543302\n",
      "\n",
      "*************Epoch 1 Avrg Training loss 0.009832156432364136 Elapsed 574.1648750305176\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.7454998199928\n",
      "************* Validation: total 99996 precision 0.9636428314275428 avgTime 0.005930569220640225\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 2 started at 1619460499.848509\n",
      "trained 16 images, use 2.7084755897521973 seconds, loss -0.036870991345494986\n",
      "\n",
      "trained 816 images, use 7.3764519691467285 seconds, loss -0.0013377551244607626\n",
      "\n",
      "trained 1616 images, use 11.876415252685547 seconds, loss -0.003569581594966425\n",
      "\n",
      "trained 2416 images, use 16.712117195129395 seconds, loss -0.005591683026547176\n",
      "\n",
      "trained 3216 images, use 21.575770616531372 seconds, loss -0.0063172924850426505\n",
      "\n",
      "trained 4016 images, use 26.091309309005737 seconds, loss -0.005256609908039016\n",
      "\n",
      "trained 4816 images, use 30.655241012573242 seconds, loss -0.005760613715566004\n",
      "\n",
      "trained 5616 images, use 35.42093086242676 seconds, loss -0.006582586302101845\n",
      "\n",
      "trained 6416 images, use 40.34227681159973 seconds, loss -0.0061500439694294915\n",
      "\n",
      "trained 7216 images, use 44.90737271308899 seconds, loss -0.0061700401943078085\n",
      "\n",
      "trained 8016 images, use 49.61615777015686 seconds, loss -0.0067668868840089534\n",
      "\n",
      "trained 8816 images, use 53.67485332489014 seconds, loss -0.006761821527607685\n",
      "\n",
      "trained 9616 images, use 58.262606143951416 seconds, loss -0.006750370125963888\n",
      "\n",
      "trained 10416 images, use 63.41850209236145 seconds, loss -0.006793653948230389\n",
      "\n",
      "trained 11216 images, use 67.84493231773376 seconds, loss -0.0062677128230681925\n",
      "\n",
      "trained 12016 images, use 72.44638252258301 seconds, loss -0.0060708840683993065\n",
      "\n",
      "trained 12816 images, use 77.15812182426453 seconds, loss -0.006342809714964519\n",
      "\n",
      "trained 13616 images, use 81.39224600791931 seconds, loss -0.0067788062918058955\n",
      "\n",
      "trained 14416 images, use 86.1312301158905 seconds, loss -0.006996568275601118\n",
      "\n",
      "trained 15216 images, use 90.67360210418701 seconds, loss -0.006418252442307973\n",
      "\n",
      "trained 16016 images, use 95.40141606330872 seconds, loss -0.005919692357267791\n",
      "\n",
      "trained 16816 images, use 99.92009401321411 seconds, loss -0.006384571635420168\n",
      "\n",
      "trained 17616 images, use 105.20379376411438 seconds, loss -0.006471072541080337\n",
      "\n",
      "trained 18416 images, use 110.33325910568237 seconds, loss -0.00632910557664622\n",
      "\n",
      "trained 19216 images, use 115.28606605529785 seconds, loss -0.005889454671093023\n",
      "\n",
      "trained 20016 images, use 120.15311431884766 seconds, loss -0.005521013022494538\n",
      "\n",
      "trained 20816 images, use 125.08209276199341 seconds, loss -0.004821969552733471\n",
      "\n",
      "trained 21616 images, use 129.73779773712158 seconds, loss -0.0034879569784230444\n",
      "\n",
      "trained 22416 images, use 134.52042889595032 seconds, loss -0.0031296220069904593\n",
      "\n",
      "trained 23216 images, use 139.20051383972168 seconds, loss -0.002784424603776557\n",
      "\n",
      "trained 24016 images, use 144.04396224021912 seconds, loss -0.0027641212272308344\n",
      "\n",
      "trained 24816 images, use 148.26055097579956 seconds, loss -0.0032638040689356054\n",
      "\n",
      "trained 25616 images, use 152.90616869926453 seconds, loss -0.0029850234410166857\n",
      "\n",
      "trained 26416 images, use 157.5980703830719 seconds, loss -0.002881409913014235\n",
      "\n",
      "trained 27216 images, use 162.0887908935547 seconds, loss -0.0032229721243848936\n",
      "\n",
      "trained 28016 images, use 167.0743112564087 seconds, loss -0.003253716268652697\n",
      "\n",
      "trained 28816 images, use 171.54725980758667 seconds, loss -0.002985675069883354\n",
      "\n",
      "trained 29616 images, use 176.71079468727112 seconds, loss -0.002581751177785918\n",
      "\n",
      "trained 30416 images, use 181.6990933418274 seconds, loss -0.002497083241289891\n",
      "\n",
      "trained 31216 images, use 186.31090188026428 seconds, loss -0.0023318019335479743\n",
      "\n",
      "trained 32016 images, use 191.45144629478455 seconds, loss -0.0023355961884962734\n",
      "\n",
      "trained 32816 images, use 195.59685516357422 seconds, loss -0.0023157389419353937\n",
      "\n",
      "trained 33616 images, use 200.44552874565125 seconds, loss -0.0023538308028102036\n",
      "\n",
      "trained 34416 images, use 204.9613552093506 seconds, loss -0.0020444584857533103\n",
      "\n",
      "trained 35216 images, use 210.00002431869507 seconds, loss -0.0021251798904262783\n",
      "\n",
      "trained 36016 images, use 214.32998490333557 seconds, loss -0.002267751441047474\n",
      "\n",
      "trained 36816 images, use 219.20406436920166 seconds, loss -0.0025024501168924417\n",
      "\n",
      "trained 37616 images, use 223.65354180335999 seconds, loss -0.002550517120869786\n",
      "\n",
      "trained 38416 images, use 228.6639506816864 seconds, loss -0.0026492797630508704\n",
      "\n",
      "trained 39216 images, use 233.47156691551208 seconds, loss -0.002689834230721489\n",
      "\n",
      "trained 40016 images, use 237.94162559509277 seconds, loss -0.003032985332968766\n",
      "\n",
      "trained 40816 images, use 242.81084966659546 seconds, loss -0.003064604053723766\n",
      "\n",
      "trained 41616 images, use 247.49978232383728 seconds, loss -0.003197028358454575\n",
      "\n",
      "trained 42416 images, use 252.00082349777222 seconds, loss -0.0030376048976399894\n",
      "\n",
      "trained 43216 images, use 257.02934288978577 seconds, loss -0.003231704414740817\n",
      "\n",
      "trained 44016 images, use 260.99572801589966 seconds, loss -0.0032947211284197185\n",
      "\n",
      "trained 44816 images, use 265.66406989097595 seconds, loss -0.0031604525777491357\n",
      "\n",
      "trained 45616 images, use 270.65501165390015 seconds, loss -0.003215735996205544\n",
      "\n",
      "trained 46416 images, use 274.46630334854126 seconds, loss -0.0033496544469697664\n",
      "\n",
      "trained 47216 images, use 279.3905529975891 seconds, loss -0.0034556722039318813\n",
      "\n",
      "trained 48016 images, use 284.32064056396484 seconds, loss -0.0034654882301808024\n",
      "\n",
      "trained 48816 images, use 289.3073208332062 seconds, loss -0.003550619948846468\n",
      "\n",
      "trained 49616 images, use 293.52733302116394 seconds, loss -0.0037436808818445506\n",
      "\n",
      "trained 50416 images, use 298.07134556770325 seconds, loss -0.003676301440117904\n",
      "\n",
      "trained 51216 images, use 303.0276770591736 seconds, loss -0.003613671863235712\n",
      "\n",
      "trained 52016 images, use 307.7201678752899 seconds, loss -0.0035741859163038936\n",
      "\n",
      "trained 52816 images, use 312.60105657577515 seconds, loss -0.0035138619026483806\n",
      "\n",
      "trained 53616 images, use 317.12336349487305 seconds, loss -0.0035076069881383697\n",
      "\n",
      "trained 54416 images, use 321.89863204956055 seconds, loss -0.0034946917470523088\n",
      "\n",
      "trained 55216 images, use 326.30991864204407 seconds, loss -0.003609225720444439\n",
      "\n",
      "trained 56016 images, use 331.21583676338196 seconds, loss -0.00345504359160288\n",
      "\n",
      "trained 56816 images, use 335.75791478157043 seconds, loss -0.003414389845225365\n",
      "\n",
      "trained 57616 images, use 340.43481063842773 seconds, loss -0.003426501272079278\n",
      "\n",
      "trained 58416 images, use 344.95198702812195 seconds, loss -0.0035618456902874606\n",
      "\n",
      "trained 59216 images, use 349.4182004928589 seconds, loss -0.003665330908252749\n",
      "\n",
      "trained 60016 images, use 354.3237781524658 seconds, loss -0.0038015555298902956\n",
      "\n",
      "trained 60816 images, use 359.2936019897461 seconds, loss -0.003890341714225775\n",
      "\n",
      "trained 61616 images, use 363.5119843482971 seconds, loss -0.0039468699195995246\n",
      "\n",
      "trained 62416 images, use 368.2922639846802 seconds, loss -0.003967444027810076\n",
      "\n",
      "trained 63216 images, use 373.1348593235016 seconds, loss -0.004000172145958499\n",
      "\n",
      "trained 64016 images, use 377.77430748939514 seconds, loss -0.0039644320007381165\n",
      "\n",
      "trained 64816 images, use 382.2783741950989 seconds, loss -0.003911804074139336\n",
      "\n",
      "trained 65616 images, use 386.9403991699219 seconds, loss -0.0038441810420829997\n",
      "\n",
      "trained 66416 images, use 391.54504799842834 seconds, loss -0.003944883671912366\n",
      "\n",
      "trained 67216 images, use 395.93722796440125 seconds, loss -0.003990416542927736\n",
      "\n",
      "trained 68016 images, use 400.609258890152 seconds, loss -0.0039022832465209025\n",
      "\n",
      "trained 68816 images, use 405.49676537513733 seconds, loss -0.004057653815225916\n",
      "\n",
      "trained 69616 images, use 409.91470289230347 seconds, loss -0.004176353241739568\n",
      "\n",
      "trained 70416 images, use 414.87021255493164 seconds, loss -0.004195717744501902\n",
      "\n",
      "trained 71216 images, use 419.1692633628845 seconds, loss -0.004112434781310289\n",
      "\n",
      "trained 72016 images, use 424.067583322525 seconds, loss -0.004185608345922382\n",
      "\n",
      "trained 72816 images, use 428.8180458545685 seconds, loss -0.0040391326660738115\n",
      "\n",
      "trained 73616 images, use 433.6835927963257 seconds, loss -0.00387248933077716\n",
      "\n",
      "trained 74416 images, use 438.3671352863312 seconds, loss -0.003859316936299645\n",
      "\n",
      "trained 75216 images, use 443.1814868450165 seconds, loss -0.003833355805897772\n",
      "\n",
      "trained 76016 images, use 447.7187898159027 seconds, loss -0.003874114512593824\n",
      "\n",
      "trained 76816 images, use 452.200546503067 seconds, loss -0.003855158763884366\n",
      "\n",
      "trained 77616 images, use 456.7035138607025 seconds, loss -0.0038297994017784994\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 78416 images, use 461.7364227771759 seconds, loss -0.0039290914120817455\n",
      "\n",
      "trained 79216 images, use 466.36350202560425 seconds, loss -0.004034996367532315\n",
      "\n",
      "trained 80016 images, use 471.0814108848572 seconds, loss -0.004015988034817095\n",
      "\n",
      "trained 80816 images, use 476.0512218475342 seconds, loss -0.00409890652480573\n",
      "\n",
      "trained 81616 images, use 480.5691907405853 seconds, loss -0.004088105796812358\n",
      "\n",
      "trained 82416 images, use 484.7925684452057 seconds, loss -0.004146674143824311\n",
      "\n",
      "trained 83216 images, use 489.3310618400574 seconds, loss -0.004136301608740654\n",
      "\n",
      "trained 84016 images, use 493.8360595703125 seconds, loss -0.004119815146317129\n",
      "\n",
      "trained 84816 images, use 498.11960554122925 seconds, loss -0.004054905323499242\n",
      "\n",
      "trained 85616 images, use 503.31123328208923 seconds, loss -0.00392676160418562\n",
      "\n",
      "trained 86416 images, use 507.44636964797974 seconds, loss -0.003915182632029804\n",
      "\n",
      "trained 87216 images, use 512.1558127403259 seconds, loss -0.0038412730987144035\n",
      "\n",
      "trained 88016 images, use 516.7446262836456 seconds, loss -0.003798484120231522\n",
      "\n",
      "trained 88816 images, use 521.7012057304382 seconds, loss -0.0038968174391657132\n",
      "\n",
      "trained 89616 images, use 526.0578951835632 seconds, loss -0.0038911510975110407\n",
      "\n",
      "trained 90416 images, use 530.8857238292694 seconds, loss -0.00385894472954659\n",
      "\n",
      "trained 91216 images, use 535.7355649471283 seconds, loss -0.003777089557424743\n",
      "\n",
      "trained 92016 images, use 540.5497195720673 seconds, loss -0.003851789346924366\n",
      "\n",
      "trained 92816 images, use 545.187539100647 seconds, loss -0.0038455369665306056\n",
      "\n",
      "trained 93616 images, use 550.0056583881378 seconds, loss -0.0038999992677532435\n",
      "\n",
      "trained 94416 images, use 554.8824639320374 seconds, loss -0.003987823936069114\n",
      "\n",
      "trained 95216 images, use 559.239604473114 seconds, loss -0.003946990497439323\n",
      "\n",
      "trained 96016 images, use 564.1709771156311 seconds, loss -0.003934167875385474\n",
      "\n",
      "trained 96816 images, use 569.1442453861237 seconds, loss -0.0037979732588951038\n",
      "\n",
      "trained 97616 images, use 573.6812915802002 seconds, loss -0.003704592080658466\n",
      "\n",
      "trained 98416 images, use 578.5038528442383 seconds, loss -0.003791380459219063\n",
      "\n",
      "trained 99216 images, use 583.1222763061523 seconds, loss -0.003774578707287683\n",
      "\n",
      "*************Epoch 2 Avrg Training loss -0.003849591393372975 Elapsed 587.3195853233337\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n",
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.7565802632105285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Validation: total 99996 precision 0.9652257518872184 avgTime 0.006917778070108706\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 3 started at 1619461779.4367404\n",
      "trained 16 images, use 1.9163501262664795 seconds, loss 0.016377918422222137\n",
      "\n",
      "trained 816 images, use 5.843927621841431 seconds, loss -0.014842554314572435\n",
      "\n",
      "trained 1616 images, use 10.398487091064453 seconds, loss -0.006433104937861893\n",
      "\n",
      "trained 2416 images, use 14.598962783813477 seconds, loss -0.005855453666491054\n",
      "\n",
      "trained 3216 images, use 18.80381178855896 seconds, loss -0.006954480748823014\n",
      "\n",
      "trained 4016 images, use 23.47851586341858 seconds, loss -0.009089763168525505\n",
      "\n",
      "trained 4816 images, use 27.715797424316406 seconds, loss -0.009097869054064315\n",
      "\n",
      "trained 5616 images, use 32.00524425506592 seconds, loss -0.010332687128042877\n",
      "\n",
      "trained 6416 images, use 36.63849449157715 seconds, loss -0.008522613227004833\n",
      "\n",
      "trained 7216 images, use 41.23138642311096 seconds, loss -0.007256147047335826\n",
      "\n",
      "trained 8016 images, use 45.76111364364624 seconds, loss -0.007297080711334521\n",
      "\n",
      "trained 8816 images, use 50.177202463150024 seconds, loss -0.007710350150233168\n",
      "\n",
      "trained 9616 images, use 54.22110652923584 seconds, loss -0.00853380209758013\n",
      "\n",
      "trained 10416 images, use 58.987733602523804 seconds, loss -0.008092067439656882\n",
      "\n",
      "trained 11216 images, use 63.36580228805542 seconds, loss -0.00849292828030473\n",
      "\n",
      "trained 12016 images, use 67.75179648399353 seconds, loss -0.009119061378829002\n",
      "\n",
      "trained 12816 images, use 72.91792845726013 seconds, loss -0.009604078153162228\n",
      "\n",
      "trained 13616 images, use 77.12620687484741 seconds, loss -0.009559121704469063\n",
      "\n",
      "trained 14416 images, use 81.81430149078369 seconds, loss -0.00985894223537421\n",
      "\n",
      "trained 15216 images, use 86.33900237083435 seconds, loss -0.009631738268932672\n",
      "\n",
      "trained 16016 images, use 90.81252455711365 seconds, loss -0.008980021239878766\n",
      "\n",
      "trained 16816 images, use 95.08616399765015 seconds, loss -0.009322115836455664\n",
      "\n",
      "trained 17616 images, use 99.7029664516449 seconds, loss -0.009624230212643118\n",
      "\n",
      "trained 18416 images, use 104.69006180763245 seconds, loss -0.009488713237235262\n",
      "\n",
      "trained 19216 images, use 109.05384731292725 seconds, loss -0.009220460624628338\n",
      "\n",
      "trained 20016 images, use 113.84357833862305 seconds, loss -0.008624046087649408\n",
      "\n",
      "trained 20816 images, use 118.4540159702301 seconds, loss -0.008213642224240812\n",
      "\n",
      "trained 21616 images, use 122.85408735275269 seconds, loss -0.008281171908745916\n",
      "\n",
      "trained 22416 images, use 127.82117915153503 seconds, loss -0.008271343209567352\n",
      "\n",
      "trained 23216 images, use 132.18011617660522 seconds, loss -0.00869798523428181\n",
      "\n",
      "trained 24016 images, use 136.6138162612915 seconds, loss -0.008677898156699245\n",
      "\n",
      "trained 24816 images, use 141.3468940258026 seconds, loss -0.009060176361260544\n",
      "\n",
      "trained 25616 images, use 145.91041374206543 seconds, loss -0.008814860081451145\n",
      "\n",
      "trained 26416 images, use 150.86268615722656 seconds, loss -0.008723707248514703\n",
      "\n",
      "trained 27216 images, use 155.74845552444458 seconds, loss -0.008601206597425706\n",
      "\n",
      "trained 28016 images, use 160.1187036037445 seconds, loss -0.008827314900343514\n",
      "\n",
      "trained 28816 images, use 165.07895469665527 seconds, loss -0.009138530038102268\n",
      "\n",
      "trained 29616 images, use 169.64922213554382 seconds, loss -0.009079741099192778\n",
      "\n",
      "trained 30416 images, use 174.01246070861816 seconds, loss -0.00909790180491906\n",
      "\n",
      "trained 31216 images, use 179.26504158973694 seconds, loss -0.009038562919270545\n",
      "\n",
      "trained 32016 images, use 183.6860761642456 seconds, loss -0.008800684166906741\n",
      "\n",
      "trained 32816 images, use 187.86394906044006 seconds, loss -0.008620167371591875\n",
      "\n",
      "trained 33616 images, use 192.71799755096436 seconds, loss -0.008693954736036928\n",
      "\n",
      "trained 34416 images, use 197.64435815811157 seconds, loss -0.008399598505732322\n",
      "\n",
      "trained 35216 images, use 202.15886449813843 seconds, loss -0.008045892081873757\n",
      "\n",
      "trained 36016 images, use 206.59464120864868 seconds, loss -0.008020782746131076\n",
      "\n",
      "trained 36816 images, use 211.3453025817871 seconds, loss -0.008130050210345572\n",
      "\n",
      "trained 37616 images, use 216.02747344970703 seconds, loss -0.00800704908228259\n",
      "\n",
      "trained 38416 images, use 220.54263710975647 seconds, loss -0.00821709891296042\n",
      "\n",
      "trained 39216 images, use 225.59071683883667 seconds, loss -0.008041592350477312\n",
      "\n",
      "trained 40016 images, use 230.14048147201538 seconds, loss -0.007945294726504726\n",
      "\n",
      "trained 40816 images, use 234.47619724273682 seconds, loss -0.007988347676402219\n",
      "\n",
      "trained 41616 images, use 239.0642864704132 seconds, loss -0.00788242292704103\n",
      "\n",
      "trained 42416 images, use 243.6518430709839 seconds, loss -0.007766454344523639\n",
      "\n",
      "trained 43216 images, use 248.4531660079956 seconds, loss -0.007841246027771217\n",
      "\n",
      "trained 44016 images, use 253.23419380187988 seconds, loss -0.007773722250275632\n",
      "\n",
      "trained 44816 images, use 258.19494581222534 seconds, loss -0.007917394226737358\n",
      "\n",
      "trained 45616 images, use 262.6222360134125 seconds, loss -0.007847608424382556\n",
      "\n",
      "trained 46416 images, use 267.4310131072998 seconds, loss -0.007822581691098037\n",
      "\n",
      "trained 47216 images, use 271.8762249946594 seconds, loss -0.0077260403942414095\n",
      "\n",
      "trained 48016 images, use 276.20707082748413 seconds, loss -0.0076358593178471375\n",
      "\n",
      "trained 48816 images, use 280.9624080657959 seconds, loss -0.007598201648183341\n",
      "\n",
      "trained 49616 images, use 285.61191725730896 seconds, loss -0.007791768007189757\n",
      "\n",
      "trained 50416 images, use 290.11579728126526 seconds, loss -0.007653523826373544\n",
      "\n",
      "trained 51216 images, use 294.7580428123474 seconds, loss -0.007551859628974063\n",
      "\n",
      "trained 52016 images, use 299.5072453022003 seconds, loss -0.007471200228406492\n",
      "\n",
      "trained 52816 images, use 303.89655661582947 seconds, loss -0.007390266853246259\n",
      "\n",
      "trained 53616 images, use 308.6210951805115 seconds, loss -0.007183413205969857\n",
      "\n",
      "trained 54416 images, use 313.0517346858978 seconds, loss -0.007184151393828967\n",
      "\n",
      "trained 55216 images, use 317.6942808628082 seconds, loss -0.0071923098470946896\n",
      "\n",
      "trained 56016 images, use 322.2096209526062 seconds, loss -0.0070670392584295805\n",
      "\n",
      "trained 56816 images, use 326.7049789428711 seconds, loss -0.0071871211268018246\n",
      "\n",
      "trained 57616 images, use 331.2161316871643 seconds, loss -0.007240297169322011\n",
      "\n",
      "trained 58416 images, use 335.9960446357727 seconds, loss -0.0074126343007491075\n",
      "\n",
      "trained 59216 images, use 340.80568385124207 seconds, loss -0.007406976914886063\n",
      "\n",
      "trained 60016 images, use 345.14285922050476 seconds, loss -0.007514028060688403\n",
      "\n",
      "trained 60816 images, use 350.094619512558 seconds, loss -0.007687298281503375\n",
      "\n",
      "trained 61616 images, use 354.4824204444885 seconds, loss -0.007762401595190589\n",
      "\n",
      "trained 62416 images, use 358.9306721687317 seconds, loss -0.008037854415351108\n",
      "\n",
      "trained 63216 images, use 363.8691165447235 seconds, loss -0.0082572575497524\n",
      "\n",
      "trained 64016 images, use 368.6239264011383 seconds, loss -0.008325143596090672\n",
      "\n",
      "trained 64816 images, use 373.1108536720276 seconds, loss -0.008447026302624859\n",
      "\n",
      "trained 65616 images, use 377.5169904232025 seconds, loss -0.008454147108731408\n",
      "\n",
      "trained 66416 images, use 381.9189748764038 seconds, loss -0.008605362196172084\n",
      "\n",
      "trained 67216 images, use 386.7511534690857 seconds, loss -0.008585543793721766\n",
      "\n",
      "trained 68016 images, use 391.1213445663452 seconds, loss -0.008678183715051498\n",
      "\n",
      "trained 68816 images, use 395.69039583206177 seconds, loss -0.008784165125682704\n",
      "\n",
      "trained 69616 images, use 400.70675802230835 seconds, loss -0.00895509574680171\n",
      "\n",
      "trained 70416 images, use 405.56355571746826 seconds, loss -0.008882937977603107\n",
      "\n",
      "trained 71216 images, use 410.07381653785706 seconds, loss -0.008822996334753764\n",
      "\n",
      "trained 72016 images, use 414.9993507862091 seconds, loss -0.008946736601894198\n",
      "\n",
      "trained 72816 images, use 419.5670063495636 seconds, loss -0.009021179982810537\n",
      "\n",
      "trained 73616 images, use 424.095192193985 seconds, loss -0.00900479047057948\n",
      "\n",
      "trained 74416 images, use 428.59764647483826 seconds, loss -0.008941131359387799\n",
      "\n",
      "trained 75216 images, use 433.3808624744415 seconds, loss -0.00902516346694861\n",
      "\n",
      "trained 76016 images, use 437.71967005729675 seconds, loss -0.008928841127994577\n",
      "\n",
      "trained 76816 images, use 442.01151967048645 seconds, loss -0.008974795345208892\n",
      "\n",
      "trained 77616 images, use 446.5915048122406 seconds, loss -0.00898547808986216\n",
      "\n",
      "trained 78416 images, use 450.9514989852905 seconds, loss -0.008976656699068473\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 455.2528431415558 seconds, loss -0.008984202572262418\n",
      "\n",
      "trained 80016 images, use 459.8563768863678 seconds, loss -0.009031492363028039\n",
      "\n",
      "trained 80816 images, use 464.3423807621002 seconds, loss -0.009050569019762165\n",
      "\n",
      "trained 81616 images, use 468.77282762527466 seconds, loss -0.009047968679582605\n",
      "\n",
      "trained 82416 images, use 473.66902112960815 seconds, loss -0.009095870029499487\n",
      "\n",
      "trained 83216 images, use 477.80554151535034 seconds, loss -0.009060910852777337\n",
      "\n",
      "trained 84016 images, use 482.7035331726074 seconds, loss -0.009093714779291549\n",
      "\n",
      "trained 84816 images, use 487.1995515823364 seconds, loss -0.009031880384175212\n",
      "\n",
      "trained 85616 images, use 491.4808225631714 seconds, loss -0.009077649161105662\n",
      "\n",
      "trained 86416 images, use 495.9306261539459 seconds, loss -0.00913551130929818\n",
      "\n",
      "trained 87216 images, use 500.4843661785126 seconds, loss -0.009207565392386888\n",
      "\n",
      "trained 88016 images, use 505.62132835388184 seconds, loss -0.009300832651195712\n",
      "\n",
      "trained 88816 images, use 509.6743609905243 seconds, loss -0.009248818115556053\n",
      "\n",
      "trained 89616 images, use 514.2341966629028 seconds, loss -0.009182395032399085\n",
      "\n",
      "trained 90416 images, use 518.5037124156952 seconds, loss -0.009082218201296321\n",
      "\n",
      "trained 91216 images, use 523.1791391372681 seconds, loss -0.009031818254303395\n",
      "\n",
      "trained 92016 images, use 527.9612698554993 seconds, loss -0.009085688556891625\n",
      "\n",
      "trained 92816 images, use 532.4220523834229 seconds, loss -0.009172134468012825\n",
      "\n",
      "trained 93616 images, use 537.5743863582611 seconds, loss -0.009194030858459445\n",
      "\n",
      "trained 94416 images, use 542.1243221759796 seconds, loss -0.009263709282516694\n",
      "\n",
      "trained 95216 images, use 546.800726890564 seconds, loss -0.009273514449222437\n",
      "\n",
      "trained 96016 images, use 551.0763471126556 seconds, loss -0.009207595820602784\n",
      "\n",
      "trained 96816 images, use 555.9331421852112 seconds, loss -0.009213627550595507\n",
      "\n",
      "trained 97616 images, use 560.8486478328705 seconds, loss -0.009192811953748383\n",
      "\n",
      "trained 98416 images, use 565.2726049423218 seconds, loss -0.009297955194376142\n",
      "\n",
      "trained 99216 images, use 569.8888509273529 seconds, loss -0.009241820965042958\n",
      "\n",
      "*************Epoch 3 Avrg Training loss -0.009234156636390834 Elapsed 574.1916751861572\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.750860034401376\n",
      "************* Validation: total 99996 precision 0.9644085763430538 avgTime 0.006886697620424043\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 4 started at 1619463042.8540952\n",
      "trained 16 images, use 1.487950325012207 seconds, loss -0.025088459253311157\n",
      "\n",
      "trained 816 images, use 5.389862298965454 seconds, loss -0.007682480328255154\n",
      "\n",
      "trained 1616 images, use 9.781745433807373 seconds, loss -0.008972178270079323\n",
      "\n",
      "trained 2416 images, use 13.968791723251343 seconds, loss -0.011899214379426619\n",
      "\n",
      "trained 3216 images, use 18.576775312423706 seconds, loss -0.01191217927875961\n",
      "\n",
      "trained 4016 images, use 22.87687873840332 seconds, loss -0.013605834242399497\n",
      "\n",
      "trained 4816 images, use 27.3362717628479 seconds, loss -0.013888735361102373\n",
      "\n",
      "trained 5616 images, use 32.09095883369446 seconds, loss -0.01451723571529907\n",
      "\n",
      "trained 6416 images, use 36.40510559082031 seconds, loss -0.015976713848205003\n",
      "\n",
      "trained 7216 images, use 40.58477520942688 seconds, loss -0.016477463962836038\n",
      "\n",
      "trained 8016 images, use 45.12797570228577 seconds, loss -0.015681084242399616\n",
      "\n",
      "trained 8816 images, use 49.20020818710327 seconds, loss -0.015344374752453734\n",
      "\n",
      "trained 9616 images, use 53.77509927749634 seconds, loss -0.016088313988639674\n",
      "\n",
      "trained 10416 images, use 58.291810750961304 seconds, loss -0.016699523090277234\n",
      "\n",
      "trained 11216 images, use 63.16674518585205 seconds, loss -0.01716195397888923\n",
      "\n",
      "trained 12016 images, use 67.46525764465332 seconds, loss -0.017694268097678087\n",
      "\n",
      "trained 12816 images, use 72.04919481277466 seconds, loss -0.01809425619510313\n",
      "\n",
      "trained 13616 images, use 76.3378005027771 seconds, loss -0.01799340673111966\n",
      "\n",
      "trained 14416 images, use 80.93723130226135 seconds, loss -0.017554212523565062\n",
      "\n",
      "trained 15216 images, use 85.33691120147705 seconds, loss -0.017601648984314773\n",
      "\n",
      "trained 16016 images, use 89.81083798408508 seconds, loss -0.017643332084053092\n",
      "\n",
      "trained 16816 images, use 94.08773112297058 seconds, loss -0.017932776723565188\n",
      "\n",
      "trained 17616 images, use 98.59116125106812 seconds, loss -0.018166833842495844\n",
      "\n",
      "trained 18416 images, use 102.94819116592407 seconds, loss -0.018546688385425922\n",
      "\n",
      "trained 19216 images, use 107.72270584106445 seconds, loss -0.019050982202576224\n",
      "\n",
      "trained 20016 images, use 112.11996269226074 seconds, loss -0.018965944525573836\n",
      "\n",
      "trained 20816 images, use 117.2386384010315 seconds, loss -0.019357112612480156\n",
      "\n",
      "trained 21616 images, use 121.21310830116272 seconds, loss -0.01942406357791686\n",
      "\n",
      "trained 22416 images, use 126.23598408699036 seconds, loss -0.01956131328097529\n",
      "\n",
      "trained 23216 images, use 130.68231916427612 seconds, loss -0.01983152925190765\n",
      "\n",
      "trained 24016 images, use 135.27803087234497 seconds, loss -0.01992595208800622\n",
      "\n",
      "trained 24816 images, use 139.56360340118408 seconds, loss -0.020084347946081348\n",
      "\n",
      "trained 25616 images, use 144.39953017234802 seconds, loss -0.02017292939137846\n",
      "\n",
      "trained 26416 images, use 149.02492713928223 seconds, loss -0.020058524075160164\n",
      "\n",
      "trained 27216 images, use 153.51898860931396 seconds, loss -0.019899130650300547\n",
      "\n",
      "trained 28016 images, use 158.43226194381714 seconds, loss -0.020060611384121317\n",
      "\n",
      "trained 28816 images, use 162.83635711669922 seconds, loss -0.020026606732156726\n",
      "\n",
      "trained 29616 images, use 167.4547872543335 seconds, loss -0.020319962890991545\n",
      "\n",
      "trained 30416 images, use 171.69536423683167 seconds, loss -0.02033407088445196\n",
      "\n",
      "trained 31216 images, use 176.0247507095337 seconds, loss -0.020383454993865686\n",
      "\n",
      "trained 32016 images, use 180.6392035484314 seconds, loss -0.02043926975025383\n",
      "\n",
      "trained 32816 images, use 185.0357096195221 seconds, loss -0.02042502249726161\n",
      "\n",
      "trained 33616 images, use 189.73896622657776 seconds, loss -0.020471743927731004\n",
      "\n",
      "trained 34416 images, use 194.22205424308777 seconds, loss -0.02039310333191774\n",
      "\n",
      "trained 35216 images, use 198.8528687953949 seconds, loss -0.020414136212311498\n",
      "\n",
      "trained 36016 images, use 203.4232213497162 seconds, loss -0.02053801583907584\n",
      "\n",
      "trained 36816 images, use 207.7840440273285 seconds, loss -0.020778167627606915\n",
      "\n",
      "trained 37616 images, use 212.86104202270508 seconds, loss -0.02095030678686822\n",
      "\n",
      "trained 38416 images, use 218.27058863639832 seconds, loss -0.021039866267931723\n",
      "\n",
      "trained 39216 images, use 222.6861870288849 seconds, loss -0.021093634246735122\n",
      "\n",
      "trained 40016 images, use 227.49729371070862 seconds, loss -0.021072616789248825\n",
      "\n",
      "trained 40816 images, use 231.9989414215088 seconds, loss -0.021139635871622316\n",
      "\n",
      "trained 41616 images, use 236.2131700515747 seconds, loss -0.021072276305535424\n",
      "\n",
      "trained 42416 images, use 240.76037216186523 seconds, loss -0.021091401269935073\n",
      "\n",
      "trained 43216 images, use 244.80630660057068 seconds, loss -0.021177700181706085\n",
      "\n",
      "trained 44016 images, use 249.55217456817627 seconds, loss -0.020966149181324296\n",
      "\n",
      "trained 44816 images, use 253.96721720695496 seconds, loss -0.021002795342138676\n",
      "\n",
      "trained 45616 images, use 258.9118027687073 seconds, loss -0.021212723996022007\n",
      "\n",
      "trained 46416 images, use 263.28934812545776 seconds, loss -0.021211675048355496\n",
      "\n",
      "trained 47216 images, use 268.1774070262909 seconds, loss -0.02119883237100824\n",
      "\n",
      "trained 48016 images, use 272.6427869796753 seconds, loss -0.021249821421364713\n",
      "\n",
      "trained 48816 images, use 277.12129163742065 seconds, loss -0.02136115370555301\n",
      "\n",
      "trained 49616 images, use 281.69352889060974 seconds, loss -0.021521216579435398\n",
      "\n",
      "trained 50416 images, use 285.8997013568878 seconds, loss -0.02151209936128829\n",
      "\n",
      "trained 51216 images, use 290.21804332733154 seconds, loss -0.021590121247292874\n",
      "\n",
      "trained 52016 images, use 295.23472714424133 seconds, loss -0.021507450268788364\n",
      "\n",
      "trained 52816 images, use 299.70796394348145 seconds, loss -0.021454207702690103\n",
      "\n",
      "trained 53616 images, use 304.49775099754333 seconds, loss -0.02156898600483504\n",
      "\n",
      "trained 54416 images, use 308.98130989074707 seconds, loss -0.02149849583463205\n",
      "\n",
      "trained 55216 images, use 314.14581847190857 seconds, loss -0.02136181819702194\n",
      "\n",
      "trained 56016 images, use 318.2354018688202 seconds, loss -0.02125068708295193\n",
      "\n",
      "trained 56816 images, use 322.7392873764038 seconds, loss -0.021292246283382655\n",
      "\n",
      "trained 57616 images, use 327.3991963863373 seconds, loss -0.021182928995419684\n",
      "\n",
      "trained 58416 images, use 332.10409116744995 seconds, loss -0.021320092997002466\n",
      "\n",
      "trained 59216 images, use 336.35784435272217 seconds, loss -0.02133082840177242\n",
      "\n",
      "trained 60016 images, use 341.3831510543823 seconds, loss -0.021253154361564542\n",
      "\n",
      "trained 60816 images, use 346.31854224205017 seconds, loss -0.021284270053685016\n",
      "\n",
      "trained 61616 images, use 350.7295858860016 seconds, loss -0.021269926512833683\n",
      "\n",
      "trained 62416 images, use 355.21577048301697 seconds, loss -0.021343231992216896\n",
      "\n",
      "trained 63216 images, use 360.1583013534546 seconds, loss -0.021302371216616343\n",
      "\n",
      "trained 64016 images, use 364.94868326187134 seconds, loss -0.021356504591787905\n",
      "\n",
      "trained 64816 images, use 369.60778284072876 seconds, loss -0.02137998019032648\n",
      "\n",
      "trained 65616 images, use 373.64660835266113 seconds, loss -0.021527325989406508\n",
      "\n",
      "trained 66416 images, use 378.21571373939514 seconds, loss -0.021516828555730397\n",
      "\n",
      "trained 67216 images, use 383.14783453941345 seconds, loss -0.02161118935573337\n",
      "\n",
      "trained 68016 images, use 387.89360070228577 seconds, loss -0.021573253798171828\n",
      "\n",
      "trained 68816 images, use 392.4339852333069 seconds, loss -0.02158248869211798\n",
      "\n",
      "trained 69616 images, use 396.72412061691284 seconds, loss -0.02168221188616612\n",
      "\n",
      "trained 70416 images, use 401.7681565284729 seconds, loss -0.021744251729789294\n",
      "\n",
      "trained 71216 images, use 406.58999967575073 seconds, loss -0.021765444499553404\n",
      "\n",
      "trained 72016 images, use 411.1380934715271 seconds, loss -0.021795597365109335\n",
      "\n",
      "trained 72816 images, use 415.4992735385895 seconds, loss -0.0218684760207469\n",
      "\n",
      "trained 73616 images, use 420.2847740650177 seconds, loss -0.0218443181085789\n",
      "\n",
      "trained 74416 images, use 424.9020609855652 seconds, loss -0.021819964543672726\n",
      "\n",
      "trained 75216 images, use 429.51553988456726 seconds, loss -0.021849221644440586\n",
      "\n",
      "trained 76016 images, use 434.040842294693 seconds, loss -0.021815086370570162\n",
      "\n",
      "trained 76816 images, use 438.9413306713104 seconds, loss -0.021828598385412075\n",
      "\n",
      "trained 77616 images, use 442.9397494792938 seconds, loss -0.021832254650455785\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 78416 images, use 447.45142889022827 seconds, loss -0.021840595256715865\n",
      "\n",
      "trained 79216 images, use 451.92606949806213 seconds, loss -0.021804684916544494\n",
      "\n",
      "trained 80016 images, use 456.37587213516235 seconds, loss -0.021898936822205017\n",
      "\n",
      "trained 80816 images, use 461.1751310825348 seconds, loss -0.022009336902333008\n",
      "\n",
      "trained 81616 images, use 465.3911187648773 seconds, loss -0.021977004993073798\n",
      "\n",
      "trained 82416 images, use 470.0797760486603 seconds, loss -0.021914340507605885\n",
      "\n",
      "trained 83216 images, use 474.8238260746002 seconds, loss -0.021881757905229844\n",
      "\n",
      "trained 84016 images, use 478.9770407676697 seconds, loss -0.021957299199430545\n",
      "\n",
      "trained 84816 images, use 483.4370038509369 seconds, loss -0.02194684698527116\n",
      "\n",
      "trained 85616 images, use 487.8607511520386 seconds, loss -0.021923680383064144\n",
      "\n",
      "trained 86416 images, use 492.29532194137573 seconds, loss -0.021925825138434215\n",
      "\n",
      "trained 87216 images, use 497.14581394195557 seconds, loss -0.0219492413884366\n",
      "\n",
      "trained 88016 images, use 501.591637134552 seconds, loss -0.02199391531127877\n",
      "\n",
      "trained 88816 images, use 505.85096311569214 seconds, loss -0.022072326934258913\n",
      "\n",
      "trained 89616 images, use 510.6339931488037 seconds, loss -0.022020034427229683\n",
      "\n",
      "trained 90416 images, use 515.0262219905853 seconds, loss -0.022004337436282388\n",
      "\n",
      "trained 91216 images, use 519.3888976573944 seconds, loss -0.0220249393913994\n",
      "\n",
      "trained 92016 images, use 523.7543385028839 seconds, loss -0.022095998323803316\n",
      "\n",
      "trained 92816 images, use 528.3589589595795 seconds, loss -0.022146658457041415\n",
      "\n",
      "trained 93616 images, use 532.9587604999542 seconds, loss -0.022142384943132528\n",
      "\n",
      "trained 94416 images, use 537.3872065544128 seconds, loss -0.022147768821588806\n",
      "\n",
      "trained 95216 images, use 541.7057318687439 seconds, loss -0.022119999668612146\n",
      "\n",
      "trained 96016 images, use 545.9987850189209 seconds, loss -0.022112412464565155\n",
      "\n",
      "trained 96816 images, use 550.4155275821686 seconds, loss -0.0221515926190927\n",
      "\n",
      "trained 97616 images, use 554.9059770107269 seconds, loss -0.022158906813720323\n",
      "\n",
      "trained 98416 images, use 559.7057926654816 seconds, loss -0.02217043623787351\n",
      "\n",
      "trained 99216 images, use 564.0444803237915 seconds, loss -0.022172352720922595\n",
      "\n",
      "*************Epoch 4 Avrg Training loss -0.02217050018576323 Elapsed 568.3086388111115\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.780661226449058\n",
      "************* Validation: total 99996 precision 0.9686658894927226 avgTime 0.006058560466236093\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 5 started at 1619464217.4328358\n",
      "trained 16 images, use 1.448988914489746 seconds, loss 7.494927558582276e-05\n",
      "\n",
      "trained 816 images, use 5.703912019729614 seconds, loss -0.030348101728052895\n",
      "\n",
      "trained 1616 images, use 10.138578176498413 seconds, loss -0.030219367428906158\n",
      "\n",
      "trained 2416 images, use 14.395485401153564 seconds, loss -0.030120155704480567\n",
      "\n",
      "trained 3216 images, use 18.371577739715576 seconds, loss -0.02812043658190359\n",
      "\n",
      "trained 4016 images, use 22.8414204120636 seconds, loss -0.027891261206821668\n",
      "\n",
      "trained 4816 images, use 26.90676712989807 seconds, loss -0.026793838663920815\n",
      "\n",
      "trained 5616 images, use 31.54097318649292 seconds, loss -0.026682249478643495\n",
      "\n",
      "trained 6416 images, use 35.5938880443573 seconds, loss -0.026805488853041702\n",
      "\n",
      "trained 7216 images, use 40.171629190444946 seconds, loss -0.02707299271553418\n",
      "\n",
      "trained 8016 images, use 44.7985155582428 seconds, loss -0.026964270958345138\n",
      "\n",
      "trained 8816 images, use 48.734304428100586 seconds, loss -0.026378032071632966\n",
      "\n",
      "trained 9616 images, use 52.916271924972534 seconds, loss -0.02633718565205427\n",
      "\n",
      "trained 10416 images, use 57.28147768974304 seconds, loss -0.026460450854432722\n",
      "\n",
      "trained 11216 images, use 61.65479516983032 seconds, loss -0.026709532926389636\n",
      "\n",
      "trained 12016 images, use 66.43639945983887 seconds, loss -0.027353994405965497\n",
      "\n",
      "trained 12816 images, use 70.5684564113617 seconds, loss -0.02725955936207662\n",
      "\n",
      "trained 13616 images, use 74.79555749893188 seconds, loss -0.027110365023727694\n",
      "\n",
      "trained 14416 images, use 79.10324788093567 seconds, loss -0.02683969139612608\n",
      "\n",
      "trained 15216 images, use 83.54334092140198 seconds, loss -0.02633604680801275\n",
      "\n",
      "trained 16016 images, use 87.60892462730408 seconds, loss -0.02658688355245204\n",
      "\n",
      "trained 16816 images, use 92.23541951179504 seconds, loss -0.026546163805785894\n",
      "\n",
      "trained 17616 images, use 96.87472867965698 seconds, loss -0.02657511874002147\n",
      "\n",
      "trained 18416 images, use 101.25006246566772 seconds, loss -0.026630239917393637\n",
      "\n",
      "trained 19216 images, use 105.49864983558655 seconds, loss -0.026788347048464424\n",
      "\n",
      "trained 20016 images, use 109.74302959442139 seconds, loss -0.02662197425392726\n",
      "\n",
      "trained 20816 images, use 114.20664477348328 seconds, loss -0.026587041840690422\n",
      "\n",
      "trained 21616 images, use 118.94236326217651 seconds, loss -0.02652661796885819\n",
      "\n",
      "trained 22416 images, use 123.03319787979126 seconds, loss -0.026254421162795003\n",
      "\n",
      "trained 23216 images, use 127.91836380958557 seconds, loss -0.02642016509188762\n",
      "\n",
      "trained 24016 images, use 132.33461952209473 seconds, loss -0.02640918489437481\n",
      "\n",
      "trained 24816 images, use 136.45780158042908 seconds, loss -0.02646362913024231\n",
      "\n",
      "trained 25616 images, use 141.1492302417755 seconds, loss -0.02638138825119647\n",
      "\n",
      "trained 26416 images, use 144.6920976638794 seconds, loss -0.026302486097142884\n",
      "\n",
      "trained 27216 images, use 148.97150564193726 seconds, loss -0.026074906486549285\n",
      "\n",
      "trained 28016 images, use 153.72967195510864 seconds, loss -0.026252715642240385\n",
      "\n",
      "trained 28816 images, use 157.49668669700623 seconds, loss -0.026314096760524364\n",
      "\n",
      "trained 29616 images, use 162.16516375541687 seconds, loss -0.026326705647234692\n",
      "\n",
      "trained 30416 images, use 166.3897843360901 seconds, loss -0.026413976529941634\n",
      "\n",
      "trained 31216 images, use 170.749125957489 seconds, loss -0.026447619380759846\n",
      "\n",
      "trained 32016 images, use 174.89589142799377 seconds, loss -0.026135068999872522\n",
      "\n",
      "trained 32816 images, use 180.052832365036 seconds, loss -0.026077691146713343\n",
      "\n",
      "trained 33616 images, use 184.1344108581543 seconds, loss -0.026155740300400465\n",
      "\n",
      "trained 34416 images, use 188.4551179409027 seconds, loss -0.02629992371099995\n",
      "\n",
      "trained 35216 images, use 192.9033224582672 seconds, loss -0.026311920332400745\n",
      "\n",
      "trained 36016 images, use 197.21062541007996 seconds, loss -0.026450806726124793\n",
      "\n",
      "trained 36816 images, use 201.79869842529297 seconds, loss -0.026386843168531095\n",
      "\n",
      "trained 37616 images, use 206.19330668449402 seconds, loss -0.02629876324669558\n",
      "\n",
      "trained 38416 images, use 210.39686393737793 seconds, loss -0.026178465596750994\n",
      "\n",
      "trained 39216 images, use 215.04117155075073 seconds, loss -0.026080286332736957\n",
      "\n",
      "trained 40016 images, use 219.47494459152222 seconds, loss -0.02625358916667711\n",
      "\n",
      "trained 40816 images, use 224.0381190776825 seconds, loss -0.026206282630578972\n",
      "\n",
      "trained 41616 images, use 228.3643696308136 seconds, loss -0.0261730834631946\n",
      "\n",
      "trained 42416 images, use 233.03182768821716 seconds, loss -0.026130034059310147\n",
      "\n",
      "trained 43216 images, use 237.48027515411377 seconds, loss -0.02588022201289439\n",
      "\n",
      "trained 44016 images, use 242.0657868385315 seconds, loss -0.025896003237639915\n",
      "\n",
      "trained 44816 images, use 246.2151379585266 seconds, loss -0.025898374918255463\n",
      "\n",
      "trained 45616 images, use 250.7000539302826 seconds, loss -0.02606322502159196\n",
      "\n",
      "trained 46416 images, use 255.04678559303284 seconds, loss -0.0261417532776311\n",
      "\n",
      "trained 47216 images, use 259.9065454006195 seconds, loss -0.026016101977762413\n",
      "\n",
      "trained 48016 images, use 264.44975996017456 seconds, loss -0.026061440997926295\n",
      "\n",
      "trained 48816 images, use 268.9859595298767 seconds, loss -0.026222999583720524\n",
      "\n",
      "trained 49616 images, use 273.4986140727997 seconds, loss -0.026367153196021877\n",
      "\n",
      "trained 50416 images, use 277.95296692848206 seconds, loss -0.026293615164116848\n",
      "\n",
      "trained 51216 images, use 282.681410074234 seconds, loss -0.026261354623965644\n",
      "\n",
      "trained 52016 images, use 286.75637555122375 seconds, loss -0.02633439702055298\n",
      "\n",
      "trained 52816 images, use 291.0109417438507 seconds, loss -0.026303153047501342\n",
      "\n",
      "trained 53616 images, use 296.25736474990845 seconds, loss -0.026409588870869714\n",
      "\n",
      "trained 54416 images, use 300.31180119514465 seconds, loss -0.026539820182436002\n",
      "\n",
      "trained 55216 images, use 304.9090805053711 seconds, loss -0.02641323880128332\n",
      "\n",
      "trained 56016 images, use 309.22960591316223 seconds, loss -0.02652746404701138\n",
      "\n",
      "trained 56816 images, use 314.46401715278625 seconds, loss -0.026498327425881825\n",
      "\n",
      "trained 57616 images, use 318.6647038459778 seconds, loss -0.026584904340199014\n",
      "\n",
      "trained 58416 images, use 322.8375027179718 seconds, loss -0.026600590782464375\n",
      "\n",
      "trained 59216 images, use 327.732524394989 seconds, loss -0.026781885621066665\n",
      "\n",
      "trained 60016 images, use 332.2385847568512 seconds, loss -0.026842360646263344\n",
      "\n",
      "trained 60816 images, use 336.35762429237366 seconds, loss -0.026829694789301015\n",
      "\n",
      "trained 61616 images, use 341.61515641212463 seconds, loss -0.026835380340821214\n",
      "\n",
      "trained 62416 images, use 345.624037027359 seconds, loss -0.026853926274163414\n",
      "\n",
      "trained 63216 images, use 349.8986678123474 seconds, loss -0.026801485984112777\n",
      "\n",
      "trained 64016 images, use 354.18561005592346 seconds, loss -0.02670694796290735\n",
      "\n",
      "trained 64816 images, use 358.4781048297882 seconds, loss -0.02662652102500506\n",
      "\n",
      "trained 65616 images, use 363.23446702957153 seconds, loss -0.026597834953601372\n",
      "\n",
      "trained 66416 images, use 367.54516768455505 seconds, loss -0.026628707470154004\n",
      "\n",
      "trained 67216 images, use 372.34191966056824 seconds, loss -0.026620654473752135\n",
      "\n",
      "trained 68016 images, use 376.51782631874084 seconds, loss -0.026670426133083177\n",
      "\n",
      "trained 68816 images, use 381.31374955177307 seconds, loss -0.026656879595785353\n",
      "\n",
      "trained 69616 images, use 385.55368995666504 seconds, loss -0.026659970056028093\n",
      "\n",
      "trained 70416 images, use 390.41963934898376 seconds, loss -0.026670432917284756\n",
      "\n",
      "trained 71216 images, use 395.03138041496277 seconds, loss -0.02667597225431233\n",
      "\n",
      "trained 72016 images, use 400.1878819465637 seconds, loss -0.026561474492155766\n",
      "\n",
      "trained 72816 images, use 404.5740113258362 seconds, loss -0.02655826823583378\n",
      "\n",
      "trained 73616 images, use 409.21476221084595 seconds, loss -0.026572095853038265\n",
      "\n",
      "trained 74416 images, use 414.09655475616455 seconds, loss -0.026481126510164845\n",
      "\n",
      "trained 75216 images, use 418.6522948741913 seconds, loss -0.026538839095541094\n",
      "\n",
      "trained 76016 images, use 423.288667678833 seconds, loss -0.0264725910870419\n",
      "\n",
      "trained 76816 images, use 427.945650100708 seconds, loss -0.026426117218673766\n",
      "\n",
      "trained 77616 images, use 432.7466969490051 seconds, loss -0.026442182446389\n",
      "\n",
      "trained 78416 images, use 437.2326431274414 seconds, loss -0.026368629524309396\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 441.8514549732208 seconds, loss -0.026301304580690903\n",
      "\n",
      "trained 80016 images, use 446.9004502296448 seconds, loss -0.02632371524023296\n",
      "\n",
      "trained 80816 images, use 450.95304012298584 seconds, loss -0.0262754865734109\n",
      "\n",
      "trained 81616 images, use 455.7040910720825 seconds, loss -0.02628048040847728\n",
      "\n",
      "trained 82416 images, use 460.0924127101898 seconds, loss -0.026274279305217498\n",
      "\n",
      "trained 83216 images, use 464.6136567592621 seconds, loss -0.02631403282690691\n",
      "\n",
      "trained 84016 images, use 469.4829180240631 seconds, loss -0.026277375942507647\n",
      "\n",
      "trained 84816 images, use 473.9786767959595 seconds, loss -0.026287003786855032\n",
      "\n",
      "trained 85616 images, use 478.8715341091156 seconds, loss -0.026327178605017133\n",
      "\n",
      "trained 86416 images, use 483.67493987083435 seconds, loss -0.026313277240265366\n",
      "\n",
      "trained 87216 images, use 488.28991436958313 seconds, loss -0.026315891469225847\n",
      "\n",
      "trained 88016 images, use 493.9093623161316 seconds, loss -0.026232720511209985\n",
      "\n",
      "trained 88816 images, use 499.5313355922699 seconds, loss -0.026152188058901474\n",
      "\n",
      "trained 89616 images, use 504.95478534698486 seconds, loss -0.026161316673544176\n",
      "\n",
      "trained 90416 images, use 510.03919315338135 seconds, loss -0.02609074954732653\n",
      "\n",
      "trained 91216 images, use 514.7280917167664 seconds, loss -0.02609113105372467\n",
      "\n",
      "trained 92016 images, use 519.9328286647797 seconds, loss -0.026165734696350997\n",
      "\n",
      "trained 92816 images, use 525.3534052371979 seconds, loss -0.026135258136009264\n",
      "\n",
      "trained 93616 images, use 531.332973241806 seconds, loss -0.026126283305559946\n",
      "\n",
      "trained 94416 images, use 537.3290207386017 seconds, loss -0.026069957103439817\n",
      "\n",
      "trained 95216 images, use 543.6321947574615 seconds, loss -0.02598458625764075\n",
      "\n",
      "trained 96016 images, use 549.2676854133606 seconds, loss -0.025922517929764275\n",
      "\n",
      "trained 96816 images, use 554.7844657897949 seconds, loss -0.025891938557470105\n",
      "\n",
      "trained 97616 images, use 560.2666392326355 seconds, loss -0.02584809074015267\n",
      "\n",
      "trained 98416 images, use 565.9206166267395 seconds, loss -0.025888970536515822\n",
      "\n",
      "trained 99216 images, use 571.0150940418243 seconds, loss -0.025853669860999337\n",
      "\n",
      "*************Epoch 5 Avrg Training loss -0.02582549544037931 Elapsed 575.792717218399\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.782291291651666\n",
      "************* Validation: total 99996 precision 0.968898755950238 avgTime 0.006452718934200636\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 6 started at 1619465438.9172044\n",
      "trained 16 images, use 1.4971067905426025 seconds, loss -0.019314477685838938\n",
      "\n",
      "trained 816 images, use 5.165174961090088 seconds, loss -0.031060357759892774\n",
      "\n",
      "trained 1616 images, use 10.153250932693481 seconds, loss -0.02791648755529048\n",
      "\n",
      "trained 2416 images, use 14.148023128509521 seconds, loss -0.028015987391319486\n",
      "\n",
      "trained 3216 images, use 18.413860082626343 seconds, loss -0.027260983573724654\n",
      "\n",
      "trained 4016 images, use 22.85670828819275 seconds, loss -0.026852893982005112\n",
      "\n",
      "trained 4816 images, use 26.85520601272583 seconds, loss -0.02583975074588468\n",
      "\n",
      "trained 5616 images, use 31.461803913116455 seconds, loss -0.025663435442089103\n",
      "\n",
      "trained 6416 images, use 36.07581162452698 seconds, loss -0.026728221750927695\n",
      "\n",
      "trained 7216 images, use 40.18474268913269 seconds, loss -0.026010245334491307\n",
      "\n",
      "trained 8016 images, use 44.97182321548462 seconds, loss -0.02591763127961042\n",
      "\n",
      "trained 8816 images, use 49.185575008392334 seconds, loss -0.025809346019609686\n",
      "\n",
      "trained 9616 images, use 53.90739846229553 seconds, loss -0.025456676683793783\n",
      "\n",
      "trained 10416 images, use 58.72439885139465 seconds, loss -0.02541678376099332\n",
      "\n",
      "trained 11216 images, use 63.60432147979736 seconds, loss -0.02577657435023265\n",
      "\n",
      "trained 12016 images, use 68.08347702026367 seconds, loss -0.02624304502648769\n",
      "\n",
      "trained 12816 images, use 73.1553418636322 seconds, loss -0.02648388875037934\n",
      "\n",
      "trained 13616 images, use 77.35583090782166 seconds, loss -0.026753864514730295\n",
      "\n",
      "trained 14416 images, use 81.79654908180237 seconds, loss -0.026705950746945584\n",
      "\n",
      "trained 15216 images, use 86.5694432258606 seconds, loss -0.026334082725453917\n",
      "\n",
      "trained 16016 images, use 90.7591781616211 seconds, loss -0.026594941335162672\n",
      "\n",
      "trained 16816 images, use 95.4477972984314 seconds, loss -0.02668853931807275\n",
      "\n",
      "trained 17616 images, use 99.72814083099365 seconds, loss -0.027040024860493405\n",
      "\n",
      "trained 18416 images, use 104.11361956596375 seconds, loss -0.02728055368994041\n",
      "\n",
      "trained 19216 images, use 108.83980512619019 seconds, loss -0.027370458889498923\n",
      "\n",
      "trained 20016 images, use 113.00103402137756 seconds, loss -0.027310725161797902\n",
      "\n",
      "trained 20816 images, use 117.71868777275085 seconds, loss -0.027294471114488572\n",
      "\n",
      "trained 21616 images, use 122.01208734512329 seconds, loss -0.027478682138471468\n",
      "\n",
      "trained 22416 images, use 126.3811993598938 seconds, loss -0.02744031191028864\n",
      "\n",
      "trained 23216 images, use 131.29390621185303 seconds, loss -0.02741402173942133\n",
      "\n",
      "trained 24016 images, use 135.78915524482727 seconds, loss -0.027138245998938416\n",
      "\n",
      "trained 24816 images, use 140.6906168460846 seconds, loss -0.027247469585488748\n",
      "\n",
      "trained 25616 images, use 145.35519003868103 seconds, loss -0.0270949942261993\n",
      "\n",
      "trained 26416 images, use 149.74553537368774 seconds, loss -0.027196380157018314\n",
      "\n",
      "trained 27216 images, use 154.429340839386 seconds, loss -0.027388418189435174\n",
      "\n",
      "trained 28016 images, use 158.59766840934753 seconds, loss -0.0274473900092123\n",
      "\n",
      "trained 28816 images, use 163.23038935661316 seconds, loss -0.02752103028292827\n",
      "\n",
      "trained 29616 images, use 167.94495582580566 seconds, loss -0.027479660302855313\n",
      "\n",
      "trained 30416 images, use 172.13318014144897 seconds, loss -0.027523701640618656\n",
      "\n",
      "trained 31216 images, use 177.15692520141602 seconds, loss -0.027513987610869907\n",
      "\n",
      "trained 32016 images, use 181.4573175907135 seconds, loss -0.02749795620782463\n",
      "\n",
      "trained 32816 images, use 185.67483949661255 seconds, loss -0.027399019967594574\n",
      "\n",
      "trained 33616 images, use 190.32421588897705 seconds, loss -0.027211831672967438\n",
      "\n",
      "trained 34416 images, use 194.95708870887756 seconds, loss -0.02708694766960228\n",
      "\n",
      "trained 35216 images, use 199.63787603378296 seconds, loss -0.027013164715740057\n",
      "\n",
      "trained 36016 images, use 203.64814043045044 seconds, loss -0.02706827440468641\n",
      "\n",
      "trained 36816 images, use 208.16713404655457 seconds, loss -0.027192427845044234\n",
      "\n",
      "trained 37616 images, use 212.58009576797485 seconds, loss -0.02706289570947901\n",
      "\n",
      "trained 38416 images, use 217.12477946281433 seconds, loss -0.027161072214686017\n",
      "\n",
      "trained 39216 images, use 221.4179129600525 seconds, loss -0.027294362255449473\n",
      "\n",
      "trained 40016 images, use 226.48412561416626 seconds, loss -0.027302014893765294\n",
      "\n",
      "trained 40816 images, use 230.58094477653503 seconds, loss -0.027294211964948384\n",
      "\n",
      "trained 41616 images, use 235.4236102104187 seconds, loss -0.027258231100010445\n",
      "\n",
      "trained 42416 images, use 240.03113079071045 seconds, loss -0.02732363537225271\n",
      "\n",
      "trained 43216 images, use 243.9078598022461 seconds, loss -0.027249905945953504\n",
      "\n",
      "trained 44016 images, use 248.93752789497375 seconds, loss -0.027336498400579334\n",
      "\n",
      "trained 44816 images, use 253.30298161506653 seconds, loss -0.02738675565944529\n",
      "\n",
      "trained 45616 images, use 257.8450756072998 seconds, loss -0.027585884079780826\n",
      "\n",
      "trained 46416 images, use 262.6626784801483 seconds, loss -0.027639736213664768\n",
      "\n",
      "trained 47216 images, use 267.3285014629364 seconds, loss -0.02754245680778653\n",
      "\n",
      "trained 48016 images, use 271.8898985385895 seconds, loss -0.02772671566521425\n",
      "\n",
      "trained 48816 images, use 276.5666275024414 seconds, loss -0.027763730262558895\n",
      "\n",
      "trained 49616 images, use 281.42235255241394 seconds, loss -0.0276307381502338\n",
      "\n",
      "trained 50416 images, use 285.7411296367645 seconds, loss -0.02769378625259833\n",
      "\n",
      "trained 51216 images, use 290.6854350566864 seconds, loss -0.0276673525285526\n",
      "\n",
      "trained 52016 images, use 295.1438193321228 seconds, loss -0.027670874230520722\n",
      "\n",
      "trained 52816 images, use 299.6389751434326 seconds, loss -0.02761466929518189\n",
      "\n",
      "trained 53616 images, use 303.960351228714 seconds, loss -0.027551972924806552\n",
      "\n",
      "trained 54416 images, use 308.4194827079773 seconds, loss -0.027575778144313546\n",
      "\n",
      "trained 55216 images, use 312.72378301620483 seconds, loss -0.027523608452807127\n",
      "\n",
      "trained 56016 images, use 317.3095738887787 seconds, loss -0.02757919542562549\n",
      "\n",
      "trained 56816 images, use 321.70170187950134 seconds, loss -0.027531516179860743\n",
      "\n",
      "trained 57616 images, use 326.56007385253906 seconds, loss -0.027459348941941887\n",
      "\n",
      "trained 58416 images, use 330.79296350479126 seconds, loss -0.027510196268172898\n",
      "\n",
      "trained 59216 images, use 335.1699285507202 seconds, loss -0.027508545561110574\n",
      "\n",
      "trained 60016 images, use 340.27149271965027 seconds, loss -0.027539176434441207\n",
      "\n",
      "trained 60816 images, use 344.3882808685303 seconds, loss -0.027566753857582695\n",
      "\n",
      "trained 61616 images, use 348.875141620636 seconds, loss -0.027540463528041417\n",
      "\n",
      "trained 62416 images, use 354.09015250205994 seconds, loss -0.027576090695498115\n",
      "\n",
      "trained 63216 images, use 359.1478590965271 seconds, loss -0.027675268314837066\n",
      "\n",
      "trained 64016 images, use 363.9568154811859 seconds, loss -0.02775282095269332\n",
      "\n",
      "trained 64816 images, use 368.25016713142395 seconds, loss -0.027746902757570663\n",
      "\n",
      "trained 65616 images, use 372.8973627090454 seconds, loss -0.02775787149287027\n",
      "\n",
      "trained 66416 images, use 377.55541825294495 seconds, loss -0.027700570543838263\n",
      "\n",
      "trained 67216 images, use 382.079487323761 seconds, loss -0.027660215623372057\n",
      "\n",
      "trained 68016 images, use 387.03893089294434 seconds, loss -0.027634596013396358\n",
      "\n",
      "trained 68816 images, use 391.53078508377075 seconds, loss -0.027653394092582936\n",
      "\n",
      "trained 69616 images, use 395.9447820186615 seconds, loss -0.02767522955747444\n",
      "\n",
      "trained 70416 images, use 401.32593393325806 seconds, loss -0.02774562710220656\n",
      "\n",
      "trained 71216 images, use 405.40923047065735 seconds, loss -0.02779508893238498\n",
      "\n",
      "trained 72016 images, use 410.07288217544556 seconds, loss -0.027848854998309986\n",
      "\n",
      "trained 72816 images, use 414.19760036468506 seconds, loss -0.027847697985520135\n",
      "\n",
      "trained 73616 images, use 419.0242202281952 seconds, loss -0.027898930616766272\n",
      "\n",
      "trained 74416 images, use 423.3582673072815 seconds, loss -0.027882931193038325\n",
      "\n",
      "trained 75216 images, use 428.3150041103363 seconds, loss -0.027859059826397095\n",
      "\n",
      "trained 76016 images, use 432.6214053630829 seconds, loss -0.0277677667016529\n",
      "\n",
      "trained 76816 images, use 437.35500049591064 seconds, loss -0.027748513273594306\n",
      "\n",
      "trained 77616 images, use 441.6752486228943 seconds, loss -0.02762931998653857\n",
      "\n",
      "trained 78416 images, use 446.36920523643494 seconds, loss -0.027571754937728257\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 450.9960563182831 seconds, loss -0.02756615652068635\n",
      "\n",
      "trained 80016 images, use 455.94584679603577 seconds, loss -0.027575056001969193\n",
      "\n",
      "trained 80816 images, use 460.1220672130585 seconds, loss -0.027493057496690974\n",
      "\n",
      "trained 81616 images, use 464.7276952266693 seconds, loss -0.027603935225844447\n",
      "\n",
      "trained 82416 images, use 469.4644901752472 seconds, loss -0.027623949040594162\n",
      "\n",
      "trained 83216 images, use 474.3327555656433 seconds, loss -0.02760599741172181\n",
      "\n",
      "trained 84016 images, use 478.8148863315582 seconds, loss -0.027589311989663017\n",
      "\n",
      "trained 84816 images, use 483.4686806201935 seconds, loss -0.02758544314980372\n",
      "\n",
      "trained 85616 images, use 487.94203186035156 seconds, loss -0.027602729217233432\n",
      "\n",
      "trained 86416 images, use 492.60308361053467 seconds, loss -0.027543525305683794\n",
      "\n",
      "trained 87216 images, use 497.08562183380127 seconds, loss -0.027557294347747455\n",
      "\n",
      "trained 88016 images, use 501.70414996147156 seconds, loss -0.027634479864425066\n",
      "\n",
      "trained 88816 images, use 506.06854271888733 seconds, loss -0.02761385001567632\n",
      "\n",
      "trained 89616 images, use 510.3698136806488 seconds, loss -0.02764793213168941\n",
      "\n",
      "trained 90416 images, use 514.7334861755371 seconds, loss -0.027660845335088512\n",
      "\n",
      "trained 91216 images, use 519.246071100235 seconds, loss -0.027627756348361485\n",
      "\n",
      "trained 92016 images, use 524.1782414913177 seconds, loss -0.02762506156400665\n",
      "\n",
      "trained 92816 images, use 528.6890211105347 seconds, loss -0.027635560344473887\n",
      "\n",
      "trained 93616 images, use 532.98672747612 seconds, loss -0.027572507574457877\n",
      "\n",
      "trained 94416 images, use 537.4924268722534 seconds, loss -0.027559953336359827\n",
      "\n",
      "trained 95216 images, use 542.5332543849945 seconds, loss -0.027501902524073203\n",
      "\n",
      "trained 96016 images, use 546.5685954093933 seconds, loss -0.027487731282616272\n",
      "\n",
      "trained 96816 images, use 551.059333562851 seconds, loss -0.027478511836289122\n",
      "\n",
      "trained 97616 images, use 555.7810707092285 seconds, loss -0.027368565458151774\n",
      "\n",
      "trained 98416 images, use 560.1742432117462 seconds, loss -0.027423220979636054\n",
      "\n",
      "trained 99216 images, use 564.5708456039429 seconds, loss -0.027417669175782186\n",
      "\n",
      "*************Epoch 6 Avrg Training loss -0.02745571994987913 Elapsed 568.7684636116028\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.78388135525421\n",
      "************* Validation: total 99996 precision 0.9691259078934585 avgTime 0.005712458439228835\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 7 started at 1619466579.2896016\n",
      "trained 16 images, use 1.4034509658813477 seconds, loss 0.0381492264168628\n",
      "\n",
      "trained 816 images, use 4.995020151138306 seconds, loss -0.016411547787216617\n",
      "\n",
      "trained 1616 images, use 9.602618932723999 seconds, loss -0.02007259507188471\n",
      "\n",
      "trained 2416 images, use 13.955813884735107 seconds, loss -0.023438544985597935\n",
      "\n",
      "trained 3216 images, use 17.86880850791931 seconds, loss -0.025538612994507888\n",
      "\n",
      "trained 4016 images, use 22.17985200881958 seconds, loss -0.02637079578820819\n",
      "\n",
      "trained 4816 images, use 26.451919078826904 seconds, loss -0.026058456867306914\n",
      "\n",
      "trained 5616 images, use 30.729507207870483 seconds, loss -0.02631707584755945\n",
      "\n",
      "trained 6416 images, use 35.43100190162659 seconds, loss -0.026346953260253398\n",
      "\n",
      "trained 7216 images, use 39.72015023231506 seconds, loss -0.02688497403518888\n",
      "\n",
      "trained 8016 images, use 43.88179636001587 seconds, loss -0.027302850255207785\n",
      "\n",
      "trained 8816 images, use 48.59350609779358 seconds, loss -0.02641187959767998\n",
      "\n",
      "trained 9616 images, use 52.53585362434387 seconds, loss -0.027116516562306556\n",
      "\n",
      "trained 10416 images, use 56.97674775123596 seconds, loss -0.026685377747386725\n",
      "\n",
      "trained 11216 images, use 61.27235960960388 seconds, loss -0.02729943543701479\n",
      "\n",
      "trained 12016 images, use 65.38174605369568 seconds, loss -0.027337250412606505\n",
      "\n",
      "trained 12816 images, use 69.92801284790039 seconds, loss -0.027657130755014667\n",
      "\n",
      "trained 13616 images, use 73.83674764633179 seconds, loss -0.027994700727612978\n",
      "\n",
      "trained 14416 images, use 78.2270233631134 seconds, loss -0.02804982350342656\n",
      "\n",
      "trained 15216 images, use 82.62423253059387 seconds, loss -0.02841895322644594\n",
      "\n",
      "trained 16016 images, use 87.35736608505249 seconds, loss -0.02801540428566943\n",
      "\n",
      "trained 16816 images, use 91.56258225440979 seconds, loss -0.0278592210157139\n",
      "\n",
      "trained 17616 images, use 95.72193217277527 seconds, loss -0.02806244813060822\n",
      "\n",
      "trained 18416 images, use 99.9563524723053 seconds, loss -0.0278826974024816\n",
      "\n",
      "trained 19216 images, use 104.11227989196777 seconds, loss -0.028174507533193706\n",
      "\n",
      "trained 20016 images, use 108.84664368629456 seconds, loss -0.028238796625170252\n",
      "\n",
      "trained 20816 images, use 112.9320216178894 seconds, loss -0.028224254925990736\n",
      "\n",
      "trained 21616 images, use 117.71901845932007 seconds, loss -0.02808201557680677\n",
      "\n",
      "trained 22416 images, use 121.95262026786804 seconds, loss -0.027930412686056633\n",
      "\n",
      "trained 23216 images, use 126.64084148406982 seconds, loss -0.027892444736769616\n",
      "\n",
      "trained 24016 images, use 131.18416333198547 seconds, loss -0.027843685868415118\n",
      "\n",
      "trained 24816 images, use 135.3995599746704 seconds, loss -0.027844534395888347\n",
      "\n",
      "trained 25616 images, use 140.39038610458374 seconds, loss -0.0277866954388963\n",
      "\n",
      "trained 26416 images, use 144.63724064826965 seconds, loss -0.028036853925372817\n",
      "\n",
      "trained 27216 images, use 149.444926738739 seconds, loss -0.028031520074274605\n",
      "\n",
      "trained 28016 images, use 154.02685022354126 seconds, loss -0.02799839614189312\n",
      "\n",
      "trained 28816 images, use 158.25497674942017 seconds, loss -0.027969044207565175\n",
      "\n",
      "trained 29616 images, use 163.13032913208008 seconds, loss -0.02813189149664028\n",
      "\n",
      "trained 30416 images, use 167.85419535636902 seconds, loss -0.028097116750118417\n",
      "\n",
      "trained 31216 images, use 172.1269953250885 seconds, loss -0.0279955091636471\n",
      "\n",
      "trained 32016 images, use 176.92406272888184 seconds, loss -0.028087489378579193\n",
      "\n",
      "trained 32816 images, use 180.97280049324036 seconds, loss -0.02806559129506987\n",
      "\n",
      "trained 33616 images, use 185.06611108779907 seconds, loss -0.028112119949025554\n",
      "\n",
      "trained 34416 images, use 190.08129858970642 seconds, loss -0.0278867754109714\n",
      "\n",
      "trained 35216 images, use 194.39288997650146 seconds, loss -0.027956929922457047\n",
      "\n",
      "trained 36016 images, use 198.5975363254547 seconds, loss -0.028067332408018838\n",
      "\n",
      "trained 36816 images, use 203.03297758102417 seconds, loss -0.028292185687866504\n",
      "\n",
      "trained 37616 images, use 207.62306666374207 seconds, loss -0.028205950426826082\n",
      "\n",
      "trained 38416 images, use 212.07394909858704 seconds, loss -0.028343712911037808\n",
      "\n",
      "trained 39216 images, use 216.648273229599 seconds, loss -0.028394434446771904\n",
      "\n",
      "trained 40016 images, use 220.77913069725037 seconds, loss -0.02834206354626419\n",
      "\n",
      "trained 40816 images, use 225.49404096603394 seconds, loss -0.028257515255625858\n",
      "\n",
      "trained 41616 images, use 229.87772393226624 seconds, loss -0.028460587747994426\n",
      "\n",
      "trained 42416 images, use 234.75830960273743 seconds, loss -0.028466336467133382\n",
      "\n",
      "trained 43216 images, use 239.28956127166748 seconds, loss -0.02850448296844927\n",
      "\n",
      "trained 44016 images, use 243.93771958351135 seconds, loss -0.02846256783565222\n",
      "\n",
      "trained 44816 images, use 248.8709192276001 seconds, loss -0.02844525900318714\n",
      "\n",
      "trained 45616 images, use 253.00328373908997 seconds, loss -0.028331272355052284\n",
      "\n",
      "trained 46416 images, use 257.4573726654053 seconds, loss -0.028159981645678407\n",
      "\n",
      "trained 47216 images, use 262.0572257041931 seconds, loss -0.028184969632302468\n",
      "\n",
      "trained 48016 images, use 266.43150210380554 seconds, loss -0.028217741964214088\n",
      "\n",
      "trained 48816 images, use 271.1543779373169 seconds, loss -0.028199448348314726\n",
      "\n",
      "trained 49616 images, use 276.2215049266815 seconds, loss -0.028285065025906324\n",
      "\n",
      "trained 50416 images, use 280.9119851589203 seconds, loss -0.028338566369064275\n",
      "\n",
      "trained 51216 images, use 285.3978600502014 seconds, loss -0.02829517197368603\n",
      "\n",
      "trained 52016 images, use 289.86993193626404 seconds, loss -0.028395819364469343\n",
      "\n",
      "trained 52816 images, use 294.32833790779114 seconds, loss -0.028311473815588236\n",
      "\n",
      "trained 53616 images, use 299.0019516944885 seconds, loss -0.028208796869793613\n",
      "\n",
      "trained 54416 images, use 303.29036808013916 seconds, loss -0.028265765458548624\n",
      "\n",
      "trained 55216 images, use 307.85775899887085 seconds, loss -0.02826984566879033\n",
      "\n",
      "trained 56016 images, use 312.3389472961426 seconds, loss -0.028225068635446042\n",
      "\n",
      "trained 56816 images, use 317.1213264465332 seconds, loss -0.028253628123067257\n",
      "\n",
      "trained 57616 images, use 321.78368043899536 seconds, loss -0.028217576022949196\n",
      "\n",
      "trained 58416 images, use 326.7488350868225 seconds, loss -0.0282450096365307\n",
      "\n",
      "trained 59216 images, use 330.9941301345825 seconds, loss -0.028243457112904703\n",
      "\n",
      "trained 60016 images, use 335.7306966781616 seconds, loss -0.028161560640449414\n",
      "\n",
      "trained 60816 images, use 340.23772048950195 seconds, loss -0.02823065324422918\n",
      "\n",
      "trained 61616 images, use 345.30426812171936 seconds, loss -0.028237909353370255\n",
      "\n",
      "trained 62416 images, use 349.8901426792145 seconds, loss -0.028206662238715666\n",
      "\n",
      "trained 63216 images, use 354.65714597702026 seconds, loss -0.028188816861400526\n",
      "\n",
      "trained 64016 images, use 359.6442370414734 seconds, loss -0.028118085506591433\n",
      "\n",
      "trained 64816 images, use 364.20921325683594 seconds, loss -0.028128272030095897\n",
      "\n",
      "trained 65616 images, use 368.8780291080475 seconds, loss -0.028174155341959547\n",
      "\n",
      "trained 66416 images, use 373.763188123703 seconds, loss -0.028082546041171094\n",
      "\n",
      "trained 67216 images, use 378.3820769786835 seconds, loss -0.028031553670038307\n",
      "\n",
      "trained 68016 images, use 382.8671760559082 seconds, loss -0.028071914341103215\n",
      "\n",
      "trained 68816 images, use 387.4323036670685 seconds, loss -0.028069626155235897\n",
      "\n",
      "trained 69616 images, use 392.6209545135498 seconds, loss -0.028085010328077604\n",
      "\n",
      "trained 70416 images, use 397.0045998096466 seconds, loss -0.028090392366399784\n",
      "\n",
      "trained 71216 images, use 401.5573856830597 seconds, loss -0.028069561689516593\n",
      "\n",
      "trained 72016 images, use 405.73709630966187 seconds, loss -0.02805164146788547\n",
      "\n",
      "trained 72816 images, use 410.16815423965454 seconds, loss -0.02811393238585309\n",
      "\n",
      "trained 73616 images, use 414.6391520500183 seconds, loss -0.02814768686367836\n",
      "\n",
      "trained 74416 images, use 419.5306656360626 seconds, loss -0.02823956438015672\n",
      "\n",
      "trained 75216 images, use 423.90840458869934 seconds, loss -0.02825102472824244\n",
      "\n",
      "trained 76016 images, use 428.57225275039673 seconds, loss -0.0282511613162447\n",
      "\n",
      "trained 76816 images, use 433.4022421836853 seconds, loss -0.028198083981804796\n",
      "\n",
      "trained 77616 images, use 438.2611780166626 seconds, loss -0.02821854304648667\n",
      "\n",
      "trained 78416 images, use 443.2181673049927 seconds, loss -0.028141429248779853\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 447.6905539035797 seconds, loss -0.028193158401386177\n",
      "\n",
      "trained 80016 images, use 452.5872790813446 seconds, loss -0.028196471142764596\n",
      "\n",
      "trained 80816 images, use 457.25717067718506 seconds, loss -0.02825015061588679\n",
      "\n",
      "trained 81616 images, use 462.330406665802 seconds, loss -0.02828659496291149\n",
      "\n",
      "trained 82416 images, use 467.13938188552856 seconds, loss -0.028301661835506704\n",
      "\n",
      "trained 83216 images, use 471.3018808364868 seconds, loss -0.02833035677392621\n",
      "\n",
      "trained 84016 images, use 476.1698226928711 seconds, loss -0.028289853498819163\n",
      "\n",
      "trained 84816 images, use 480.8119456768036 seconds, loss -0.028318973841051247\n",
      "\n",
      "trained 85616 images, use 485.7782862186432 seconds, loss -0.028335001740257378\n",
      "\n",
      "trained 86416 images, use 490.1796193122864 seconds, loss -0.02841062223812458\n",
      "\n",
      "trained 87216 images, use 494.6741545200348 seconds, loss -0.028407036520810062\n",
      "\n",
      "trained 88016 images, use 499.64514112472534 seconds, loss -0.028465633896290296\n",
      "\n",
      "trained 88816 images, use 504.54465794563293 seconds, loss -0.02839556672930676\n",
      "\n",
      "trained 89616 images, use 508.93069195747375 seconds, loss -0.02835774338665857\n",
      "\n",
      "trained 90416 images, use 513.7757527828217 seconds, loss -0.028404387650253455\n",
      "\n",
      "trained 91216 images, use 518.0106103420258 seconds, loss -0.02840934338524578\n",
      "\n",
      "trained 92016 images, use 523.4242124557495 seconds, loss -0.02843350852909096\n",
      "\n",
      "trained 92816 images, use 528.0723128318787 seconds, loss -0.028485340523584035\n",
      "\n",
      "trained 93616 images, use 532.4272747039795 seconds, loss -0.02854526805703635\n",
      "\n",
      "trained 94416 images, use 537.2896015644073 seconds, loss -0.028491380138020717\n",
      "\n",
      "trained 95216 images, use 541.714387178421 seconds, loss -0.028549758751136408\n",
      "\n",
      "trained 96016 images, use 546.7610924243927 seconds, loss -0.02857654772754824\n",
      "\n",
      "trained 96816 images, use 551.2362544536591 seconds, loss -0.028604360498112165\n",
      "\n",
      "trained 97616 images, use 555.9203100204468 seconds, loss -0.0285757470877917\n",
      "\n",
      "trained 98416 images, use 561.1176233291626 seconds, loss -0.028602145151837566\n",
      "\n",
      "trained 99216 images, use 566.2345180511475 seconds, loss -0.02860993781251305\n",
      "\n",
      "*************Epoch 7 Avrg Training loss -0.02861607086715638 Elapsed 570.3775553703308\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.784121364854594\n",
      "************* Validation: total 99996 precision 0.9691601949792278 avgTime 0.005751434936681372\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 8 started at 1619467725.3675642\n",
      "trained 16 images, use 1.7027957439422607 seconds, loss -0.04741908982396126\n",
      "\n",
      "trained 816 images, use 6.2812111377716064 seconds, loss -0.027078479569301914\n",
      "\n",
      "trained 1616 images, use 10.838730096817017 seconds, loss -0.0270213466389542\n",
      "\n",
      "trained 2416 images, use 15.930056095123291 seconds, loss -0.028752584866077468\n",
      "\n",
      "trained 3216 images, use 20.473485708236694 seconds, loss -0.030078771738042652\n",
      "\n",
      "trained 4016 images, use 25.290859699249268 seconds, loss -0.029715178079478783\n",
      "\n",
      "trained 4816 images, use 30.075589656829834 seconds, loss -0.02914623474739438\n",
      "\n",
      "trained 5616 images, use 34.50355911254883 seconds, loss -0.029365900850944048\n",
      "\n",
      "trained 6416 images, use 39.34705376625061 seconds, loss -0.030317824831727826\n",
      "\n",
      "trained 7216 images, use 43.75777554512024 seconds, loss -0.029649182798377006\n",
      "\n",
      "trained 8016 images, use 48.9093062877655 seconds, loss -0.029924215791753844\n",
      "\n",
      "trained 8816 images, use 53.52417278289795 seconds, loss -0.029782394213565818\n",
      "\n",
      "trained 9616 images, use 58.019694566726685 seconds, loss -0.029583016490010005\n",
      "\n",
      "trained 10416 images, use 62.41725492477417 seconds, loss -0.029956743055504515\n",
      "\n",
      "trained 11216 images, use 67.39450144767761 seconds, loss -0.03003592258542046\n",
      "\n",
      "trained 12016 images, use 71.93591165542603 seconds, loss -0.029639826259747128\n",
      "\n",
      "trained 12816 images, use 77.14595127105713 seconds, loss -0.02941435565501994\n",
      "\n",
      "trained 13616 images, use 81.58740305900574 seconds, loss -0.029240899045059148\n",
      "\n",
      "trained 14416 images, use 86.04332399368286 seconds, loss -0.029319367844239153\n",
      "\n",
      "trained 15216 images, use 90.8493583202362 seconds, loss -0.02949059758208298\n",
      "\n",
      "trained 16016 images, use 95.33991885185242 seconds, loss -0.02932890319993885\n",
      "\n",
      "trained 16816 images, use 99.71738648414612 seconds, loss -0.029527893230943108\n",
      "\n",
      "trained 17616 images, use 104.55167365074158 seconds, loss -0.02959733126351508\n",
      "\n",
      "trained 18416 images, use 109.6818618774414 seconds, loss -0.02962105693228602\n",
      "\n",
      "trained 19216 images, use 114.23446154594421 seconds, loss -0.029375458348285685\n",
      "\n",
      "trained 20016 images, use 119.06484293937683 seconds, loss -0.029086123669496675\n",
      "\n",
      "trained 20816 images, use 123.66728615760803 seconds, loss -0.028936060589641585\n",
      "\n",
      "trained 21616 images, use 128.05471563339233 seconds, loss -0.028971276684689747\n",
      "\n",
      "trained 22416 images, use 132.6239891052246 seconds, loss -0.029086645616033652\n",
      "\n",
      "trained 23216 images, use 136.82311916351318 seconds, loss -0.028876396190123308\n",
      "\n",
      "trained 24016 images, use 141.5331585407257 seconds, loss -0.028927915007583998\n",
      "\n",
      "trained 24816 images, use 146.10891222953796 seconds, loss -0.02892574437012887\n",
      "\n",
      "trained 25616 images, use 150.66656804084778 seconds, loss -0.028793814823130717\n",
      "\n",
      "trained 26416 images, use 155.01094007492065 seconds, loss -0.029022988628587973\n",
      "\n",
      "trained 27216 images, use 159.85590863227844 seconds, loss -0.028897243006733044\n",
      "\n",
      "trained 28016 images, use 164.44290828704834 seconds, loss -0.028847528647007768\n",
      "\n",
      "trained 28816 images, use 169.25802659988403 seconds, loss -0.028903057301033125\n",
      "\n",
      "trained 29616 images, use 173.59515404701233 seconds, loss -0.028913738558895202\n",
      "\n",
      "trained 30416 images, use 178.56109285354614 seconds, loss -0.02867644880799907\n",
      "\n",
      "trained 31216 images, use 183.4534044265747 seconds, loss -0.02874948624688278\n",
      "\n",
      "trained 32016 images, use 187.84353709220886 seconds, loss -0.028980525475301736\n",
      "\n",
      "trained 32816 images, use 192.36148357391357 seconds, loss -0.029107195660035216\n",
      "\n",
      "trained 33616 images, use 196.9657108783722 seconds, loss -0.02936541777254971\n",
      "\n",
      "trained 34416 images, use 201.57414555549622 seconds, loss -0.029214461509676635\n",
      "\n",
      "trained 35216 images, use 206.07864117622375 seconds, loss -0.029175969149782287\n",
      "\n",
      "trained 36016 images, use 211.08428859710693 seconds, loss -0.029213199175747107\n",
      "\n",
      "trained 36816 images, use 215.5551724433899 seconds, loss -0.029096611547233756\n",
      "\n",
      "trained 37616 images, use 219.89940452575684 seconds, loss -0.029235080396324248\n",
      "\n",
      "trained 38416 images, use 224.0887496471405 seconds, loss -0.02937867637595197\n",
      "\n",
      "trained 39216 images, use 228.81443214416504 seconds, loss -0.029156750887717037\n",
      "\n",
      "trained 40016 images, use 233.94746136665344 seconds, loss -0.029213894682703172\n",
      "\n",
      "trained 40816 images, use 238.11691999435425 seconds, loss -0.02910423380939485\n",
      "\n",
      "trained 41616 images, use 243.22528529167175 seconds, loss -0.029276558546863556\n",
      "\n",
      "trained 42416 images, use 248.06947469711304 seconds, loss -0.029319978205258578\n",
      "\n",
      "trained 43216 images, use 252.90684127807617 seconds, loss -0.029234843518217906\n",
      "\n",
      "trained 44016 images, use 257.6283781528473 seconds, loss -0.02908898582454455\n",
      "\n",
      "trained 44816 images, use 262.40217876434326 seconds, loss -0.02902390525574631\n",
      "\n",
      "trained 45616 images, use 266.8670036792755 seconds, loss -0.029002096559082105\n",
      "\n",
      "trained 46416 images, use 271.12530422210693 seconds, loss -0.028879578611702095\n",
      "\n",
      "trained 47216 images, use 276.0323419570923 seconds, loss -0.028807420330262633\n",
      "\n",
      "trained 48016 images, use 280.7656147480011 seconds, loss -0.028792554124911652\n",
      "\n",
      "trained 48816 images, use 284.9036166667938 seconds, loss -0.028794294899270823\n",
      "\n",
      "trained 49616 images, use 289.8680591583252 seconds, loss -0.028906633250672113\n",
      "\n",
      "trained 50416 images, use 294.5754268169403 seconds, loss -0.02895949828234936\n",
      "\n",
      "trained 51216 images, use 299.13008666038513 seconds, loss -0.028948679847616336\n",
      "\n",
      "trained 52016 images, use 303.65076303482056 seconds, loss -0.028897630578776142\n",
      "\n",
      "trained 52816 images, use 308.47813153266907 seconds, loss -0.028829519512117\n",
      "\n",
      "trained 53616 images, use 313.59485149383545 seconds, loss -0.028649096925770227\n",
      "\n",
      "trained 54416 images, use 317.7840099334717 seconds, loss -0.028599375313282435\n",
      "\n",
      "trained 55216 images, use 322.79245948791504 seconds, loss -0.0286038673963484\n",
      "\n",
      "trained 56016 images, use 326.96138191223145 seconds, loss -0.028631693907417356\n",
      "\n",
      "trained 56816 images, use 331.64656805992126 seconds, loss -0.02862541196512325\n",
      "\n",
      "trained 57616 images, use 336.1863830089569 seconds, loss -0.028526358531551547\n",
      "\n",
      "trained 58416 images, use 340.93566608428955 seconds, loss -0.028492433670835343\n",
      "\n",
      "trained 59216 images, use 345.3253734111786 seconds, loss -0.02852141012221627\n",
      "\n",
      "trained 60016 images, use 350.26461935043335 seconds, loss -0.028495117298287947\n",
      "\n",
      "trained 60816 images, use 355.0709798336029 seconds, loss -0.02855222641844386\n",
      "\n",
      "trained 61616 images, use 360.0794486999512 seconds, loss -0.028527001885740214\n",
      "\n",
      "trained 62416 images, use 364.49491024017334 seconds, loss -0.028535600132935178\n",
      "\n",
      "trained 63216 images, use 369.758496761322 seconds, loss -0.028488270529602865\n",
      "\n",
      "trained 64016 images, use 374.3944742679596 seconds, loss -0.028536433734545587\n",
      "\n",
      "trained 64816 images, use 379.4089455604553 seconds, loss -0.028619605220355032\n",
      "\n",
      "trained 65616 images, use 383.9765167236328 seconds, loss -0.028610235799394573\n",
      "\n",
      "trained 66416 images, use 388.6030879020691 seconds, loss -0.028646432254337995\n",
      "\n",
      "trained 67216 images, use 393.26059889793396 seconds, loss -0.02862129390054703\n",
      "\n",
      "trained 68016 images, use 397.7637801170349 seconds, loss -0.02863613220839508\n",
      "\n",
      "trained 68816 images, use 402.51237964630127 seconds, loss -0.028572146466933734\n",
      "\n",
      "trained 69616 images, use 406.7879819869995 seconds, loss -0.028540173264861163\n",
      "\n",
      "trained 70416 images, use 411.99164175987244 seconds, loss -0.028512290844305285\n",
      "\n",
      "trained 71216 images, use 416.38010478019714 seconds, loss -0.028505197340377413\n",
      "\n",
      "trained 72016 images, use 420.68135023117065 seconds, loss -0.028492434567034312\n",
      "\n",
      "trained 72816 images, use 425.76365542411804 seconds, loss -0.02861405139988866\n",
      "\n",
      "trained 73616 images, use 430.27105140686035 seconds, loss -0.028666057506126958\n",
      "\n",
      "trained 74416 images, use 434.55907917022705 seconds, loss -0.02871624632688802\n",
      "\n",
      "trained 75216 images, use 439.0105834007263 seconds, loss -0.028758643502628457\n",
      "\n",
      "trained 76016 images, use 443.3642466068268 seconds, loss -0.028775558730100927\n",
      "\n",
      "trained 76816 images, use 447.7786295413971 seconds, loss -0.028802160147531206\n",
      "\n",
      "trained 77616 images, use 452.65676498413086 seconds, loss -0.02873188719857071\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 78416 images, use 457.3935389518738 seconds, loss -0.028758460711836905\n",
      "\n",
      "trained 79216 images, use 462.12729239463806 seconds, loss -0.02882499987581171\n",
      "\n",
      "trained 80016 images, use 466.3116044998169 seconds, loss -0.02874935738549141\n",
      "\n",
      "trained 80816 images, use 471.6494834423065 seconds, loss -0.028828304547116143\n",
      "\n",
      "trained 81616 images, use 475.84455156326294 seconds, loss -0.028799890356714083\n",
      "\n",
      "trained 82416 images, use 480.3361690044403 seconds, loss -0.028754479333112596\n",
      "\n",
      "trained 83216 images, use 485.72611236572266 seconds, loss -0.028729027498945913\n",
      "\n",
      "trained 84016 images, use 490.50288462638855 seconds, loss -0.028714070850743182\n",
      "\n",
      "trained 84816 images, use 495.68327713012695 seconds, loss -0.028805290698821966\n",
      "\n",
      "trained 85616 images, use 500.0829463005066 seconds, loss -0.02885421104597372\n",
      "\n",
      "trained 86416 images, use 504.29361295700073 seconds, loss -0.028916440032726778\n",
      "\n",
      "trained 87216 images, use 508.9952690601349 seconds, loss -0.028931307642251616\n",
      "\n",
      "trained 88016 images, use 513.5867528915405 seconds, loss -0.028999295977544904\n",
      "\n",
      "trained 88816 images, use 518.3227472305298 seconds, loss -0.02897878367825189\n",
      "\n",
      "trained 89616 images, use 522.5606851577759 seconds, loss -0.02907722012569127\n",
      "\n",
      "trained 90416 images, use 527.5608966350555 seconds, loss -0.029104175614430627\n",
      "\n",
      "trained 91216 images, use 532.0573024749756 seconds, loss -0.0291203173389026\n",
      "\n",
      "trained 92016 images, use 537.0750019550323 seconds, loss -0.029118222105700423\n",
      "\n",
      "trained 92816 images, use 541.5530104637146 seconds, loss -0.029128461919312308\n",
      "\n",
      "trained 93616 images, use 546.1347103118896 seconds, loss -0.029184421950252285\n",
      "\n",
      "trained 94416 images, use 550.426971912384 seconds, loss -0.02920490072618123\n",
      "\n",
      "trained 95216 images, use 555.284054517746 seconds, loss -0.0292315825005028\n",
      "\n",
      "trained 96016 images, use 559.9699556827545 seconds, loss -0.029291056578977098\n",
      "\n",
      "trained 96816 images, use 565.0045034885406 seconds, loss -0.02930347182649338\n",
      "\n",
      "trained 97616 images, use 569.7110633850098 seconds, loss -0.02940039322657813\n",
      "\n",
      "trained 98416 images, use 574.2318243980408 seconds, loss -0.02938506667686011\n",
      "\n",
      "trained 99216 images, use 578.885276556015 seconds, loss -0.029365296196636605\n",
      "\n",
      "*************Epoch 8 Avrg Training loss -0.02940279301557006 Elapsed 582.695737361908\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.784711388455539\n",
      "************* Validation: total 99996 precision 0.9692444840650769 avgTime 0.00568431228622207\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 9 started at 1619468877.0225995\n",
      "trained 16 images, use 1.554049015045166 seconds, loss -0.03673103079199791\n",
      "\n",
      "trained 816 images, use 5.414200067520142 seconds, loss -0.02138492304304516\n",
      "\n",
      "trained 1616 images, use 9.379917621612549 seconds, loss -0.02389721961332957\n",
      "\n",
      "trained 2416 images, use 14.149176359176636 seconds, loss -0.02374847458923724\n",
      "\n",
      "trained 3216 images, use 18.201938152313232 seconds, loss -0.026850432674222033\n",
      "\n",
      "trained 4016 images, use 22.355018854141235 seconds, loss -0.027477372441469\n",
      "\n",
      "trained 4816 images, use 26.638497352600098 seconds, loss -0.029249015054375792\n",
      "\n",
      "trained 5616 images, use 30.729841709136963 seconds, loss -0.029477217137153646\n",
      "\n",
      "trained 6416 images, use 35.11447286605835 seconds, loss -0.029762493768480204\n",
      "\n",
      "trained 7216 images, use 39.58793306350708 seconds, loss -0.029790525760830883\n",
      "\n",
      "trained 8016 images, use 43.83257722854614 seconds, loss -0.029722471243523643\n",
      "\n",
      "trained 8816 images, use 48.16523575782776 seconds, loss -0.029629475678998988\n",
      "\n",
      "trained 9616 images, use 52.549625396728516 seconds, loss -0.029730304866840872\n",
      "\n",
      "trained 10416 images, use 56.97960901260376 seconds, loss -0.02983198357725907\n",
      "\n",
      "trained 11216 images, use 61.28960037231445 seconds, loss -0.02964794209013175\n",
      "\n",
      "trained 12016 images, use 65.98837971687317 seconds, loss -0.030026399290379494\n",
      "\n",
      "trained 12816 images, use 70.06860208511353 seconds, loss -0.029456767348737846\n",
      "\n",
      "trained 13616 images, use 75.5208842754364 seconds, loss -0.02945342866486789\n",
      "\n",
      "trained 14416 images, use 80.29093766212463 seconds, loss -0.029165499180878886\n",
      "\n",
      "trained 15216 images, use 84.64660406112671 seconds, loss -0.029329812088408402\n",
      "\n",
      "trained 16016 images, use 89.42125225067139 seconds, loss -0.029138404126403082\n",
      "\n",
      "trained 16816 images, use 93.90791344642639 seconds, loss -0.0291226478943481\n",
      "\n",
      "trained 17616 images, use 98.40016484260559 seconds, loss -0.029186592172319795\n",
      "\n",
      "trained 18416 images, use 103.42312121391296 seconds, loss -0.0291966139557513\n",
      "\n",
      "trained 19216 images, use 108.27587699890137 seconds, loss -0.029020699225158823\n",
      "\n",
      "trained 20016 images, use 113.21349620819092 seconds, loss -0.02868784131306964\n",
      "\n",
      "trained 20816 images, use 117.97202754020691 seconds, loss -0.029015032147363198\n",
      "\n",
      "trained 21616 images, use 122.20107650756836 seconds, loss -0.028785418177134686\n",
      "\n",
      "trained 22416 images, use 127.16978693008423 seconds, loss -0.028689432259068795\n",
      "\n",
      "trained 23216 images, use 131.25745844841003 seconds, loss -0.028660872375641175\n",
      "\n",
      "trained 24016 images, use 135.80027604103088 seconds, loss -0.02900997785981582\n",
      "\n",
      "trained 24816 images, use 140.42376279830933 seconds, loss -0.028965100046257332\n",
      "\n",
      "trained 25616 images, use 145.067773103714 seconds, loss -0.028896725411282936\n",
      "\n",
      "trained 26416 images, use 149.84656524658203 seconds, loss -0.029036218050960176\n",
      "\n",
      "trained 27216 images, use 154.7831289768219 seconds, loss -0.029268236162237077\n",
      "\n",
      "trained 28016 images, use 159.42293071746826 seconds, loss -0.029228802496974935\n",
      "\n",
      "trained 28816 images, use 163.72694563865662 seconds, loss -0.029318566033206653\n",
      "\n",
      "trained 29616 images, use 168.564954996109 seconds, loss -0.02933167841395631\n",
      "\n",
      "trained 30416 images, use 173.5613670349121 seconds, loss -0.02938647354335444\n",
      "\n",
      "trained 31216 images, use 177.97093605995178 seconds, loss -0.02939933350659105\n",
      "\n",
      "trained 32016 images, use 182.42330288887024 seconds, loss -0.029418156136211796\n",
      "\n",
      "trained 32816 images, use 186.54512000083923 seconds, loss -0.02954104699853055\n",
      "\n",
      "trained 33616 images, use 191.5615575313568 seconds, loss -0.029536622587646846\n",
      "\n",
      "trained 34416 images, use 195.67130160331726 seconds, loss -0.029574418029363427\n",
      "\n",
      "trained 35216 images, use 199.8564794063568 seconds, loss -0.029675016729992648\n",
      "\n",
      "trained 36016 images, use 205.179354429245 seconds, loss -0.02962012143517587\n",
      "\n",
      "trained 36816 images, use 209.7966992855072 seconds, loss -0.02957517040986986\n",
      "\n",
      "trained 37616 images, use 214.32420945167542 seconds, loss -0.029659856292749615\n",
      "\n",
      "trained 38416 images, use 219.31843662261963 seconds, loss -0.029687125732685265\n",
      "\n",
      "trained 39216 images, use 223.23868775367737 seconds, loss -0.02979302927695861\n",
      "\n",
      "trained 40016 images, use 228.07726430892944 seconds, loss -0.029715912387689433\n",
      "\n",
      "trained 40816 images, use 232.5205798149109 seconds, loss -0.02981909557722734\n",
      "\n",
      "trained 41616 images, use 237.51897644996643 seconds, loss -0.0299371940765259\n",
      "\n",
      "trained 42416 images, use 241.64635944366455 seconds, loss -0.029981333905162992\n",
      "\n",
      "trained 43216 images, use 246.39364743232727 seconds, loss -0.029977164011993622\n",
      "\n",
      "trained 44016 images, use 251.18656635284424 seconds, loss -0.030063371429268373\n",
      "\n",
      "trained 44816 images, use 255.90368676185608 seconds, loss -0.0299450552822157\n",
      "\n",
      "trained 45616 images, use 260.1914279460907 seconds, loss -0.02989698819664964\n",
      "\n",
      "trained 46416 images, use 264.88420367240906 seconds, loss -0.029839119179275033\n",
      "\n",
      "trained 47216 images, use 269.6308698654175 seconds, loss -0.02991976816414915\n",
      "\n",
      "trained 48016 images, use 274.2826726436615 seconds, loss -0.030033388017660596\n",
      "\n",
      "trained 48816 images, use 279.38532066345215 seconds, loss -0.029854575266560268\n",
      "\n",
      "trained 49616 images, use 283.8823149204254 seconds, loss -0.029935292497727473\n",
      "\n",
      "trained 50416 images, use 289.25320315361023 seconds, loss -0.029932725881111556\n",
      "\n",
      "trained 51216 images, use 293.6985607147217 seconds, loss -0.029872619814697493\n",
      "\n",
      "trained 52016 images, use 298.7799837589264 seconds, loss -0.02988794866504418\n",
      "\n",
      "trained 52816 images, use 304.30355739593506 seconds, loss -0.02980054537487088\n",
      "\n",
      "trained 53616 images, use 309.1491231918335 seconds, loss -0.029792647529381062\n",
      "\n",
      "trained 54416 images, use 314.39551401138306 seconds, loss -0.029784349621831366\n",
      "\n",
      "trained 55216 images, use 319.25298285484314 seconds, loss -0.029793299173317227\n",
      "\n",
      "trained 56016 images, use 324.35714530944824 seconds, loss -0.02982807580572232\n",
      "\n",
      "trained 56816 images, use 328.8658652305603 seconds, loss -0.029763091989419076\n",
      "\n",
      "trained 57616 images, use 334.2047441005707 seconds, loss -0.0297877566683143\n",
      "\n",
      "trained 58416 images, use 338.7525851726532 seconds, loss -0.029740232592233965\n",
      "\n",
      "trained 59216 images, use 344.0113444328308 seconds, loss -0.029687616852595505\n",
      "\n",
      "trained 60016 images, use 348.0634608268738 seconds, loss -0.029707879504317528\n",
      "\n",
      "trained 60816 images, use 352.80222964286804 seconds, loss -0.029603138997482084\n",
      "\n",
      "trained 61616 images, use 357.51630663871765 seconds, loss -0.029708319137472124\n",
      "\n",
      "trained 62416 images, use 362.6242401599884 seconds, loss -0.029757350460834414\n",
      "\n",
      "trained 63216 images, use 366.8735911846161 seconds, loss -0.029832205655874248\n",
      "\n",
      "trained 64016 images, use 371.6136395931244 seconds, loss -0.02975647765583676\n",
      "\n",
      "trained 64816 images, use 375.82833313941956 seconds, loss -0.029756407033602918\n",
      "\n",
      "trained 65616 images, use 380.53046774864197 seconds, loss -0.029789350219332093\n",
      "\n",
      "trained 66416 images, use 385.2675566673279 seconds, loss -0.029809856253486377\n",
      "\n",
      "trained 67216 images, use 390.043963432312 seconds, loss -0.029701182203825283\n",
      "\n",
      "trained 68016 images, use 394.78666615486145 seconds, loss -0.02973130039751532\n",
      "\n",
      "trained 68816 images, use 399.72661781311035 seconds, loss -0.0297975659082695\n",
      "\n",
      "trained 69616 images, use 404.1112470626831 seconds, loss -0.02980721015668183\n",
      "\n",
      "trained 70416 images, use 409.22093439102173 seconds, loss -0.029828110447022715\n",
      "\n",
      "trained 71216 images, use 413.43159222602844 seconds, loss -0.029823613878213428\n",
      "\n",
      "trained 72016 images, use 418.62800121307373 seconds, loss -0.029770702391629572\n",
      "\n",
      "trained 72816 images, use 422.8046591281891 seconds, loss -0.029835376676622977\n",
      "\n",
      "trained 73616 images, use 427.23600602149963 seconds, loss -0.02993257911563849\n",
      "\n",
      "trained 74416 images, use 431.8405587673187 seconds, loss -0.029951090459912705\n",
      "\n",
      "trained 75216 images, use 436.01368498802185 seconds, loss -0.030055298622593707\n",
      "\n",
      "trained 76016 images, use 440.71367287635803 seconds, loss -0.030038565363400355\n",
      "\n",
      "trained 76816 images, use 444.99107122421265 seconds, loss -0.029969313094334333\n",
      "\n",
      "trained 77616 images, use 449.51433539390564 seconds, loss -0.029991426327272468\n",
      "\n",
      "trained 78416 images, use 453.47589468955994 seconds, loss -0.030068345085063973\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 457.948543548584 seconds, loss -0.03005501968851198\n",
      "\n",
      "trained 80016 images, use 462.57398295402527 seconds, loss -0.03003372197898142\n",
      "\n",
      "trained 80816 images, use 466.95521330833435 seconds, loss -0.030130473122745076\n",
      "\n",
      "trained 81616 images, use 472.11706614494324 seconds, loss -0.030193657946600772\n",
      "\n",
      "trained 82416 images, use 476.9968912601471 seconds, loss -0.03016478444213127\n",
      "\n",
      "trained 83216 images, use 481.8847818374634 seconds, loss -0.030131853300581695\n",
      "\n",
      "trained 84016 images, use 487.53297758102417 seconds, loss -0.030159734584310358\n",
      "\n",
      "trained 84816 images, use 493.2306525707245 seconds, loss -0.030225864545521862\n",
      "\n",
      "trained 85616 images, use 497.93556213378906 seconds, loss -0.030177030110027408\n",
      "\n",
      "trained 86416 images, use 502.91178488731384 seconds, loss -0.030195205288540774\n",
      "\n",
      "trained 87216 images, use 508.13645911216736 seconds, loss -0.0302128179494821\n",
      "\n",
      "trained 88016 images, use 513.0223937034607 seconds, loss -0.030186656810910203\n",
      "\n",
      "trained 88816 images, use 517.8559939861298 seconds, loss -0.030181545947195652\n",
      "\n",
      "trained 89616 images, use 523.5026395320892 seconds, loss -0.03020532989193003\n",
      "\n",
      "trained 90416 images, use 528.578617811203 seconds, loss -0.030237480963653602\n",
      "\n",
      "trained 91216 images, use 533.5359740257263 seconds, loss -0.030235391119443678\n",
      "\n",
      "trained 92016 images, use 538.7539081573486 seconds, loss -0.03025693860371933\n",
      "\n",
      "trained 92816 images, use 543.5339283943176 seconds, loss -0.03028334537493659\n",
      "\n",
      "trained 93616 images, use 548.3083009719849 seconds, loss -0.030299166516973067\n",
      "\n",
      "trained 94416 images, use 552.8628177642822 seconds, loss -0.030343968766657178\n",
      "\n",
      "trained 95216 images, use 557.8259706497192 seconds, loss -0.03034995194139382\n",
      "\n",
      "trained 96016 images, use 562.1099531650543 seconds, loss -0.030388115894316264\n",
      "\n",
      "trained 96816 images, use 567.5494277477264 seconds, loss -0.030355999071105425\n",
      "\n",
      "trained 97616 images, use 572.2239999771118 seconds, loss -0.030394806178995554\n",
      "\n",
      "trained 98416 images, use 577.0963234901428 seconds, loss -0.030355269565508283\n",
      "\n",
      "trained 99216 images, use 581.6981389522552 seconds, loss -0.030393169922471718\n",
      "\n",
      "*************Epoch 9 Avrg Training loss -0.0303495256755632 Elapsed 585.8020508289337\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.785751430057203\n",
      "************* Validation: total 99996 precision 0.9693930614367432 avgTime 0.005675316662820626\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 10 started at 1619470030.9116197\n",
      "trained 16 images, use 1.42850661277771 seconds, loss 0.002043015672825277\n",
      "\n",
      "trained 816 images, use 5.619229316711426 seconds, loss -0.023416033188718408\n",
      "\n",
      "trained 1616 images, use 9.927239179611206 seconds, loss -0.02045066740945057\n",
      "\n",
      "trained 2416 images, use 13.947385311126709 seconds, loss -0.024727204571191624\n",
      "\n",
      "trained 3216 images, use 18.425333976745605 seconds, loss -0.02745562507133589\n",
      "\n",
      "trained 4016 images, use 22.350926399230957 seconds, loss -0.027748589083799628\n",
      "\n",
      "trained 4816 images, use 27.052729606628418 seconds, loss -0.02708184413342787\n",
      "\n",
      "trained 5616 images, use 31.607714414596558 seconds, loss -0.028171777995347404\n",
      "\n",
      "trained 6416 images, use 35.7643518447876 seconds, loss -0.028448682791008085\n",
      "\n",
      "trained 7216 images, use 40.16362261772156 seconds, loss -0.02850909632760366\n",
      "\n",
      "trained 8016 images, use 44.52397632598877 seconds, loss -0.028770201345371088\n",
      "\n",
      "trained 8816 images, use 49.00480675697327 seconds, loss -0.028635342456595114\n",
      "\n",
      "trained 9616 images, use 53.04376268386841 seconds, loss -0.028542271734246255\n",
      "\n",
      "trained 10416 images, use 57.38978028297424 seconds, loss -0.028841390719650882\n",
      "\n",
      "trained 11216 images, use 61.47859001159668 seconds, loss -0.02862033206921255\n",
      "\n",
      "trained 12016 images, use 66.18985390663147 seconds, loss -0.028520729927113835\n",
      "\n",
      "trained 12816 images, use 70.81136727333069 seconds, loss -0.028701364880852703\n",
      "\n",
      "trained 13616 images, use 75.44319415092468 seconds, loss -0.029209687505368693\n",
      "\n",
      "trained 14416 images, use 80.67674207687378 seconds, loss -0.029451505612655384\n",
      "\n",
      "trained 15216 images, use 84.89281892776489 seconds, loss -0.029735437876584114\n",
      "\n",
      "trained 16016 images, use 89.0504789352417 seconds, loss -0.029692614107283546\n",
      "\n",
      "trained 16816 images, use 93.47497987747192 seconds, loss -0.029717811744888616\n",
      "\n",
      "trained 17616 images, use 98.26885390281677 seconds, loss -0.02960337983838141\n",
      "\n",
      "trained 18416 images, use 102.44244980812073 seconds, loss -0.02919256818049476\n",
      "\n",
      "trained 19216 images, use 107.54409623146057 seconds, loss -0.029159363818119916\n",
      "\n",
      "trained 20016 images, use 111.99271392822266 seconds, loss -0.0292976995388874\n",
      "\n",
      "trained 20816 images, use 116.7489242553711 seconds, loss -0.029415439255353146\n",
      "\n",
      "trained 21616 images, use 121.1607575416565 seconds, loss -0.029679579177661168\n",
      "\n",
      "trained 22416 images, use 126.02334332466125 seconds, loss -0.029493191483075453\n",
      "\n",
      "trained 23216 images, use 130.37503743171692 seconds, loss -0.02921877885443933\n",
      "\n",
      "trained 24016 images, use 135.21528792381287 seconds, loss -0.02916126236726912\n",
      "\n",
      "trained 24816 images, use 139.97936820983887 seconds, loss -0.029290261070045908\n",
      "\n",
      "trained 25616 images, use 144.6928722858429 seconds, loss -0.02917326755414734\n",
      "\n",
      "trained 26416 images, use 149.36412692070007 seconds, loss -0.02917580668070246\n",
      "\n",
      "trained 27216 images, use 154.59834456443787 seconds, loss -0.029389386098568435\n",
      "\n",
      "trained 28016 images, use 158.89919304847717 seconds, loss -0.029364926270034175\n",
      "\n",
      "trained 28816 images, use 163.89306092262268 seconds, loss -0.029102081840691244\n",
      "\n",
      "trained 29616 images, use 168.28487730026245 seconds, loss -0.029194413342466696\n",
      "\n",
      "trained 30416 images, use 173.27600526809692 seconds, loss -0.029239060861759748\n",
      "\n",
      "trained 31216 images, use 177.97885608673096 seconds, loss -0.029119825194050847\n",
      "\n",
      "trained 32016 images, use 182.49740862846375 seconds, loss -0.029401655185074014\n",
      "\n",
      "trained 32816 images, use 186.7924771308899 seconds, loss -0.029434010602865997\n",
      "\n",
      "trained 33616 images, use 191.44871592521667 seconds, loss -0.029404182813369862\n",
      "\n",
      "trained 34416 images, use 196.04701280593872 seconds, loss -0.02940384298623249\n",
      "\n",
      "trained 35216 images, use 200.71330785751343 seconds, loss -0.029581806632134264\n",
      "\n",
      "trained 36016 images, use 205.5749490261078 seconds, loss -0.029847512288638897\n",
      "\n",
      "trained 36816 images, use 210.1372425556183 seconds, loss -0.029768455691545657\n",
      "\n",
      "trained 37616 images, use 215.07429695129395 seconds, loss -0.029701795373258472\n",
      "\n",
      "trained 38416 images, use 219.26606583595276 seconds, loss -0.02961176129576444\n",
      "\n",
      "trained 39216 images, use 223.75123524665833 seconds, loss -0.02972564523367634\n",
      "\n",
      "trained 40016 images, use 228.9035758972168 seconds, loss -0.02973788411311229\n",
      "\n",
      "trained 40816 images, use 232.94077324867249 seconds, loss -0.029933135364577326\n",
      "\n",
      "trained 41616 images, use 237.58382105827332 seconds, loss -0.029841876130136693\n",
      "\n",
      "trained 42416 images, use 242.27982592582703 seconds, loss -0.029757722006649112\n",
      "\n",
      "trained 43216 images, use 246.63522005081177 seconds, loss -0.029930204710480017\n",
      "\n",
      "trained 44016 images, use 251.371084690094 seconds, loss -0.029859458758050048\n",
      "\n",
      "trained 44816 images, use 255.7702009677887 seconds, loss -0.029933523971134055\n",
      "\n",
      "trained 45616 images, use 260.4845371246338 seconds, loss -0.029988096430058286\n",
      "\n",
      "trained 46416 images, use 265.41425132751465 seconds, loss -0.029853938557178713\n",
      "\n",
      "trained 47216 images, use 270.1230182647705 seconds, loss -0.029968553655977163\n",
      "\n",
      "trained 48016 images, use 274.9476020336151 seconds, loss -0.02995040986277428\n",
      "\n",
      "trained 48816 images, use 279.59262466430664 seconds, loss -0.029937808762298682\n",
      "\n",
      "trained 49616 images, use 284.0129096508026 seconds, loss -0.030005225667010728\n",
      "\n",
      "trained 50416 images, use 289.2385084629059 seconds, loss -0.03008545188904902\n",
      "\n",
      "trained 51216 images, use 293.55561423301697 seconds, loss -0.030117779421141314\n",
      "\n",
      "trained 52016 images, use 298.10651421546936 seconds, loss -0.030172447686738574\n",
      "\n",
      "trained 52816 images, use 303.15501046180725 seconds, loss -0.03014800816057351\n",
      "\n",
      "trained 53616 images, use 307.7727782726288 seconds, loss -0.030135651565087664\n",
      "\n",
      "trained 54416 images, use 311.92424511909485 seconds, loss -0.03017505498777364\n",
      "\n",
      "trained 55216 images, use 316.6534595489502 seconds, loss -0.03018230637815847\n",
      "\n",
      "trained 56016 images, use 321.3111081123352 seconds, loss -0.030279209493441598\n",
      "\n",
      "trained 56816 images, use 326.448481798172 seconds, loss -0.030305515167263826\n",
      "\n",
      "trained 57616 images, use 330.8091504573822 seconds, loss -0.030266395950569618\n",
      "\n",
      "trained 58416 images, use 335.5993881225586 seconds, loss -0.03033716846348216\n",
      "\n",
      "trained 59216 images, use 339.8903224468231 seconds, loss -0.030402635778261387\n",
      "\n",
      "trained 60016 images, use 344.5185737609863 seconds, loss -0.03045953289779621\n",
      "\n",
      "trained 60816 images, use 349.5478346347809 seconds, loss -0.030446572621122988\n",
      "\n",
      "trained 61616 images, use 354.1906518936157 seconds, loss -0.030470187090699524\n",
      "\n",
      "trained 62416 images, use 358.50578141212463 seconds, loss -0.030571523331588392\n",
      "\n",
      "trained 63216 images, use 363.17918252944946 seconds, loss -0.03057158510004871\n",
      "\n",
      "trained 64016 images, use 367.7254066467285 seconds, loss -0.030599388524111718\n",
      "\n",
      "trained 64816 images, use 372.3094103336334 seconds, loss -0.030679776059337905\n",
      "\n",
      "trained 65616 images, use 377.431752204895 seconds, loss -0.030631260144371893\n",
      "\n",
      "trained 66416 images, use 381.72962713241577 seconds, loss -0.03065201395027671\n",
      "\n",
      "trained 67216 images, use 386.86680245399475 seconds, loss -0.030659957930566903\n",
      "\n",
      "trained 68016 images, use 391.82586121559143 seconds, loss -0.030637649959202623\n",
      "\n",
      "trained 68816 images, use 396.17586040496826 seconds, loss -0.0306558995444847\n",
      "\n",
      "trained 69616 images, use 400.7977035045624 seconds, loss -0.030595559433486547\n",
      "\n",
      "trained 70416 images, use 405.88182067871094 seconds, loss -0.030523842916192357\n",
      "\n",
      "trained 71216 images, use 410.8686354160309 seconds, loss -0.03057024497847347\n",
      "\n",
      "trained 72016 images, use 415.1702251434326 seconds, loss -0.03057522350255753\n",
      "\n",
      "trained 72816 images, use 419.8469557762146 seconds, loss -0.03060222469170351\n",
      "\n",
      "trained 73616 images, use 424.1640567779541 seconds, loss -0.030495855741264972\n",
      "\n",
      "trained 74416 images, use 429.35837268829346 seconds, loss -0.030485628219194115\n",
      "\n",
      "trained 75216 images, use 433.5800840854645 seconds, loss -0.030506379023671017\n",
      "\n",
      "trained 76016 images, use 438.0059380531311 seconds, loss -0.0305844199632909\n",
      "\n",
      "trained 76816 images, use 442.68211936950684 seconds, loss -0.03061875754297146\n",
      "\n",
      "trained 77616 images, use 447.1099307537079 seconds, loss -0.030704443042031137\n",
      "\n",
      "trained 78416 images, use 451.5544924736023 seconds, loss -0.03064853819682839\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 456.56595635414124 seconds, loss -0.0306600383473312\n",
      "\n",
      "trained 80016 images, use 461.1497037410736 seconds, loss -0.030717600969966456\n",
      "\n",
      "trained 80816 images, use 465.83617901802063 seconds, loss -0.030712565662607487\n",
      "\n",
      "trained 81616 images, use 469.92242074012756 seconds, loss -0.030692162385298\n",
      "\n",
      "trained 82416 images, use 474.4310894012451 seconds, loss -0.030712338089304122\n",
      "\n",
      "trained 83216 images, use 479.41029024124146 seconds, loss -0.030680789718498094\n",
      "\n",
      "trained 84016 images, use 483.84412908554077 seconds, loss -0.03064017180283233\n",
      "\n",
      "trained 84816 images, use 488.70350313186646 seconds, loss -0.030558413121182612\n",
      "\n",
      "trained 85616 images, use 493.34578251838684 seconds, loss -0.03061136076428904\n",
      "\n",
      "trained 86416 images, use 498.1509208679199 seconds, loss -0.030612697709755065\n",
      "\n",
      "trained 87216 images, use 502.19467639923096 seconds, loss -0.03051688973341874\n",
      "\n",
      "trained 88016 images, use 507.2265102863312 seconds, loss -0.030545881989593585\n",
      "\n",
      "trained 88816 images, use 512.0211400985718 seconds, loss -0.030506344427963215\n",
      "\n",
      "trained 89616 images, use 516.7282855510712 seconds, loss -0.030494815031820388\n",
      "\n",
      "trained 90416 images, use 521.628737449646 seconds, loss -0.030530297389143507\n",
      "\n",
      "trained 91216 images, use 525.9879562854767 seconds, loss -0.030577503461423062\n",
      "\n",
      "trained 92016 images, use 530.5889506340027 seconds, loss -0.03055315525948871\n",
      "\n",
      "trained 92816 images, use 535.2512845993042 seconds, loss -0.03055405705298223\n",
      "\n",
      "trained 93616 images, use 540.1059267520905 seconds, loss -0.030547346597278088\n",
      "\n",
      "trained 94416 images, use 545.1584434509277 seconds, loss -0.030590613324022124\n",
      "\n",
      "trained 95216 images, use 549.5711297988892 seconds, loss -0.030584083609203654\n",
      "\n",
      "trained 96016 images, use 554.5666658878326 seconds, loss -0.030596632614829318\n",
      "\n",
      "trained 96816 images, use 559.1604254245758 seconds, loss -0.030590193294469582\n",
      "\n",
      "trained 97616 images, use 563.5830035209656 seconds, loss -0.03063814831690238\n",
      "\n",
      "trained 98416 images, use 568.3183410167694 seconds, loss -0.03069605330853778\n",
      "\n",
      "trained 99216 images, use 572.9846577644348 seconds, loss -0.030681496153946174\n",
      "\n",
      "*************Epoch 10 Avrg Training loss -0.030700497306190663 Elapsed 577.2186300754547\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.785711428457138\n",
      "************* Validation: total 99996 precision 0.9693873469224483 avgTime 0.005845809775384179\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 11 started at 1619471193.3790886\n",
      "trained 16 images, use 1.738347053527832 seconds, loss -0.09440413862466812\n",
      "\n",
      "trained 816 images, use 5.9271955490112305 seconds, loss -0.03317800743286625\n",
      "\n",
      "trained 1616 images, use 10.231775999069214 seconds, loss -0.028004726845683406\n",
      "\n",
      "trained 2416 images, use 14.227192163467407 seconds, loss -0.02931858217830926\n",
      "\n",
      "trained 3216 images, use 18.523646116256714 seconds, loss -0.029133525464660557\n",
      "\n",
      "trained 4016 images, use 22.83735203742981 seconds, loss -0.030247372171633258\n",
      "\n",
      "trained 4816 images, use 27.228439807891846 seconds, loss -0.03158150430408719\n",
      "\n",
      "trained 5616 images, use 32.10975456237793 seconds, loss -0.032399138366167014\n",
      "\n",
      "trained 6416 images, use 36.19157886505127 seconds, loss -0.03283802660465297\n",
      "\n",
      "trained 7216 images, use 40.857794761657715 seconds, loss -0.032947971183656256\n",
      "\n",
      "trained 8016 images, use 45.229318380355835 seconds, loss -0.03298921110426981\n",
      "\n",
      "trained 8816 images, use 50.079031467437744 seconds, loss -0.03249588610162763\n",
      "\n",
      "trained 9616 images, use 54.4646520614624 seconds, loss -0.03245544754155809\n",
      "\n",
      "trained 10416 images, use 58.774972915649414 seconds, loss -0.03214419674099402\n",
      "\n",
      "trained 11216 images, use 63.59914469718933 seconds, loss -0.0319602313557359\n",
      "\n",
      "trained 12016 images, use 67.89083647727966 seconds, loss -0.031425012135186045\n",
      "\n",
      "trained 12816 images, use 72.49054384231567 seconds, loss -0.03175410637382718\n",
      "\n",
      "trained 13616 images, use 77.72982931137085 seconds, loss -0.03179494020819946\n",
      "\n",
      "trained 14416 images, use 82.44338011741638 seconds, loss -0.03149143001777936\n",
      "\n",
      "trained 15216 images, use 86.83562994003296 seconds, loss -0.031830899348000756\n",
      "\n",
      "trained 16016 images, use 91.32245802879333 seconds, loss -0.03151477923952207\n",
      "\n",
      "trained 16816 images, use 95.95651268959045 seconds, loss -0.03130900281505399\n",
      "\n",
      "trained 17616 images, use 100.23852968215942 seconds, loss -0.03125146494393095\n",
      "\n",
      "trained 18416 images, use 104.43275499343872 seconds, loss -0.03129022729612648\n",
      "\n",
      "trained 19216 images, use 109.29357528686523 seconds, loss -0.031378395230037576\n",
      "\n",
      "trained 20016 images, use 113.72881269454956 seconds, loss -0.031224801738733387\n",
      "\n",
      "trained 20816 images, use 118.3748869895935 seconds, loss -0.03139574939349462\n",
      "\n",
      "trained 21616 images, use 122.86746120452881 seconds, loss -0.031671683731672104\n",
      "\n",
      "trained 22416 images, use 127.92776250839233 seconds, loss -0.03150981379922177\n",
      "\n",
      "trained 23216 images, use 132.31363463401794 seconds, loss -0.03153215170867734\n",
      "\n",
      "trained 24016 images, use 136.81476712226868 seconds, loss -0.031519919396206277\n",
      "\n",
      "trained 24816 images, use 141.27620148658752 seconds, loss -0.031308291659677044\n",
      "\n",
      "trained 25616 images, use 145.85061812400818 seconds, loss -0.031189377231359602\n",
      "\n",
      "trained 26416 images, use 150.45791220664978 seconds, loss -0.031181032752577543\n",
      "\n",
      "trained 27216 images, use 154.99219751358032 seconds, loss -0.03098942731107384\n",
      "\n",
      "trained 28016 images, use 159.8645031452179 seconds, loss -0.03083299997620732\n",
      "\n",
      "trained 28816 images, use 164.59595727920532 seconds, loss -0.0306856605982837\n",
      "\n",
      "trained 29616 images, use 169.04906225204468 seconds, loss -0.030744826847521778\n",
      "\n",
      "trained 30416 images, use 173.80254793167114 seconds, loss -0.030807048142045046\n",
      "\n",
      "trained 31216 images, use 177.96839213371277 seconds, loss -0.030881060948160656\n",
      "\n",
      "trained 32016 images, use 182.68541312217712 seconds, loss -0.030997677215134137\n",
      "\n",
      "trained 32816 images, use 187.36499524116516 seconds, loss -0.030905371279601856\n",
      "\n",
      "trained 33616 images, use 192.10824942588806 seconds, loss -0.031097112165283818\n",
      "\n",
      "trained 34416 images, use 196.34121966362 seconds, loss -0.031071535905046778\n",
      "\n",
      "trained 35216 images, use 201.20213651657104 seconds, loss -0.030883605918919657\n",
      "\n",
      "trained 36016 images, use 205.5173466205597 seconds, loss -0.030836443468823256\n",
      "\n",
      "trained 36816 images, use 210.6192717552185 seconds, loss -0.030972468604553414\n",
      "\n",
      "trained 37616 images, use 215.1387288570404 seconds, loss -0.0309339633801783\n",
      "\n",
      "trained 38416 images, use 219.7938585281372 seconds, loss -0.030921877892184566\n",
      "\n",
      "trained 39216 images, use 224.69104051589966 seconds, loss -0.030984576667165212\n",
      "\n",
      "trained 40016 images, use 228.9534935951233 seconds, loss -0.03107934792520049\n",
      "\n",
      "trained 40816 images, use 233.8325960636139 seconds, loss -0.031112444468554903\n",
      "\n",
      "trained 41616 images, use 238.69152998924255 seconds, loss -0.03109844816570122\n",
      "\n",
      "trained 42416 images, use 243.0367410182953 seconds, loss -0.03095242869915525\n",
      "\n",
      "trained 43216 images, use 247.8777208328247 seconds, loss -0.030910350693768875\n",
      "\n",
      "trained 44016 images, use 252.51823329925537 seconds, loss -0.03094442437563531\n",
      "\n",
      "trained 44816 images, use 256.9855170249939 seconds, loss -0.030879783461054276\n",
      "\n",
      "trained 45616 images, use 262.18863821029663 seconds, loss -0.030765377408235272\n",
      "\n",
      "trained 46416 images, use 267.57627964019775 seconds, loss -0.030683462756815185\n",
      "\n",
      "trained 47216 images, use 272.04640221595764 seconds, loss -0.030718383500105337\n",
      "\n",
      "trained 48016 images, use 276.91610741615295 seconds, loss -0.03074576187702701\n",
      "\n",
      "trained 48816 images, use 281.30564737319946 seconds, loss -0.030694150567442128\n",
      "\n",
      "trained 49616 images, use 285.8312075138092 seconds, loss -0.03077548866413291\n",
      "\n",
      "trained 50416 images, use 290.70542192459106 seconds, loss -0.03079778209925246\n",
      "\n",
      "trained 51216 images, use 295.490736246109 seconds, loss -0.030695275237511806\n",
      "\n",
      "trained 52016 images, use 300.5772051811218 seconds, loss -0.03065349274960352\n",
      "\n",
      "trained 52816 images, use 304.8465347290039 seconds, loss -0.030648982042663576\n",
      "\n",
      "trained 53616 images, use 309.42371702194214 seconds, loss -0.030626950221118165\n",
      "\n",
      "trained 54416 images, use 314.53838205337524 seconds, loss -0.030652273492359244\n",
      "\n",
      "trained 55216 images, use 318.8040101528168 seconds, loss -0.030597581879115085\n",
      "\n",
      "trained 56016 images, use 323.5821199417114 seconds, loss -0.030708454220989938\n",
      "\n",
      "trained 56816 images, use 328.0550196170807 seconds, loss -0.03068406499608314\n",
      "\n",
      "trained 57616 images, use 332.6635854244232 seconds, loss -0.030624751036185907\n",
      "\n",
      "trained 58416 images, use 337.4522306919098 seconds, loss -0.030631638267410357\n",
      "\n",
      "trained 59216 images, use 341.91970467567444 seconds, loss -0.030686865875417586\n",
      "\n",
      "trained 60016 images, use 346.9362545013428 seconds, loss -0.030603238584052804\n",
      "\n",
      "trained 60816 images, use 351.4418637752533 seconds, loss -0.03062713618139365\n",
      "\n",
      "trained 61616 images, use 356.34988236427307 seconds, loss -0.030654008034247435\n",
      "\n",
      "trained 62416 images, use 361.02943658828735 seconds, loss -0.03076252717463013\n",
      "\n",
      "trained 63216 images, use 365.84541153907776 seconds, loss -0.030680074219635447\n",
      "\n",
      "trained 64016 images, use 370.4064564704895 seconds, loss -0.030753531548506314\n",
      "\n",
      "trained 64816 images, use 375.34681820869446 seconds, loss -0.030786636344845537\n",
      "\n",
      "trained 65616 images, use 379.225301027298 seconds, loss -0.03079266996945061\n",
      "\n",
      "trained 66416 images, use 383.99480962753296 seconds, loss -0.030745769394543692\n",
      "\n",
      "trained 67216 images, use 389.0271680355072 seconds, loss -0.030778110961930723\n",
      "\n",
      "trained 68016 images, use 393.1467502117157 seconds, loss -0.03077470438786651\n",
      "\n",
      "trained 68816 images, use 398.2595446109772 seconds, loss -0.030819173898315757\n",
      "\n",
      "trained 69616 images, use 403.38093662261963 seconds, loss -0.03081327097435437\n",
      "\n",
      "trained 70416 images, use 407.9199390411377 seconds, loss -0.030804459380101942\n",
      "\n",
      "trained 71216 images, use 412.654824256897 seconds, loss -0.030805784660070872\n",
      "\n",
      "trained 72016 images, use 417.48348569869995 seconds, loss -0.03076694393361599\n",
      "\n",
      "trained 72816 images, use 421.59046840667725 seconds, loss -0.030784292874564988\n",
      "\n",
      "trained 73616 images, use 426.152596950531 seconds, loss -0.030766234790997365\n",
      "\n",
      "trained 74416 images, use 430.6269357204437 seconds, loss -0.030832106163511338\n",
      "\n",
      "trained 75216 images, use 435.2878406047821 seconds, loss -0.030780357395317374\n",
      "\n",
      "trained 76016 images, use 439.78720021247864 seconds, loss -0.030916793232007776\n",
      "\n",
      "trained 76816 images, use 444.1427297592163 seconds, loss -0.03083067694859544\n",
      "\n",
      "trained 77616 images, use 449.4959030151367 seconds, loss -0.030866404768775196\n",
      "\n",
      "trained 78416 images, use 454.03397154808044 seconds, loss -0.030902696512596098\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 458.4715220928192 seconds, loss -0.030942529181277757\n",
      "\n",
      "trained 80016 images, use 463.2561376094818 seconds, loss -0.031029171635056446\n",
      "\n",
      "trained 80816 images, use 467.65830993652344 seconds, loss -0.03098356134732497\n",
      "\n",
      "trained 81616 images, use 472.30497670173645 seconds, loss -0.031022172507697485\n",
      "\n",
      "trained 82416 images, use 477.29600620269775 seconds, loss -0.031028030379041158\n",
      "\n",
      "trained 83216 images, use 482.08952021598816 seconds, loss -0.03098169153680299\n",
      "\n",
      "trained 84016 images, use 486.57530069351196 seconds, loss -0.030979192952157796\n",
      "\n",
      "trained 84816 images, use 491.4605851173401 seconds, loss -0.030969114726851536\n",
      "\n",
      "trained 85616 images, use 496.24287462234497 seconds, loss -0.030897211100112416\n",
      "\n",
      "trained 86416 images, use 501.21372509002686 seconds, loss -0.030908946178404288\n",
      "\n",
      "trained 87216 images, use 506.1065254211426 seconds, loss -0.030872012798096732\n",
      "\n",
      "trained 88016 images, use 510.4855122566223 seconds, loss -0.030802020445238575\n",
      "\n",
      "trained 88816 images, use 515.4265894889832 seconds, loss -0.030744524949300342\n",
      "\n",
      "trained 89616 images, use 519.8221147060394 seconds, loss -0.030768139809126776\n",
      "\n",
      "trained 90416 images, use 524.7314248085022 seconds, loss -0.030750376844835482\n",
      "\n",
      "trained 91216 images, use 529.2987852096558 seconds, loss -0.03079252471653748\n",
      "\n",
      "trained 92016 images, use 533.9955694675446 seconds, loss -0.0308034091683588\n",
      "\n",
      "trained 92816 images, use 538.7042510509491 seconds, loss -0.03083767371633832\n",
      "\n",
      "trained 93616 images, use 543.2054660320282 seconds, loss -0.03087032892527606\n",
      "\n",
      "trained 94416 images, use 547.8284890651703 seconds, loss -0.03086490286350813\n",
      "\n",
      "trained 95216 images, use 552.8201012611389 seconds, loss -0.03090421937561844\n",
      "\n",
      "trained 96016 images, use 557.0331490039825 seconds, loss -0.03090751823937614\n",
      "\n",
      "trained 96816 images, use 562.3341383934021 seconds, loss -0.030868067523996214\n",
      "\n",
      "trained 97616 images, use 566.7654371261597 seconds, loss -0.030806974281181655\n",
      "\n",
      "trained 98416 images, use 571.8543374538422 seconds, loss -0.030877470193479632\n",
      "\n",
      "trained 99216 images, use 576.1544134616852 seconds, loss -0.030930398735100985\n",
      "\n",
      "*************Epoch 11 Avrg Training loss -0.030894220045571054 Elapsed 580.5007708072662\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.786061442457698\n",
      "************* Validation: total 99996 precision 0.9694373489225283 avgTime 0.00610071686040049\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 12 started at 1619472384.289897\n",
      "trained 16 images, use 1.4263265132904053 seconds, loss -0.015413667540997267\n",
      "\n",
      "trained 816 images, use 5.414522171020508 seconds, loss -0.026635046304354894\n",
      "\n",
      "trained 1616 images, use 9.65522813796997 seconds, loss -0.02359348517265347\n",
      "\n",
      "trained 2416 images, use 13.8604416847229 seconds, loss -0.0260475715440736\n",
      "\n",
      "trained 3216 images, use 18.265979290008545 seconds, loss -0.026009258454095206\n",
      "\n",
      "trained 4016 images, use 22.723222494125366 seconds, loss -0.026866168867562528\n",
      "\n",
      "trained 4816 images, use 26.80990433692932 seconds, loss -0.027151555337792125\n",
      "\n",
      "trained 5616 images, use 31.195998430252075 seconds, loss -0.0272899332377082\n",
      "\n",
      "trained 6416 images, use 35.376304149627686 seconds, loss -0.027694309239527298\n",
      "\n",
      "trained 7216 images, use 39.73465633392334 seconds, loss -0.027914095365640122\n",
      "\n",
      "trained 8016 images, use 44.021803855895996 seconds, loss -0.02783350022541146\n",
      "\n",
      "trained 8816 images, use 48.4490966796875 seconds, loss -0.028149659228224697\n",
      "\n",
      "trained 9616 images, use 52.63603973388672 seconds, loss -0.02812723004177221\n",
      "\n",
      "trained 10416 images, use 57.66377878189087 seconds, loss -0.028317020703856784\n",
      "\n",
      "trained 11216 images, use 61.75134587287903 seconds, loss -0.02852951088773009\n",
      "\n",
      "trained 12016 images, use 66.56826424598694 seconds, loss -0.02901089806739383\n",
      "\n",
      "trained 12816 images, use 71.15759587287903 seconds, loss -0.029168632873951904\n",
      "\n",
      "trained 13616 images, use 75.59728622436523 seconds, loss -0.029374255933546433\n",
      "\n",
      "trained 14416 images, use 79.57399535179138 seconds, loss -0.029188348007866058\n",
      "\n",
      "trained 15216 images, use 84.47462844848633 seconds, loss -0.02923198794731896\n",
      "\n",
      "trained 16016 images, use 88.5956072807312 seconds, loss -0.029062979935487166\n",
      "\n",
      "trained 16816 images, use 92.86200761795044 seconds, loss -0.02929534025084613\n",
      "\n",
      "trained 17616 images, use 97.49983096122742 seconds, loss -0.029589583515910085\n",
      "\n",
      "trained 18416 images, use 102.0216429233551 seconds, loss -0.03000988175636681\n",
      "\n",
      "trained 19216 images, use 106.38104438781738 seconds, loss -0.029988266985076745\n",
      "\n",
      "trained 20016 images, use 110.68183159828186 seconds, loss -0.030238552111110366\n",
      "\n",
      "trained 20816 images, use 115.33465623855591 seconds, loss -0.030653067246462013\n",
      "\n",
      "trained 21616 images, use 119.76499485969543 seconds, loss -0.030895352278744764\n",
      "\n",
      "trained 22416 images, use 123.66450428962708 seconds, loss -0.03093863333283486\n",
      "\n",
      "trained 23216 images, use 128.80082416534424 seconds, loss -0.030889788093582355\n",
      "\n",
      "trained 24016 images, use 133.23697352409363 seconds, loss -0.03091458809638712\n",
      "\n",
      "trained 24816 images, use 137.73833537101746 seconds, loss -0.031061239583187523\n",
      "\n",
      "trained 25616 images, use 142.0848686695099 seconds, loss -0.030754366041514884\n",
      "\n",
      "trained 26416 images, use 146.48693084716797 seconds, loss -0.030943132515256433\n",
      "\n",
      "trained 27216 images, use 151.06805968284607 seconds, loss -0.030827556264032174\n",
      "\n",
      "trained 28016 images, use 155.29403614997864 seconds, loss -0.030927030042302416\n",
      "\n",
      "trained 28816 images, use 160.09846329689026 seconds, loss -0.03087400636548434\n",
      "\n",
      "trained 29616 images, use 164.60141611099243 seconds, loss -0.030998382468657458\n",
      "\n",
      "trained 30416 images, use 169.27203106880188 seconds, loss -0.03089991488860655\n",
      "\n",
      "trained 31216 images, use 173.5841600894928 seconds, loss -0.0307389465058514\n",
      "\n",
      "trained 32016 images, use 178.30669116973877 seconds, loss -0.030988049426614647\n",
      "\n",
      "trained 32816 images, use 182.55374360084534 seconds, loss -0.03127116741686879\n",
      "\n",
      "trained 33616 images, use 187.58818411827087 seconds, loss -0.031112814609542547\n",
      "\n",
      "trained 34416 images, use 191.75820899009705 seconds, loss -0.03106445616365302\n",
      "\n",
      "trained 35216 images, use 196.52874541282654 seconds, loss -0.0309526086583878\n",
      "\n",
      "trained 36016 images, use 201.17327523231506 seconds, loss -0.031110644271715317\n",
      "\n",
      "trained 36816 images, use 205.22380948066711 seconds, loss -0.031021601003681176\n",
      "\n",
      "trained 37616 images, use 209.3542561531067 seconds, loss -0.03083722644175516\n",
      "\n",
      "trained 38416 images, use 213.51986002922058 seconds, loss -0.0307998150339057\n",
      "\n",
      "trained 39216 images, use 218.5384018421173 seconds, loss -0.03075373335621681\n",
      "\n",
      "trained 40016 images, use 222.82870173454285 seconds, loss -0.030795390561332014\n",
      "\n",
      "trained 40816 images, use 227.33249616622925 seconds, loss -0.030713172741829997\n",
      "\n",
      "trained 41616 images, use 231.88554191589355 seconds, loss -0.030587860583870866\n",
      "\n",
      "trained 42416 images, use 236.66704320907593 seconds, loss -0.030700382473778886\n",
      "\n",
      "trained 43216 images, use 240.8109631538391 seconds, loss -0.03059311793237523\n",
      "\n",
      "trained 44016 images, use 245.13576245307922 seconds, loss -0.03040790032072097\n",
      "\n",
      "trained 44816 images, use 250.30414843559265 seconds, loss -0.03027981067657525\n",
      "\n",
      "trained 45616 images, use 254.5165832042694 seconds, loss -0.030158782714940494\n",
      "\n",
      "trained 46416 images, use 259.0720601081848 seconds, loss -0.030297787135128817\n",
      "\n",
      "trained 47216 images, use 263.3747732639313 seconds, loss -0.030402907887922145\n",
      "\n",
      "trained 48016 images, use 267.884375333786 seconds, loss -0.030486004680953017\n",
      "\n",
      "trained 48816 images, use 272.24579429626465 seconds, loss -0.030469971996918564\n",
      "\n",
      "trained 49616 images, use 276.4512677192688 seconds, loss -0.030531222745563052\n",
      "\n",
      "trained 50416 images, use 281.70114731788635 seconds, loss -0.03058228737723939\n",
      "\n",
      "trained 51216 images, use 286.2334632873535 seconds, loss -0.03049144416598001\n",
      "\n",
      "trained 52016 images, use 290.7690145969391 seconds, loss -0.03050640024165727\n",
      "\n",
      "trained 52816 images, use 295.545184135437 seconds, loss -0.030549357339007644\n",
      "\n",
      "trained 53616 images, use 300.012069940567 seconds, loss -0.030595297831157258\n",
      "\n",
      "trained 54416 images, use 304.5029766559601 seconds, loss -0.030511533440961656\n",
      "\n",
      "trained 55216 images, use 309.5348868370056 seconds, loss -0.03050731583027465\n",
      "\n",
      "trained 56016 images, use 314.26022815704346 seconds, loss -0.030636460422101275\n",
      "\n",
      "trained 56816 images, use 318.84892296791077 seconds, loss -0.030759208272823097\n",
      "\n",
      "trained 57616 images, use 323.11764788627625 seconds, loss -0.030798005277964433\n",
      "\n",
      "trained 58416 images, use 327.76347255706787 seconds, loss -0.03068505014905159\n",
      "\n",
      "trained 59216 images, use 331.94323229789734 seconds, loss -0.030660785491810404\n",
      "\n",
      "trained 60016 images, use 336.5547151565552 seconds, loss -0.030772931991806883\n",
      "\n",
      "trained 60816 images, use 340.91038703918457 seconds, loss -0.030834655820247806\n",
      "\n",
      "trained 61616 images, use 345.59358382225037 seconds, loss -0.030796206209066885\n",
      "\n",
      "trained 62416 images, use 350.5932402610779 seconds, loss -0.030763148333385146\n",
      "\n",
      "trained 63216 images, use 354.87256598472595 seconds, loss -0.030856679314588603\n",
      "\n",
      "trained 64016 images, use 359.1760804653168 seconds, loss -0.03090248168156267\n",
      "\n",
      "trained 64816 images, use 363.9677381515503 seconds, loss -0.030870013409120742\n",
      "\n",
      "trained 65616 images, use 368.9683802127838 seconds, loss -0.030921893933398666\n",
      "\n",
      "trained 66416 images, use 373.5192770957947 seconds, loss -0.03086413381536035\n",
      "\n",
      "trained 67216 images, use 377.6888427734375 seconds, loss -0.030843826541452696\n",
      "\n",
      "trained 68016 images, use 382.4803545475006 seconds, loss -0.03079357805125793\n",
      "\n",
      "trained 68816 images, use 386.85549211502075 seconds, loss -0.03085036571884841\n",
      "\n",
      "trained 69616 images, use 391.566437959671 seconds, loss -0.030756052008832083\n",
      "\n",
      "trained 70416 images, use 395.96449875831604 seconds, loss -0.030765620267752685\n",
      "\n",
      "trained 71216 images, use 400.5794425010681 seconds, loss -0.03079555662281334\n",
      "\n",
      "trained 72016 images, use 405.3336355686188 seconds, loss -0.030838961481816096\n",
      "\n",
      "trained 72816 images, use 409.66373014450073 seconds, loss -0.030832218675039443\n",
      "\n",
      "trained 73616 images, use 414.5489637851715 seconds, loss -0.03084124080564583\n",
      "\n",
      "trained 74416 images, use 418.75742983818054 seconds, loss -0.03084916269406988\n",
      "\n",
      "trained 75216 images, use 423.51866245269775 seconds, loss -0.030911450527316097\n",
      "\n",
      "trained 76016 images, use 428.4424715042114 seconds, loss -0.031010150647575\n",
      "\n",
      "trained 76816 images, use 432.69475412368774 seconds, loss -0.03096119098389604\n",
      "\n",
      "trained 77616 images, use 437.26221561431885 seconds, loss -0.030886237073968745\n",
      "\n",
      "trained 78416 images, use 441.6933295726776 seconds, loss -0.030885059143833226\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 446.1689100265503 seconds, loss -0.030803542436256073\n",
      "\n",
      "trained 80016 images, use 450.87970542907715 seconds, loss -0.030794397260537766\n",
      "\n",
      "trained 80816 images, use 455.6241223812103 seconds, loss -0.030817465123223985\n",
      "\n",
      "trained 81616 images, use 460.035826921463 seconds, loss -0.03089505111952976\n",
      "\n",
      "trained 82416 images, use 464.63853669166565 seconds, loss -0.03093720449696747\n",
      "\n",
      "trained 83216 images, use 469.2635416984558 seconds, loss -0.030909573529291842\n",
      "\n",
      "trained 84016 images, use 473.8238847255707 seconds, loss -0.030950481615369993\n",
      "\n",
      "trained 84816 images, use 478.61999583244324 seconds, loss -0.030970770515136765\n",
      "\n",
      "trained 85616 images, use 483.5536730289459 seconds, loss -0.030955614773879984\n",
      "\n",
      "trained 86416 images, use 487.7829222679138 seconds, loss -0.030990076853004953\n",
      "\n",
      "trained 87216 images, use 492.51620149612427 seconds, loss -0.03097677767086691\n",
      "\n",
      "trained 88016 images, use 497.2428560256958 seconds, loss -0.03099499545779328\n",
      "\n",
      "trained 88816 images, use 502.03991079330444 seconds, loss -0.030937361763799177\n",
      "\n",
      "trained 89616 images, use 506.9328570365906 seconds, loss -0.030965618447142802\n",
      "\n",
      "trained 90416 images, use 511.40617847442627 seconds, loss -0.030987981219551805\n",
      "\n",
      "trained 91216 images, use 516.6535551548004 seconds, loss -0.031002013601556595\n",
      "\n",
      "trained 92016 images, use 520.9065244197845 seconds, loss -0.031030873327254682\n",
      "\n",
      "trained 92816 images, use 525.6562509536743 seconds, loss -0.030958203112677066\n",
      "\n",
      "trained 93616 images, use 529.8889517784119 seconds, loss -0.030930405247507734\n",
      "\n",
      "trained 94416 images, use 534.6326720714569 seconds, loss -0.030935090551232728\n",
      "\n",
      "trained 95216 images, use 539.4517636299133 seconds, loss -0.030877977854578194\n",
      "\n",
      "trained 96016 images, use 544.5157701969147 seconds, loss -0.0308810851080936\n",
      "\n",
      "trained 96816 images, use 549.2555284500122 seconds, loss -0.03091640099456778\n",
      "\n",
      "trained 97616 images, use 553.7428646087646 seconds, loss -0.030944621266571156\n",
      "\n",
      "trained 98416 images, use 558.5922377109528 seconds, loss -0.030953602449033276\n",
      "\n",
      "trained 99216 images, use 563.2070851325989 seconds, loss -0.030938131054218942\n",
      "\n",
      "*************Epoch 12 Avrg Training loss -0.030980436753863434 Elapsed 567.7265396118164\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.785791431657266\n",
      "************* Validation: total 99996 precision 0.969398775951038 avgTime 0.005657478389112829\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 13 started at 1619473518.2369833\n",
      "trained 16 images, use 1.6481146812438965 seconds, loss -0.0675552487373352\n",
      "\n",
      "trained 816 images, use 6.191185474395752 seconds, loss -0.03565394976959187\n",
      "\n",
      "trained 1616 images, use 11.919348955154419 seconds, loss -0.029840242416577324\n",
      "\n",
      "trained 2416 images, use 17.302843809127808 seconds, loss -0.02926213396111914\n",
      "\n",
      "trained 3216 images, use 22.21644949913025 seconds, loss -0.02901662995230317\n",
      "\n",
      "trained 4016 images, use 26.843717575073242 seconds, loss -0.0315983577951058\n",
      "\n",
      "trained 4816 images, use 32.51904296875 seconds, loss -0.03252475062627368\n",
      "\n",
      "trained 5616 images, use 38.33922600746155 seconds, loss -0.03242511602139783\n",
      "\n",
      "trained 6416 images, use 43.42331790924072 seconds, loss -0.03230002883838074\n",
      "\n",
      "trained 7216 images, use 48.773494243621826 seconds, loss -0.031751408878133276\n",
      "\n",
      "trained 8016 images, use 54.37133264541626 seconds, loss -0.03165689452736527\n",
      "\n",
      "trained 8816 images, use 58.949265480041504 seconds, loss -0.03178602918230759\n",
      "\n",
      "trained 9616 images, use 63.63404297828674 seconds, loss -0.031387139360798684\n",
      "\n",
      "trained 10416 images, use 69.142413854599 seconds, loss -0.03133404990887393\n",
      "\n",
      "trained 11216 images, use 74.38149881362915 seconds, loss -0.03159971388997831\n",
      "\n",
      "trained 12016 images, use 79.27159786224365 seconds, loss -0.031783361764720824\n",
      "\n",
      "trained 12816 images, use 84.44158673286438 seconds, loss -0.03121452117728181\n",
      "\n",
      "trained 13616 images, use 89.111403465271 seconds, loss -0.03156379250214779\n",
      "\n",
      "trained 14416 images, use 93.34712743759155 seconds, loss -0.03147963246525345\n",
      "\n",
      "trained 15216 images, use 98.11495685577393 seconds, loss -0.0319449310195473\n",
      "\n",
      "trained 16016 images, use 103.3633599281311 seconds, loss -0.031664275198883575\n",
      "\n",
      "trained 16816 images, use 107.71180248260498 seconds, loss -0.031888884587397505\n",
      "\n",
      "trained 17616 images, use 112.65599584579468 seconds, loss -0.0316203950484429\n",
      "\n",
      "trained 18416 images, use 118.33898901939392 seconds, loss -0.03169684154744997\n",
      "\n",
      "trained 19216 images, use 122.5892972946167 seconds, loss -0.03181527328408326\n",
      "\n",
      "trained 20016 images, use 127.16438484191895 seconds, loss -0.03143524136823915\n",
      "\n",
      "trained 20816 images, use 131.82140278816223 seconds, loss -0.031406368418824146\n",
      "\n",
      "trained 21616 images, use 136.47687435150146 seconds, loss -0.0314358045259563\n",
      "\n",
      "trained 22416 images, use 141.425213098526 seconds, loss -0.03135036510258236\n",
      "\n",
      "trained 23216 images, use 146.45403027534485 seconds, loss -0.03122073503315539\n",
      "\n",
      "trained 24016 images, use 150.81711316108704 seconds, loss -0.03116937132148927\n",
      "\n",
      "trained 24816 images, use 155.4550964832306 seconds, loss -0.031196212769770405\n",
      "\n",
      "trained 25616 images, use 160.10084128379822 seconds, loss -0.031195906510336893\n",
      "\n",
      "trained 26416 images, use 164.53665041923523 seconds, loss -0.03095108826637104\n",
      "\n",
      "trained 27216 images, use 169.42875146865845 seconds, loss -0.03100781082056265\n",
      "\n",
      "trained 28016 images, use 174.16782808303833 seconds, loss -0.030959955544546412\n",
      "\n",
      "trained 28816 images, use 178.89889526367188 seconds, loss -0.030949915413141744\n",
      "\n",
      "trained 29616 images, use 183.89885902404785 seconds, loss -0.03077517096675206\n",
      "\n",
      "trained 30416 images, use 188.70258212089539 seconds, loss -0.030948257422869357\n",
      "\n",
      "trained 31216 images, use 193.42447328567505 seconds, loss -0.030851014810920556\n",
      "\n",
      "trained 32016 images, use 197.8929271697998 seconds, loss -0.03094901367537123\n",
      "\n",
      "trained 32816 images, use 202.9674892425537 seconds, loss -0.030918000387042267\n",
      "\n",
      "trained 33616 images, use 207.80062651634216 seconds, loss -0.030831216657307894\n",
      "\n",
      "trained 34416 images, use 212.60178399085999 seconds, loss -0.030979232434781307\n",
      "\n",
      "trained 35216 images, use 217.055438041687 seconds, loss -0.03122400164822751\n",
      "\n",
      "trained 36016 images, use 222.033127784729 seconds, loss -0.03097860397335123\n",
      "\n",
      "trained 36816 images, use 226.96264696121216 seconds, loss -0.031015315499021444\n",
      "\n",
      "trained 37616 images, use 232.60016226768494 seconds, loss -0.0311633614529763\n",
      "\n",
      "trained 38416 images, use 237.1156132221222 seconds, loss -0.031071072111370925\n",
      "\n",
      "trained 39216 images, use 241.99791622161865 seconds, loss -0.03107865262551542\n",
      "\n",
      "trained 40016 images, use 246.55737853050232 seconds, loss -0.031060712131061534\n",
      "\n",
      "trained 40816 images, use 251.52320790290833 seconds, loss -0.031009418175908576\n",
      "\n",
      "trained 41616 images, use 256.33658027648926 seconds, loss -0.031070987551383353\n",
      "\n",
      "trained 42416 images, use 261.1651759147644 seconds, loss -0.0312332927485277\n",
      "\n",
      "trained 43216 images, use 265.6143605709076 seconds, loss -0.03129779184788304\n",
      "\n",
      "trained 44016 images, use 269.9976215362549 seconds, loss -0.03142581405105997\n",
      "\n",
      "trained 44816 images, use 274.7677035331726 seconds, loss -0.031397662603948766\n",
      "\n",
      "trained 45616 images, use 279.62066173553467 seconds, loss -0.031348484882192246\n",
      "\n",
      "trained 46416 images, use 284.38759756088257 seconds, loss -0.03115828559057058\n",
      "\n",
      "trained 47216 images, use 289.26235604286194 seconds, loss -0.031217437385357115\n",
      "\n",
      "trained 48016 images, use 294.0521514415741 seconds, loss -0.03120844907528544\n",
      "\n",
      "trained 48816 images, use 299.00971961021423 seconds, loss -0.031315630981283135\n",
      "\n",
      "trained 49616 images, use 303.79608941078186 seconds, loss -0.03122060363657131\n",
      "\n",
      "trained 50416 images, use 308.37920093536377 seconds, loss -0.031342755582244815\n",
      "\n",
      "trained 51216 images, use 313.5015752315521 seconds, loss -0.03134643211887259\n",
      "\n",
      "trained 52016 images, use 318.2004671096802 seconds, loss -0.03134149681005472\n",
      "\n",
      "trained 52816 images, use 323.29352259635925 seconds, loss -0.0313415635469699\n",
      "\n",
      "trained 53616 images, use 327.85974073410034 seconds, loss -0.031377072270312084\n",
      "\n",
      "trained 54416 images, use 331.96231627464294 seconds, loss -0.031241866992232394\n",
      "\n",
      "trained 55216 images, use 336.9914207458496 seconds, loss -0.031291839835361705\n",
      "\n",
      "trained 56016 images, use 341.84304308891296 seconds, loss -0.0313037340240877\n",
      "\n",
      "trained 56816 images, use 346.4360008239746 seconds, loss -0.03125853497526937\n",
      "\n",
      "trained 57616 images, use 351.2320303916931 seconds, loss -0.03130513367489685\n",
      "\n",
      "trained 58416 images, use 355.9789893627167 seconds, loss -0.031315015098887455\n",
      "\n",
      "trained 59216 images, use 360.4844186306 seconds, loss -0.031238576803900835\n",
      "\n",
      "trained 60016 images, use 365.4338855743408 seconds, loss -0.031194686450546905\n",
      "\n",
      "trained 60816 images, use 370.28540802001953 seconds, loss -0.03127316111196632\n",
      "\n",
      "trained 61616 images, use 374.7966499328613 seconds, loss -0.031188617250945377\n",
      "\n",
      "trained 62416 images, use 379.9202539920807 seconds, loss -0.031187299514160712\n",
      "\n",
      "trained 63216 images, use 384.93003964424133 seconds, loss -0.031248099114360408\n",
      "\n",
      "trained 64016 images, use 389.280720949173 seconds, loss -0.03125207011502361\n",
      "\n",
      "trained 64816 images, use 394.0496709346771 seconds, loss -0.03129735953398315\n",
      "\n",
      "trained 65616 images, use 398.3180208206177 seconds, loss -0.03127768950261582\n",
      "\n",
      "trained 66416 images, use 402.9714574813843 seconds, loss -0.03129930000132512\n",
      "\n",
      "trained 67216 images, use 407.6937518119812 seconds, loss -0.03140817994002907\n",
      "\n",
      "trained 68016 images, use 412.2277431488037 seconds, loss -0.03137370582560372\n",
      "\n",
      "trained 68816 images, use 417.39287424087524 seconds, loss -0.03132157959885151\n",
      "\n",
      "trained 69616 images, use 421.9916937351227 seconds, loss -0.03127232321456068\n",
      "\n",
      "trained 70416 images, use 426.93030190467834 seconds, loss -0.0312503145515447\n",
      "\n",
      "trained 71216 images, use 431.3681387901306 seconds, loss -0.031206442343723235\n",
      "\n",
      "trained 72016 images, use 436.3719663619995 seconds, loss -0.03117068291590855\n",
      "\n",
      "trained 72816 images, use 441.0195503234863 seconds, loss -0.03114179852895404\n",
      "\n",
      "trained 73616 images, use 445.3343789577484 seconds, loss -0.031039684427808564\n",
      "\n",
      "trained 74416 images, use 449.79483675956726 seconds, loss -0.031031122578264167\n",
      "\n",
      "trained 75216 images, use 454.96095061302185 seconds, loss -0.031122796340383646\n",
      "\n",
      "trained 76016 images, use 459.73851561546326 seconds, loss -0.031017518494295383\n",
      "\n",
      "trained 76816 images, use 464.10863161087036 seconds, loss -0.030974859491180513\n",
      "\n",
      "trained 77616 images, use 468.58975887298584 seconds, loss -0.030958419946776883\n",
      "\n",
      "trained 78416 images, use 473.47734212875366 seconds, loss -0.030890480019884283\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 478.33494329452515 seconds, loss -0.030846853332837695\n",
      "\n",
      "trained 80016 images, use 483.05312609672546 seconds, loss -0.030832033416818685\n",
      "\n",
      "trained 80816 images, use 487.8877274990082 seconds, loss -0.030893814387475658\n",
      "\n",
      "trained 81616 images, use 492.37882804870605 seconds, loss -0.030939544418063354\n",
      "\n",
      "trained 82416 images, use 497.30867290496826 seconds, loss -0.030928949699704028\n",
      "\n",
      "trained 83216 images, use 501.9543490409851 seconds, loss -0.030895886043363966\n",
      "\n",
      "trained 84016 images, use 506.72159147262573 seconds, loss -0.030914507427722476\n",
      "\n",
      "trained 84816 images, use 511.783766746521 seconds, loss -0.030917033637449347\n",
      "\n",
      "trained 85616 images, use 516.0690593719482 seconds, loss -0.03094731615502593\n",
      "\n",
      "trained 86416 images, use 520.3343243598938 seconds, loss -0.031005335429338882\n",
      "\n",
      "trained 87216 images, use 525.6271674633026 seconds, loss -0.031052772908965392\n",
      "\n",
      "trained 88016 images, use 530.1154322624207 seconds, loss -0.03106829485007485\n",
      "\n",
      "trained 88816 images, use 534.7274460792542 seconds, loss -0.03099109031665235\n",
      "\n",
      "trained 89616 images, use 539.7091100215912 seconds, loss -0.031017595963166347\n",
      "\n",
      "trained 90416 images, use 544.1282911300659 seconds, loss -0.031011174291784564\n",
      "\n",
      "trained 91216 images, use 548.7665596008301 seconds, loss -0.031033762465205946\n",
      "\n",
      "trained 92016 images, use 553.600656747818 seconds, loss -0.030994342714763572\n",
      "\n",
      "trained 92816 images, use 558.0484759807587 seconds, loss -0.03101160241043623\n",
      "\n",
      "trained 93616 images, use 562.6932044029236 seconds, loss -0.03094448868509502\n",
      "\n",
      "trained 94416 images, use 567.1654932498932 seconds, loss -0.030927933722009526\n",
      "\n",
      "trained 95216 images, use 572.036865234375 seconds, loss -0.03097332708527206\n",
      "\n",
      "trained 96016 images, use 577.0260503292084 seconds, loss -0.031033480433208964\n",
      "\n",
      "trained 96816 images, use 581.7547378540039 seconds, loss -0.0310678611446691\n",
      "\n",
      "trained 97616 images, use 586.7730112075806 seconds, loss -0.03107890788220266\n",
      "\n",
      "trained 98416 images, use 591.2347452640533 seconds, loss -0.031133864351880265\n",
      "\n",
      "trained 99216 images, use 595.9149193763733 seconds, loss -0.031132187465092265\n",
      "\n",
      "*************Epoch 13 Avrg Training loss -0.03111251417557698 Elapsed 600.2818582057953\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.786091443657746\n",
      "************* Validation: total 99996 precision 0.9694416348082494 avgTime 0.005919849764342747\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 14 started at 1619474711.1779716\n",
      "trained 16 images, use 2.035015106201172 seconds, loss -0.020107484553591348\n",
      "\n",
      "trained 816 images, use 7.161109447479248 seconds, loss -0.024668317150992783\n",
      "\n",
      "trained 1616 images, use 13.330708503723145 seconds, loss -0.025316003272123185\n",
      "\n",
      "trained 2416 images, use 19.6966450214386 seconds, loss -0.02901865831182704\n",
      "\n",
      "trained 3216 images, use 24.942230463027954 seconds, loss -0.030508194295324226\n",
      "\n",
      "trained 4016 images, use 31.198436498641968 seconds, loss -0.03043144977195627\n",
      "\n",
      "trained 4816 images, use 36.67608976364136 seconds, loss -0.030266341539763986\n",
      "\n",
      "trained 5616 images, use 41.88446617126465 seconds, loss -0.031193415731675857\n",
      "\n",
      "trained 6416 images, use 46.59282350540161 seconds, loss -0.031023935766081954\n",
      "\n",
      "trained 7216 images, use 51.90310263633728 seconds, loss -0.030767795965437116\n",
      "\n",
      "trained 8016 images, use 57.27936124801636 seconds, loss -0.030377765363592078\n",
      "\n",
      "trained 8816 images, use 62.413259983062744 seconds, loss -0.030834753575872113\n",
      "\n",
      "trained 9616 images, use 67.64602565765381 seconds, loss -0.03172629837795632\n",
      "\n",
      "trained 10416 images, use 72.45012378692627 seconds, loss -0.032068325514285824\n",
      "\n",
      "trained 11216 images, use 77.60106372833252 seconds, loss -0.0324557155057162\n",
      "\n",
      "trained 12016 images, use 82.02532458305359 seconds, loss -0.03224728237949861\n",
      "\n",
      "trained 12816 images, use 87.72727608680725 seconds, loss -0.03198070793029531\n",
      "\n",
      "trained 13616 images, use 92.17939043045044 seconds, loss -0.032172838438668805\n",
      "\n",
      "trained 14416 images, use 96.5454409122467 seconds, loss -0.03204736260189175\n",
      "\n",
      "trained 15216 images, use 101.20353388786316 seconds, loss -0.032065418048330324\n",
      "\n",
      "trained 16016 images, use 106.01352429389954 seconds, loss -0.0324974523882965\n",
      "\n",
      "trained 16816 images, use 110.554358959198 seconds, loss -0.032585766553427785\n",
      "\n",
      "trained 17616 images, use 114.95952773094177 seconds, loss -0.03245201511259387\n",
      "\n",
      "trained 18416 images, use 120.00095081329346 seconds, loss -0.03251471951881671\n",
      "\n",
      "trained 19216 images, use 124.92894673347473 seconds, loss -0.032539982045571715\n",
      "\n",
      "trained 20016 images, use 129.73344087600708 seconds, loss -0.0322655631671176\n",
      "\n",
      "trained 20816 images, use 134.25686407089233 seconds, loss -0.032333507317605925\n",
      "\n",
      "trained 21616 images, use 138.7093575000763 seconds, loss -0.03200365417095574\n",
      "\n",
      "trained 22416 images, use 143.67377543449402 seconds, loss -0.03197718465952586\n",
      "\n",
      "trained 23216 images, use 148.63020873069763 seconds, loss -0.03186486589549642\n",
      "\n",
      "trained 24016 images, use 154.40159630775452 seconds, loss -0.031615761311184674\n",
      "\n",
      "trained 24816 images, use 159.0911135673523 seconds, loss -0.03162152996428684\n",
      "\n",
      "trained 25616 images, use 164.14133763313293 seconds, loss -0.031483056121076575\n",
      "\n",
      "trained 26416 images, use 168.72367691993713 seconds, loss -0.03147054096965111\n",
      "\n",
      "trained 27216 images, use 173.5906581878662 seconds, loss -0.03156324240671893\n",
      "\n",
      "trained 28016 images, use 178.22500109672546 seconds, loss -0.03142678608732303\n",
      "\n",
      "trained 28816 images, use 183.7724153995514 seconds, loss -0.031598790828396804\n",
      "\n",
      "trained 29616 images, use 188.60826420783997 seconds, loss -0.031438619171490836\n",
      "\n",
      "trained 30416 images, use 193.10440826416016 seconds, loss -0.03169366612647689\n",
      "\n",
      "trained 31216 images, use 198.18338584899902 seconds, loss -0.031611934983762\n",
      "\n",
      "trained 32016 images, use 203.0843050479889 seconds, loss -0.03172524589164444\n",
      "\n",
      "trained 32816 images, use 207.99943685531616 seconds, loss -0.03165079588048843\n",
      "\n",
      "trained 33616 images, use 213.33588886260986 seconds, loss -0.03163466699239986\n",
      "\n",
      "trained 34416 images, use 218.11025261878967 seconds, loss -0.03149733582953893\n",
      "\n",
      "trained 35216 images, use 223.56965827941895 seconds, loss -0.03139075433468559\n",
      "\n",
      "trained 36016 images, use 228.63074445724487 seconds, loss -0.03127361816187529\n",
      "\n",
      "trained 36816 images, use 233.43760800361633 seconds, loss -0.03127205763550011\n",
      "\n",
      "trained 37616 images, use 238.0309510231018 seconds, loss -0.03132634962333986\n",
      "\n",
      "trained 38416 images, use 242.6084976196289 seconds, loss -0.03127861126539501\n",
      "\n",
      "trained 39216 images, use 247.68875741958618 seconds, loss -0.03142140215721452\n",
      "\n",
      "trained 40016 images, use 252.4904282093048 seconds, loss -0.03155328808770273\n",
      "\n",
      "trained 40816 images, use 257.1838011741638 seconds, loss -0.031465982884015725\n",
      "\n",
      "trained 41616 images, use 261.7513656616211 seconds, loss -0.031391584428753644\n",
      "\n",
      "trained 42416 images, use 266.394015789032 seconds, loss -0.031347370339390876\n",
      "\n",
      "trained 43216 images, use 270.9501667022705 seconds, loss -0.03136645147357713\n",
      "\n",
      "trained 44016 images, use 275.7712392807007 seconds, loss -0.03121421315501592\n",
      "\n",
      "trained 44816 images, use 280.22844982147217 seconds, loss -0.031300764245610284\n",
      "\n",
      "trained 45616 images, use 285.13140749931335 seconds, loss -0.03125612663084006\n",
      "\n",
      "trained 46416 images, use 289.69980478286743 seconds, loss -0.031083494017252633\n",
      "\n",
      "trained 47216 images, use 294.3013114929199 seconds, loss -0.031038775065064153\n",
      "\n",
      "trained 48016 images, use 299.333683013916 seconds, loss -0.031056793819409748\n",
      "\n",
      "trained 48816 images, use 303.732013463974 seconds, loss -0.031141254001353452\n",
      "\n",
      "trained 49616 images, use 308.25089025497437 seconds, loss -0.03107919242084835\n",
      "\n",
      "trained 50416 images, use 313.0455856323242 seconds, loss -0.031104118473675908\n",
      "\n",
      "trained 51216 images, use 317.54975748062134 seconds, loss -0.030950885789529578\n",
      "\n",
      "trained 52016 images, use 322.33757281303406 seconds, loss -0.030868915007970635\n",
      "\n",
      "trained 52816 images, use 327.2639524936676 seconds, loss -0.030946191441318917\n",
      "\n",
      "trained 53616 images, use 331.85896253585815 seconds, loss -0.030925473739446634\n",
      "\n",
      "trained 54416 images, use 336.51640939712524 seconds, loss -0.030995053456990652\n",
      "\n",
      "trained 55216 images, use 341.37391114234924 seconds, loss -0.031002509095007808\n",
      "\n",
      "trained 56016 images, use 345.74056601524353 seconds, loss -0.031018152268492246\n",
      "\n",
      "trained 56816 images, use 350.082546710968 seconds, loss -0.031055490623677955\n",
      "\n",
      "trained 57616 images, use 355.11448431015015 seconds, loss -0.031046549219230307\n",
      "\n",
      "trained 58416 images, use 360.05080580711365 seconds, loss -0.031070168091797332\n",
      "\n",
      "trained 59216 images, use 364.5994141101837 seconds, loss -0.031161661395411964\n",
      "\n",
      "trained 60016 images, use 370.0896580219269 seconds, loss -0.031099896971507317\n",
      "\n",
      "trained 60816 images, use 374.61326909065247 seconds, loss -0.03116551452083434\n",
      "\n",
      "trained 61616 images, use 379.3795578479767 seconds, loss -0.031246128636285606\n",
      "\n",
      "trained 62416 images, use 383.7172222137451 seconds, loss -0.031257947003040534\n",
      "\n",
      "trained 63216 images, use 388.3707597255707 seconds, loss -0.031271448460637764\n",
      "\n",
      "trained 64016 images, use 393.2136194705963 seconds, loss -0.03140406842769785\n",
      "\n",
      "trained 64816 images, use 397.6979920864105 seconds, loss -0.03147285730974892\n",
      "\n",
      "trained 65616 images, use 403.38310050964355 seconds, loss -0.03157166009847356\n",
      "\n",
      "trained 66416 images, use 407.72745156288147 seconds, loss -0.03157577073272609\n",
      "\n",
      "trained 67216 images, use 412.0965518951416 seconds, loss -0.0316762328293883\n",
      "\n",
      "trained 68016 images, use 416.49662494659424 seconds, loss -0.031648920004347145\n",
      "\n",
      "trained 68816 images, use 421.2790205478668 seconds, loss -0.03162845187110371\n",
      "\n",
      "trained 69616 images, use 425.9887590408325 seconds, loss -0.03168698597359367\n",
      "\n",
      "trained 70416 images, use 430.93620252609253 seconds, loss -0.031708838733299646\n",
      "\n",
      "trained 71216 images, use 435.7403326034546 seconds, loss -0.03163469403796329\n",
      "\n",
      "trained 72016 images, use 440.5129568576813 seconds, loss -0.03163021474879104\n",
      "\n",
      "trained 72816 images, use 445.93965435028076 seconds, loss -0.03159757801425993\n",
      "\n",
      "trained 73616 images, use 450.8149936199188 seconds, loss -0.03166538750709005\n",
      "\n",
      "trained 74416 images, use 455.1530828475952 seconds, loss -0.031598957607869786\n",
      "\n",
      "trained 75216 images, use 459.6921036243439 seconds, loss -0.03149250145678025\n",
      "\n",
      "trained 76016 images, use 464.43372344970703 seconds, loss -0.031473929080149024\n",
      "\n",
      "trained 76816 images, use 469.4374723434448 seconds, loss -0.03148271979799819\n",
      "\n",
      "trained 77616 images, use 474.2374761104584 seconds, loss -0.03133474890603268\n",
      "\n",
      "trained 78416 images, use 478.57981634140015 seconds, loss -0.03141161236798533\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 483.258269071579 seconds, loss -0.03131126898547187\n",
      "\n",
      "trained 80016 images, use 487.58664178848267 seconds, loss -0.03136356892545356\n",
      "\n",
      "trained 80816 images, use 491.9860887527466 seconds, loss -0.03137091060106091\n",
      "\n",
      "trained 81616 images, use 496.90696477890015 seconds, loss -0.031327839041107544\n",
      "\n",
      "trained 82416 images, use 501.31658816337585 seconds, loss -0.03132744155829784\n",
      "\n",
      "trained 83216 images, use 506.0501666069031 seconds, loss -0.031313201417838374\n",
      "\n",
      "trained 84016 images, use 510.8582196235657 seconds, loss -0.03123048249824569\n",
      "\n",
      "trained 84816 images, use 515.6446521282196 seconds, loss -0.031243451965727816\n",
      "\n",
      "trained 85616 images, use 520.6715266704559 seconds, loss -0.03129846900677887\n",
      "\n",
      "trained 86416 images, use 525.2832000255585 seconds, loss -0.03125940287600547\n",
      "\n",
      "trained 87216 images, use 529.6624882221222 seconds, loss -0.031227152761495854\n",
      "\n",
      "trained 88016 images, use 534.2928159236908 seconds, loss -0.031250200305683956\n",
      "\n",
      "trained 88816 images, use 538.5095016956329 seconds, loss -0.031229185042737043\n",
      "\n",
      "trained 89616 images, use 543.1834893226624 seconds, loss -0.031163108958035524\n",
      "\n",
      "trained 90416 images, use 547.8990383148193 seconds, loss -0.031121649614892496\n",
      "\n",
      "trained 91216 images, use 552.4655246734619 seconds, loss -0.031188257120499215\n",
      "\n",
      "trained 92016 images, use 556.7980966567993 seconds, loss -0.031133583393438708\n",
      "\n",
      "trained 92816 images, use 561.589376449585 seconds, loss -0.03110903213790204\n",
      "\n",
      "trained 93616 images, use 566.4273476600647 seconds, loss -0.031109609315372332\n",
      "\n",
      "trained 94416 images, use 570.8472456932068 seconds, loss -0.03120329474678694\n",
      "\n",
      "trained 95216 images, use 576.4251744747162 seconds, loss -0.03114655810075676\n",
      "\n",
      "trained 96016 images, use 580.506621837616 seconds, loss -0.031116468341572952\n",
      "\n",
      "trained 96816 images, use 584.8642723560333 seconds, loss -0.031145449661066808\n",
      "\n",
      "trained 97616 images, use 589.7526004314423 seconds, loss -0.031146292980851392\n",
      "\n",
      "trained 98416 images, use 594.328542470932 seconds, loss -0.03115804379007776\n",
      "\n",
      "trained 99216 images, use 599.2064409255981 seconds, loss -0.031245766201744775\n",
      "\n",
      "*************Epoch 14 Avrg Training loss -0.03126102646695184 Elapsed 603.2768783569336\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n",
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.7860514420576825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Validation: total 99996 precision 0.9694359202939546 avgTime 0.005793910896049947\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 15 started at 1619475894.315667\n",
      "trained 16 images, use 1.9092516899108887 seconds, loss 0.00011774920858442783\n",
      "\n",
      "trained 816 images, use 5.894379138946533 seconds, loss -0.0344312513549137\n",
      "\n",
      "trained 1616 images, use 10.719057083129883 seconds, loss -0.03362035783734606\n",
      "\n",
      "trained 2416 images, use 14.606934547424316 seconds, loss -0.034028914930977885\n",
      "\n",
      "trained 3216 images, use 19.524840116500854 seconds, loss -0.03556809583069975\n",
      "\n",
      "trained 4016 images, use 23.729533433914185 seconds, loss -0.033796852167630016\n",
      "\n",
      "trained 4816 images, use 27.91759991645813 seconds, loss -0.0343054298306792\n",
      "\n",
      "trained 5616 images, use 32.38156580924988 seconds, loss -0.03348874231699416\n",
      "\n",
      "trained 6416 images, use 37.06743884086609 seconds, loss -0.03408857946105379\n",
      "\n",
      "trained 7216 images, use 41.420833110809326 seconds, loss -0.03475651510502576\n",
      "\n",
      "trained 8016 images, use 46.013245820999146 seconds, loss -0.03389744277494746\n",
      "\n",
      "trained 8816 images, use 50.01365637779236 seconds, loss -0.0348660000515084\n",
      "\n",
      "trained 9616 images, use 55.152212142944336 seconds, loss -0.03486798710798251\n",
      "\n",
      "trained 10416 images, use 59.33600664138794 seconds, loss -0.03404460473663266\n",
      "\n",
      "trained 11216 images, use 64.19556260108948 seconds, loss -0.033663031899178505\n",
      "\n",
      "trained 12016 images, use 68.65710759162903 seconds, loss -0.0333727547752749\n",
      "\n",
      "trained 12816 images, use 73.70071125030518 seconds, loss -0.03289437978392776\n",
      "\n",
      "trained 13616 images, use 77.95787286758423 seconds, loss -0.0329912677261484\n",
      "\n",
      "trained 14416 images, use 82.68923425674438 seconds, loss -0.03297448641126846\n",
      "\n",
      "trained 15216 images, use 87.50884938240051 seconds, loss -0.03306398859395868\n",
      "\n",
      "trained 16016 images, use 91.82659602165222 seconds, loss -0.03344725594028878\n",
      "\n",
      "trained 16816 images, use 96.32376146316528 seconds, loss -0.032935156321792926\n",
      "\n",
      "trained 17616 images, use 100.73297381401062 seconds, loss -0.03328300589861702\n",
      "\n",
      "trained 18416 images, use 105.31873035430908 seconds, loss -0.03308305102264302\n",
      "\n",
      "trained 19216 images, use 109.47739958763123 seconds, loss -0.033310747073943756\n",
      "\n",
      "trained 20016 images, use 113.91432571411133 seconds, loss -0.03306871670672619\n",
      "\n",
      "trained 20816 images, use 118.34163475036621 seconds, loss -0.03314005164761123\n",
      "\n",
      "trained 21616 images, use 122.59582734107971 seconds, loss -0.032753792381653726\n",
      "\n",
      "trained 22416 images, use 127.36414408683777 seconds, loss -0.03239881752595419\n",
      "\n",
      "trained 23216 images, use 131.79231786727905 seconds, loss -0.032194054416859574\n",
      "\n",
      "trained 24016 images, use 136.56103348731995 seconds, loss -0.03212948266207452\n",
      "\n",
      "trained 24816 images, use 140.66665887832642 seconds, loss -0.03212779578903618\n",
      "\n",
      "trained 25616 images, use 145.14540433883667 seconds, loss -0.031865846392597395\n",
      "\n",
      "trained 26416 images, use 149.9964873790741 seconds, loss -0.03194117440604202\n",
      "\n",
      "trained 27216 images, use 154.49453377723694 seconds, loss -0.03185894677150443\n",
      "\n",
      "trained 28016 images, use 159.40209460258484 seconds, loss -0.03189643679036297\n",
      "\n",
      "trained 28816 images, use 164.01393246650696 seconds, loss -0.03172079127224004\n",
      "\n",
      "trained 29616 images, use 168.5473210811615 seconds, loss -0.03170152703085534\n",
      "\n",
      "trained 30416 images, use 173.19821643829346 seconds, loss -0.0316129402317151\n",
      "\n",
      "trained 31216 images, use 177.83926224708557 seconds, loss -0.031733309587389485\n",
      "\n",
      "trained 32016 images, use 182.1731939315796 seconds, loss -0.0317275379337106\n",
      "\n",
      "trained 32816 images, use 187.15792560577393 seconds, loss -0.03162779317422556\n",
      "\n",
      "trained 33616 images, use 193.89237785339355 seconds, loss -0.0317910389216135\n",
      "\n",
      "trained 34416 images, use 202.80139994621277 seconds, loss -0.031735957912583324\n",
      "\n",
      "trained 35216 images, use 210.7295699119568 seconds, loss -0.03173915438682687\n",
      "\n",
      "trained 36016 images, use 217.3108673095703 seconds, loss -0.031699239407299115\n",
      "\n",
      "trained 36816 images, use 224.2730941772461 seconds, loss -0.03164559607592151\n",
      "\n",
      "trained 37616 images, use 231.4876959323883 seconds, loss -0.031470623651651486\n",
      "\n",
      "trained 38416 images, use 236.47922086715698 seconds, loss -0.03144651950579367\n",
      "\n",
      "trained 39216 images, use 242.7057399749756 seconds, loss -0.03147065864447133\n",
      "\n",
      "trained 40016 images, use 248.43504190444946 seconds, loss -0.03147637594181041\n",
      "\n",
      "trained 40816 images, use 254.14954590797424 seconds, loss -0.031466667830340654\n",
      "\n",
      "trained 41616 images, use 259.5861756801605 seconds, loss -0.031490711487497915\n",
      "\n",
      "trained 42416 images, use 265.0765700340271 seconds, loss -0.031606074221080076\n",
      "\n",
      "trained 43216 images, use 270.14084124565125 seconds, loss -0.03153810857308941\n",
      "\n",
      "trained 44016 images, use 275.6198470592499 seconds, loss -0.03139617850305424\n",
      "\n",
      "trained 44816 images, use 281.3824007511139 seconds, loss -0.031399468463316905\n",
      "\n",
      "trained 45616 images, use 286.59189438819885 seconds, loss -0.031229845919071988\n",
      "\n",
      "trained 46416 images, use 291.93884778022766 seconds, loss -0.031241608869621264\n",
      "\n",
      "trained 47216 images, use 296.57007360458374 seconds, loss -0.031292647045053544\n",
      "\n",
      "trained 48016 images, use 301.76375007629395 seconds, loss -0.03127231667516021\n",
      "\n",
      "trained 48816 images, use 306.6203866004944 seconds, loss -0.03136157712861841\n",
      "\n",
      "trained 49616 images, use 311.25677514076233 seconds, loss -0.031360276852570985\n",
      "\n",
      "trained 50416 images, use 316.4566099643707 seconds, loss -0.03134788846257627\n",
      "\n",
      "trained 51216 images, use 321.43974566459656 seconds, loss -0.03129398668340194\n",
      "\n",
      "trained 52016 images, use 326.5035264492035 seconds, loss -0.03140338757715044\n",
      "\n",
      "trained 52816 images, use 331.76223587989807 seconds, loss -0.03137796387205016\n",
      "\n",
      "trained 53616 images, use 337.08134293556213 seconds, loss -0.031479190112465076\n",
      "\n",
      "trained 54416 images, use 343.5272035598755 seconds, loss -0.03149806436927041\n",
      "\n",
      "trained 55216 images, use 348.9275817871094 seconds, loss -0.03138872340688256\n",
      "\n",
      "trained 56016 images, use 354.13738560676575 seconds, loss -0.031262819967694255\n",
      "\n",
      "trained 56816 images, use 360.00016236305237 seconds, loss -0.031244900233129196\n",
      "\n",
      "trained 57616 images, use 366.03475403785706 seconds, loss -0.031312815000358346\n",
      "\n",
      "trained 58416 images, use 372.15484070777893 seconds, loss -0.031236650742428075\n",
      "\n",
      "trained 59216 images, use 377.4249300956726 seconds, loss -0.03127574590595549\n",
      "\n",
      "trained 60016 images, use 383.54446816444397 seconds, loss -0.031249093486513384\n",
      "\n",
      "trained 60816 images, use 388.3927149772644 seconds, loss -0.03128775389702139\n",
      "\n",
      "trained 61616 images, use 393.5805068016052 seconds, loss -0.031306230981170226\n",
      "\n",
      "trained 62416 images, use 398.7223811149597 seconds, loss -0.03130746498022532\n",
      "\n",
      "trained 63216 images, use 403.9543879032135 seconds, loss -0.031215059333571105\n",
      "\n",
      "trained 64016 images, use 409.48021030426025 seconds, loss -0.031138663091686076\n",
      "\n",
      "trained 64816 images, use 414.9202229976654 seconds, loss -0.031076238961810155\n",
      "\n",
      "trained 65616 images, use 420.2011594772339 seconds, loss -0.031048524372146998\n",
      "\n",
      "trained 66416 images, use 425.03040170669556 seconds, loss -0.03103378371306012\n",
      "\n",
      "trained 67216 images, use 431.3330624103546 seconds, loss -0.031033267427666756\n",
      "\n",
      "trained 68016 images, use 436.30505108833313 seconds, loss -0.031027511836049033\n",
      "\n",
      "trained 68816 images, use 441.14921402931213 seconds, loss -0.031059626258228005\n",
      "\n",
      "trained 69616 images, use 446.03464913368225 seconds, loss -0.031023591083676944\n",
      "\n",
      "trained 70416 images, use 451.38381934165955 seconds, loss -0.03100313631902445\n",
      "\n",
      "trained 71216 images, use 456.44385528564453 seconds, loss -0.030989684371291938\n",
      "\n",
      "trained 72016 images, use 461.8415377140045 seconds, loss -0.030942983039731992\n",
      "\n",
      "trained 72816 images, use 465.9216694831848 seconds, loss -0.030963791170939108\n",
      "\n",
      "trained 73616 images, use 471.36144828796387 seconds, loss -0.031002157641929148\n",
      "\n",
      "trained 74416 images, use 476.09664940834045 seconds, loss -0.031057184053351658\n",
      "\n",
      "trained 75216 images, use 480.9864852428436 seconds, loss -0.031029115495990755\n",
      "\n",
      "trained 76016 images, use 485.25177335739136 seconds, loss -0.031030941693456122\n",
      "\n",
      "trained 76816 images, use 489.9641342163086 seconds, loss -0.03103717144462843\n",
      "\n",
      "trained 77616 images, use 495.06559205055237 seconds, loss -0.03102818154763512\n",
      "\n",
      "trained 78416 images, use 499.7144944667816 seconds, loss -0.031023828001408637\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 504.01982259750366 seconds, loss -0.03103491044397673\n",
      "\n",
      "trained 80016 images, use 508.8965268135071 seconds, loss -0.03105021257654759\n",
      "\n",
      "trained 80816 images, use 513.590692281723 seconds, loss -0.03109980010740649\n",
      "\n",
      "trained 81616 images, use 518.3702178001404 seconds, loss -0.031162611215417853\n",
      "\n",
      "trained 82416 images, use 522.5661778450012 seconds, loss -0.031152714962897943\n",
      "\n",
      "trained 83216 images, use 527.6421527862549 seconds, loss -0.031165551479706878\n",
      "\n",
      "trained 84016 images, use 532.2243795394897 seconds, loss -0.031233047764702888\n",
      "\n",
      "trained 84816 images, use 536.7522165775299 seconds, loss -0.031235752093602114\n",
      "\n",
      "trained 85616 images, use 541.4937150478363 seconds, loss -0.031229282376822435\n",
      "\n",
      "trained 86416 images, use 545.9842512607574 seconds, loss -0.03131804904432632\n",
      "\n",
      "trained 87216 images, use 550.9421894550323 seconds, loss -0.031265303345534484\n",
      "\n",
      "trained 88016 images, use 555.6619603633881 seconds, loss -0.03125379856576208\n",
      "\n",
      "trained 88816 images, use 560.393239736557 seconds, loss -0.03127248658746781\n",
      "\n",
      "trained 89616 images, use 565.0613870620728 seconds, loss -0.031240791989094234\n",
      "\n",
      "trained 90416 images, use 569.8632972240448 seconds, loss -0.031200032557567273\n",
      "\n",
      "trained 91216 images, use 574.8008363246918 seconds, loss -0.03125316599880068\n",
      "\n",
      "trained 92016 images, use 579.2533144950867 seconds, loss -0.0312404538546268\n",
      "\n",
      "trained 92816 images, use 583.8994691371918 seconds, loss -0.03125730877034675\n",
      "\n",
      "trained 93616 images, use 588.7565972805023 seconds, loss -0.03127006337972542\n",
      "\n",
      "trained 94416 images, use 593.2664415836334 seconds, loss -0.031289865104612666\n",
      "\n",
      "trained 95216 images, use 598.0250751972198 seconds, loss -0.031258906610595945\n",
      "\n",
      "trained 96016 images, use 602.3509411811829 seconds, loss -0.031197523802320583\n",
      "\n",
      "trained 96816 images, use 606.7202572822571 seconds, loss -0.03120230349661896\n",
      "\n",
      "trained 97616 images, use 611.7813465595245 seconds, loss -0.031146026305458745\n",
      "\n",
      "trained 98416 images, use 616.1589391231537 seconds, loss -0.031143996052515912\n",
      "\n",
      "trained 99216 images, use 620.409117937088 seconds, loss -0.031238212726089145\n",
      "\n",
      "*************Epoch 15 Avrg Training loss -0.031289136118088576 Elapsed 625.1842775344849\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.786021440857635\n",
      "************* Validation: total 99996 precision 0.9694316344082335 avgTime 0.005959919519083773\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 16 started at 1619477116.0256739\n",
      "trained 16 images, use 1.5294513702392578 seconds, loss -0.020128195641973434\n",
      "\n",
      "trained 816 images, use 6.3721654415130615 seconds, loss -0.030848386905142015\n",
      "\n",
      "trained 1616 images, use 10.507042169570923 seconds, loss -0.03022353098043484\n",
      "\n",
      "trained 2416 images, use 15.177631378173828 seconds, loss -0.03079101825026878\n",
      "\n",
      "trained 3216 images, use 19.884533643722534 seconds, loss -0.029568676971517688\n",
      "\n",
      "trained 4016 images, use 24.871106147766113 seconds, loss -0.028622884265480878\n",
      "\n",
      "trained 4816 images, use 29.93127417564392 seconds, loss -0.030409725947554655\n",
      "\n",
      "trained 5616 images, use 35.04022574424744 seconds, loss -0.031016089414727978\n",
      "\n",
      "trained 6416 images, use 39.302769899368286 seconds, loss -0.031600577018449635\n",
      "\n",
      "trained 7216 images, use 44.07044696807861 seconds, loss -0.030699393859015444\n",
      "\n",
      "trained 8016 images, use 48.357959270477295 seconds, loss -0.031500601447172434\n",
      "\n",
      "trained 8816 images, use 53.36264181137085 seconds, loss -0.031341897567944234\n",
      "\n",
      "trained 9616 images, use 57.913225412368774 seconds, loss -0.03140879575100622\n",
      "\n",
      "trained 10416 images, use 62.39037752151489 seconds, loss -0.03140997204999945\n",
      "\n",
      "trained 11216 images, use 67.61072659492493 seconds, loss -0.031682212475930865\n",
      "\n",
      "trained 12016 images, use 72.37276458740234 seconds, loss -0.031515525516071306\n",
      "\n",
      "trained 12816 images, use 76.96707534790039 seconds, loss -0.03133329825589855\n",
      "\n",
      "trained 13616 images, use 81.19747614860535 seconds, loss -0.03120469982408322\n",
      "\n",
      "trained 14416 images, use 86.4005560874939 seconds, loss -0.03142652841040999\n",
      "\n",
      "trained 15216 images, use 91.27320909500122 seconds, loss -0.031351077543196396\n",
      "\n",
      "trained 16016 images, use 95.8329770565033 seconds, loss -0.03139828862181012\n",
      "\n",
      "trained 16816 images, use 100.03024673461914 seconds, loss -0.031348287288932374\n",
      "\n",
      "trained 17616 images, use 104.05255436897278 seconds, loss -0.0314378167762105\n",
      "\n",
      "trained 18416 images, use 109.23219895362854 seconds, loss -0.03151017925535626\n",
      "\n",
      "trained 19216 images, use 113.55592894554138 seconds, loss -0.03165647801628727\n",
      "\n",
      "trained 20016 images, use 117.89558696746826 seconds, loss -0.031418747730012096\n",
      "\n",
      "trained 20816 images, use 122.55611538887024 seconds, loss -0.03088519863809184\n",
      "\n",
      "trained 21616 images, use 127.1559808254242 seconds, loss -0.03080311958774944\n",
      "\n",
      "trained 22416 images, use 132.12925696372986 seconds, loss -0.030870894937182928\n",
      "\n",
      "trained 23216 images, use 136.66027736663818 seconds, loss -0.030665409013019257\n",
      "\n",
      "trained 24016 images, use 140.7580714225769 seconds, loss -0.031040631948637938\n",
      "\n",
      "trained 24816 images, use 145.42117595672607 seconds, loss -0.030967748937459978\n",
      "\n",
      "trained 25616 images, use 150.2619435787201 seconds, loss -0.031112768785401833\n",
      "\n",
      "trained 26416 images, use 154.29904913902283 seconds, loss -0.031211056309714543\n",
      "\n",
      "trained 27216 images, use 158.7366428375244 seconds, loss -0.031187270462418596\n",
      "\n",
      "trained 28016 images, use 163.2468066215515 seconds, loss -0.031381712570641145\n",
      "\n",
      "trained 28816 images, use 167.638347864151 seconds, loss -0.03123479370303151\n",
      "\n",
      "trained 29616 images, use 171.95502352714539 seconds, loss -0.031073416877942222\n",
      "\n",
      "trained 30416 images, use 176.55436515808105 seconds, loss -0.03090155086550872\n",
      "\n",
      "trained 31216 images, use 181.14022994041443 seconds, loss -0.030808180951042142\n",
      "\n",
      "trained 32016 images, use 185.14905095100403 seconds, loss -0.0309029048863312\n",
      "\n",
      "trained 32816 images, use 190.08374571800232 seconds, loss -0.030905350508436423\n",
      "\n",
      "trained 33616 images, use 194.15498232841492 seconds, loss -0.030993237667006294\n",
      "\n",
      "trained 34416 images, use 198.71320462226868 seconds, loss -0.03118185384451532\n",
      "\n",
      "trained 35216 images, use 203.47732877731323 seconds, loss -0.03126029171756757\n",
      "\n",
      "trained 36016 images, use 207.77375507354736 seconds, loss -0.031106731135833433\n",
      "\n",
      "trained 36816 images, use 212.6135756969452 seconds, loss -0.03119378332386509\n",
      "\n",
      "trained 37616 images, use 217.37544965744019 seconds, loss -0.03104174763298936\n",
      "\n",
      "trained 38416 images, use 222.64601707458496 seconds, loss -0.030974076710668985\n",
      "\n",
      "trained 39216 images, use 226.86164665222168 seconds, loss -0.030948527591038555\n",
      "\n",
      "trained 40016 images, use 231.48053288459778 seconds, loss -0.030918825574770735\n",
      "\n",
      "trained 40816 images, use 235.90066027641296 seconds, loss -0.030920561512434306\n",
      "\n",
      "trained 41616 images, use 241.0121214389801 seconds, loss -0.03094736043475145\n",
      "\n",
      "trained 42416 images, use 245.58856105804443 seconds, loss -0.030789764726050873\n",
      "\n",
      "trained 43216 images, use 249.8303461074829 seconds, loss -0.030920733207864953\n",
      "\n",
      "trained 44016 images, use 254.39517998695374 seconds, loss -0.030959254951572035\n",
      "\n",
      "trained 44816 images, use 259.0891363620758 seconds, loss -0.03102952794500145\n",
      "\n",
      "trained 45616 images, use 263.52293062210083 seconds, loss -0.031191928063473175\n",
      "\n",
      "trained 46416 images, use 268.4786591529846 seconds, loss -0.031217608467508203\n",
      "\n",
      "trained 47216 images, use 272.92019605636597 seconds, loss -0.03130870776332132\n",
      "\n",
      "trained 48016 images, use 277.8641502857208 seconds, loss -0.031387339590554564\n",
      "\n",
      "trained 48816 images, use 282.0912916660309 seconds, loss -0.031409792462525635\n",
      "\n",
      "trained 49616 images, use 286.5331246852875 seconds, loss -0.03139240530015623\n",
      "\n",
      "trained 50416 images, use 291.1017258167267 seconds, loss -0.03144784595546346\n",
      "\n",
      "trained 51216 images, use 295.9540069103241 seconds, loss -0.03137083668637325\n",
      "\n",
      "trained 52016 images, use 301.3452844619751 seconds, loss -0.031419286768330446\n",
      "\n",
      "trained 52816 images, use 306.90474009513855 seconds, loss -0.03139775511313834\n",
      "\n",
      "trained 53616 images, use 311.4886190891266 seconds, loss -0.03137769985423783\n",
      "\n",
      "trained 54416 images, use 316.61099219322205 seconds, loss -0.031432027512966816\n",
      "\n",
      "trained 55216 images, use 321.43556451797485 seconds, loss -0.03140431370230261\n",
      "\n",
      "trained 56016 images, use 326.5661714076996 seconds, loss -0.03139723574146325\n",
      "\n",
      "trained 56816 images, use 331.42301893234253 seconds, loss -0.031320802664096654\n",
      "\n",
      "trained 57616 images, use 336.373731136322 seconds, loss -0.031399608430499576\n",
      "\n",
      "trained 58416 images, use 341.710830450058 seconds, loss -0.031394284978370976\n",
      "\n",
      "trained 59216 images, use 346.34814834594727 seconds, loss -0.031390651024657955\n",
      "\n",
      "trained 60016 images, use 352.72305727005005 seconds, loss -0.031363081845675836\n",
      "\n",
      "trained 60816 images, use 358.6231915950775 seconds, loss -0.03136838916099022\n",
      "\n",
      "trained 61616 images, use 363.9077169895172 seconds, loss -0.031362325096085934\n",
      "\n",
      "trained 62416 images, use 370.16243052482605 seconds, loss -0.03140418268184558\n",
      "\n",
      "trained 63216 images, use 375.06286120414734 seconds, loss -0.03141880630358835\n",
      "\n",
      "trained 64016 images, use 379.827433347702 seconds, loss -0.031362022143776286\n",
      "\n",
      "trained 64816 images, use 384.8342583179474 seconds, loss -0.031272571402422664\n",
      "\n",
      "trained 65616 images, use 389.82559275627136 seconds, loss -0.031183902913331257\n",
      "\n",
      "trained 66416 images, use 395.1735348701477 seconds, loss -0.03125336851242736\n",
      "\n",
      "trained 67216 images, use 400.29280066490173 seconds, loss -0.03117255073840535\n",
      "\n",
      "trained 68016 images, use 404.7918484210968 seconds, loss -0.031140047983553954\n",
      "\n",
      "trained 68816 images, use 409.7173664569855 seconds, loss -0.031089468303022692\n",
      "\n",
      "trained 69616 images, use 415.1804201602936 seconds, loss -0.031074743460059694\n",
      "\n",
      "trained 70416 images, use 419.94381380081177 seconds, loss -0.031097764308188787\n",
      "\n",
      "trained 71216 images, use 424.5219795703888 seconds, loss -0.03108227667896979\n",
      "\n",
      "trained 72016 images, use 429.3714015483856 seconds, loss -0.031140174945681286\n",
      "\n",
      "trained 72816 images, use 433.72042536735535 seconds, loss -0.031123530752317576\n",
      "\n",
      "trained 73616 images, use 438.52287316322327 seconds, loss -0.03114577122234668\n",
      "\n",
      "trained 74416 images, use 443.3495090007782 seconds, loss -0.031134126080650377\n",
      "\n",
      "trained 75216 images, use 447.67316484451294 seconds, loss -0.031138626296599452\n",
      "\n",
      "trained 76016 images, use 452.296502828598 seconds, loss -0.031151072530668164\n",
      "\n",
      "trained 76816 images, use 457.0790274143219 seconds, loss -0.03112414279361156\n",
      "\n",
      "trained 77616 images, use 461.76567339897156 seconds, loss -0.031097781436336614\n",
      "\n",
      "trained 78416 images, use 466.4898672103882 seconds, loss -0.031139029739258473\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 471.5715866088867 seconds, loss -0.031169830169244524\n",
      "\n",
      "trained 80016 images, use 476.2160120010376 seconds, loss -0.031184985856153664\n",
      "\n",
      "trained 80816 images, use 481.0253930091858 seconds, loss -0.031191221031633406\n",
      "\n",
      "trained 81616 images, use 485.695219039917 seconds, loss -0.031183652534922793\n",
      "\n",
      "trained 82416 images, use 490.80702567100525 seconds, loss -0.03117692875428389\n",
      "\n",
      "trained 83216 images, use 495.2626111507416 seconds, loss -0.031139228055019095\n",
      "\n",
      "trained 84016 images, use 500.2194330692291 seconds, loss -0.03119542231003028\n",
      "\n",
      "trained 84816 images, use 504.717547416687 seconds, loss -0.03119308200523523\n",
      "\n",
      "trained 85616 images, use 508.91257882118225 seconds, loss -0.031261052119801375\n",
      "\n",
      "trained 86416 images, use 514.0001237392426 seconds, loss -0.03127419991366004\n",
      "\n",
      "trained 87216 images, use 518.8845446109772 seconds, loss -0.031181172862557623\n",
      "\n",
      "trained 88016 images, use 523.4789946079254 seconds, loss -0.0311385686304174\n",
      "\n",
      "trained 88816 images, use 528.2037825584412 seconds, loss -0.031148536391650303\n",
      "\n",
      "trained 89616 images, use 532.5377902984619 seconds, loss -0.03115406395041436\n",
      "\n",
      "trained 90416 images, use 537.3974902629852 seconds, loss -0.031167335665761468\n",
      "\n",
      "trained 91216 images, use 542.1557722091675 seconds, loss -0.031111649142027555\n",
      "\n",
      "trained 92016 images, use 546.3763847351074 seconds, loss -0.031146542308954823\n",
      "\n",
      "trained 92816 images, use 551.1260118484497 seconds, loss -0.031213836833286504\n",
      "\n",
      "trained 93616 images, use 555.5525586605072 seconds, loss -0.031245112879199\n",
      "\n",
      "trained 94416 images, use 560.2757134437561 seconds, loss -0.031239840398350694\n",
      "\n",
      "trained 95216 images, use 565.4566414356232 seconds, loss -0.031181357164495552\n",
      "\n",
      "trained 96016 images, use 570.2474927902222 seconds, loss -0.03119025686268262\n",
      "\n",
      "trained 96816 images, use 575.006285905838 seconds, loss -0.031234720766443444\n",
      "\n",
      "trained 97616 images, use 579.628648519516 seconds, loss -0.031222497856097185\n",
      "\n",
      "trained 98416 images, use 584.7335216999054 seconds, loss -0.03124805930840787\n",
      "\n",
      "trained 99216 images, use 589.1931486129761 seconds, loss -0.031217284147265715\n",
      "\n",
      "*************Epoch 16 Avrg Training loss -0.03127485094426236 Elapsed 593.4518938064575\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.785801432057283\n",
      "************* Validation: total 99996 precision 0.9694002045796118 avgTime 0.005878907429456205\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 17 started at 1619478297.7838228\n",
      "trained 16 images, use 1.4301316738128662 seconds, loss -0.12324247136712074\n",
      "\n",
      "trained 816 images, use 5.343166351318359 seconds, loss -0.03079227494128225\n",
      "\n",
      "trained 1616 images, use 9.986927032470703 seconds, loss -0.029496245218466607\n",
      "\n",
      "trained 2416 images, use 13.90307903289795 seconds, loss -0.02729889688434265\n",
      "\n",
      "trained 3216 images, use 18.757620334625244 seconds, loss -0.028799933230708695\n",
      "\n",
      "trained 4016 images, use 22.674922227859497 seconds, loss -0.02926723596108007\n",
      "\n",
      "trained 4816 images, use 27.692071199417114 seconds, loss -0.02907987145252547\n",
      "\n",
      "trained 5616 images, use 31.601472854614258 seconds, loss -0.02883671770421162\n",
      "\n",
      "trained 6416 images, use 36.199995279312134 seconds, loss -0.02859586176665703\n",
      "\n",
      "trained 7216 images, use 41.08968663215637 seconds, loss -0.029847855732282068\n",
      "\n",
      "trained 8016 images, use 45.53208112716675 seconds, loss -0.030098013837905037\n",
      "\n",
      "trained 8816 images, use 49.87982797622681 seconds, loss -0.02980484919388499\n",
      "\n",
      "trained 9616 images, use 54.604536294937134 seconds, loss -0.030629142628669778\n",
      "\n",
      "trained 10416 images, use 59.19341850280762 seconds, loss -0.030529918272406333\n",
      "\n",
      "trained 11216 images, use 63.796915769577026 seconds, loss -0.029898221317083286\n",
      "\n",
      "trained 12016 images, use 68.32643127441406 seconds, loss -0.030230226572508033\n",
      "\n",
      "trained 12816 images, use 73.04207229614258 seconds, loss -0.030200686298146588\n",
      "\n",
      "trained 13616 images, use 77.50984764099121 seconds, loss -0.030239617183477622\n",
      "\n",
      "trained 14416 images, use 82.2197494506836 seconds, loss -0.030408641121600407\n",
      "\n",
      "trained 15216 images, use 86.68765497207642 seconds, loss -0.030359608089209393\n",
      "\n",
      "trained 16016 images, use 91.50061058998108 seconds, loss -0.030486624562846842\n",
      "\n",
      "trained 16816 images, use 95.90877866744995 seconds, loss -0.03031068793410376\n",
      "\n",
      "trained 17616 images, use 100.15796732902527 seconds, loss -0.030228301859172902\n",
      "\n",
      "trained 18416 images, use 104.71086645126343 seconds, loss -0.030559575814452542\n",
      "\n",
      "trained 19216 images, use 109.15186548233032 seconds, loss -0.030611363805331027\n",
      "\n",
      "trained 20016 images, use 113.52433156967163 seconds, loss -0.03055577743633841\n",
      "\n",
      "trained 20816 images, use 119.33617615699768 seconds, loss -0.030851329557905163\n",
      "\n",
      "trained 21616 images, use 123.00762176513672 seconds, loss -0.030868744018582393\n",
      "\n",
      "trained 22416 images, use 128.07466530799866 seconds, loss -0.03060093952095724\n",
      "\n",
      "trained 23216 images, use 132.4428424835205 seconds, loss -0.030418633055816675\n",
      "\n",
      "trained 24016 images, use 136.81177353858948 seconds, loss -0.030546008199797667\n",
      "\n",
      "trained 24816 images, use 141.63390827178955 seconds, loss -0.030595665473957014\n",
      "\n",
      "trained 25616 images, use 146.28932118415833 seconds, loss -0.030656064722299706\n",
      "\n",
      "trained 26416 images, use 150.478125333786 seconds, loss -0.03065915908367024\n",
      "\n",
      "trained 27216 images, use 155.22284030914307 seconds, loss -0.030515566682865952\n",
      "\n",
      "trained 28016 images, use 160.05663776397705 seconds, loss -0.030505676140393106\n",
      "\n",
      "trained 28816 images, use 164.2522840499878 seconds, loss -0.030550343947103813\n",
      "\n",
      "trained 29616 images, use 168.8126769065857 seconds, loss -0.030508241478260336\n",
      "\n",
      "trained 30416 images, use 173.2931318283081 seconds, loss -0.030394908685620947\n",
      "\n",
      "trained 31216 images, use 177.4504644870758 seconds, loss -0.030402554871012514\n",
      "\n",
      "trained 32016 images, use 181.800475358963 seconds, loss -0.03036627033479313\n",
      "\n",
      "trained 32816 images, use 186.02870154380798 seconds, loss -0.03036631263224982\n",
      "\n",
      "trained 33616 images, use 190.89298820495605 seconds, loss -0.03054273962220253\n",
      "\n",
      "trained 34416 images, use 195.5468351840973 seconds, loss -0.030699580635483358\n",
      "\n",
      "trained 35216 images, use 199.70139908790588 seconds, loss -0.030677058688788922\n",
      "\n",
      "trained 36016 images, use 204.01247715950012 seconds, loss -0.03058239205318776\n",
      "\n",
      "trained 36816 images, use 208.40824604034424 seconds, loss -0.03061361554267167\n",
      "\n",
      "trained 37616 images, use 212.76365065574646 seconds, loss -0.03069527921429725\n",
      "\n",
      "trained 38416 images, use 216.97431015968323 seconds, loss -0.03080543981783926\n",
      "\n",
      "trained 39216 images, use 221.80175375938416 seconds, loss -0.030683998287139903\n",
      "\n",
      "trained 40016 images, use 226.55447459220886 seconds, loss -0.030823549669756645\n",
      "\n",
      "trained 40816 images, use 231.40715169906616 seconds, loss -0.030814460799615997\n",
      "\n",
      "trained 41616 images, use 235.91536617279053 seconds, loss -0.030829186530211442\n",
      "\n",
      "trained 42416 images, use 240.5193772315979 seconds, loss -0.031018490496776213\n",
      "\n",
      "trained 43216 images, use 245.24468207359314 seconds, loss -0.031161471793606857\n",
      "\n",
      "trained 44016 images, use 249.6207718849182 seconds, loss -0.031095840329321417\n",
      "\n",
      "trained 44816 images, use 254.11325359344482 seconds, loss -0.031225605493843105\n",
      "\n",
      "trained 45616 images, use 258.7851095199585 seconds, loss -0.031172897932691474\n",
      "\n",
      "trained 46416 images, use 262.84847927093506 seconds, loss -0.031223084932524483\n",
      "\n",
      "trained 47216 images, use 267.74290561676025 seconds, loss -0.031230219414868744\n",
      "\n",
      "trained 48016 images, use 272.4129891395569 seconds, loss -0.031112507348138602\n",
      "\n",
      "trained 48816 images, use 277.24849820137024 seconds, loss -0.03114207363495094\n",
      "\n",
      "trained 49616 images, use 282.11746859550476 seconds, loss -0.031143287895624684\n",
      "\n",
      "trained 50416 images, use 286.89209938049316 seconds, loss -0.031173799550442177\n",
      "\n",
      "trained 51216 images, use 291.17522621154785 seconds, loss -0.031200702682771753\n",
      "\n",
      "trained 52016 images, use 295.64931416511536 seconds, loss -0.031171070852373212\n",
      "\n",
      "trained 52816 images, use 300.2813048362732 seconds, loss -0.031188755344746598\n",
      "\n",
      "trained 53616 images, use 304.6989629268646 seconds, loss -0.03107998826529925\n",
      "\n",
      "trained 54416 images, use 309.04975986480713 seconds, loss -0.03115790423535137\n",
      "\n",
      "trained 55216 images, use 313.4944109916687 seconds, loss -0.031050961949927798\n",
      "\n",
      "trained 56016 images, use 317.5861613750458 seconds, loss -0.03106479889307621\n",
      "\n",
      "trained 56816 images, use 321.9505264759064 seconds, loss -0.031091822738216243\n",
      "\n",
      "trained 57616 images, use 326.5427191257477 seconds, loss -0.03101280841621853\n",
      "\n",
      "trained 58416 images, use 331.4355356693268 seconds, loss -0.031121022627302757\n",
      "\n",
      "trained 59216 images, use 335.88366055488586 seconds, loss -0.03100691166824628\n",
      "\n",
      "trained 60016 images, use 341.4961063861847 seconds, loss -0.030895020537506333\n",
      "\n",
      "trained 60816 images, use 345.60500860214233 seconds, loss -0.030919939611755255\n",
      "\n",
      "trained 61616 images, use 350.4846730232239 seconds, loss -0.031021505854674374\n",
      "\n",
      "trained 62416 images, use 355.58470344543457 seconds, loss -0.030955504630997412\n",
      "\n",
      "trained 63216 images, use 359.89276933670044 seconds, loss -0.030924233411228345\n",
      "\n",
      "trained 64016 images, use 364.434339761734 seconds, loss -0.0309273122655409\n",
      "\n",
      "trained 64816 images, use 369.4477984905243 seconds, loss -0.030965283869151983\n",
      "\n",
      "trained 65616 images, use 374.4636890888214 seconds, loss -0.030990597872003926\n",
      "\n",
      "trained 66416 images, use 378.9395184516907 seconds, loss -0.031036047214315177\n",
      "\n",
      "trained 67216 images, use 383.6988215446472 seconds, loss -0.03113585690293763\n",
      "\n",
      "trained 68016 images, use 388.5081753730774 seconds, loss -0.031089609645878532\n",
      "\n",
      "trained 68816 images, use 393.334299325943 seconds, loss -0.03119414738182693\n",
      "\n",
      "trained 69616 images, use 398.1784484386444 seconds, loss -0.031198126145826954\n",
      "\n",
      "trained 70416 images, use 403.6093499660492 seconds, loss -0.03114315977220378\n",
      "\n",
      "trained 71216 images, use 408.0783145427704 seconds, loss -0.031092221384706548\n",
      "\n",
      "trained 72016 images, use 412.79951095581055 seconds, loss -0.031034410355292114\n",
      "\n",
      "trained 72816 images, use 417.76100277900696 seconds, loss -0.03118304327658917\n",
      "\n",
      "trained 73616 images, use 422.5185914039612 seconds, loss -0.031199246984570963\n",
      "\n",
      "trained 74416 images, use 426.93347358703613 seconds, loss -0.031211424078161843\n",
      "\n",
      "trained 75216 images, use 431.5526180267334 seconds, loss -0.03120762056289308\n",
      "\n",
      "trained 76016 images, use 436.1648943424225 seconds, loss -0.03119835235687148\n",
      "\n",
      "trained 76816 images, use 440.73417353630066 seconds, loss -0.031206828173962472\n",
      "\n",
      "trained 77616 images, use 445.3474004268646 seconds, loss -0.031315702038522186\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 78416 images, use 450.1793611049652 seconds, loss -0.03139532484995231\n",
      "\n",
      "trained 79216 images, use 455.1869566440582 seconds, loss -0.0313819802948285\n",
      "\n",
      "trained 80016 images, use 460.00911045074463 seconds, loss -0.03132363596435701\n",
      "\n",
      "trained 80816 images, use 464.29125452041626 seconds, loss -0.03133245281392137\n",
      "\n",
      "trained 81616 images, use 469.10287261009216 seconds, loss -0.03132986188056697\n",
      "\n",
      "trained 82416 images, use 473.9241786003113 seconds, loss -0.03133790905853648\n",
      "\n",
      "trained 83216 images, use 478.79474091529846 seconds, loss -0.031313288522346265\n",
      "\n",
      "trained 84016 images, use 482.96513628959656 seconds, loss -0.031403445623440406\n",
      "\n",
      "trained 84816 images, use 487.6349108219147 seconds, loss -0.0313512986586386\n",
      "\n",
      "trained 85616 images, use 492.12034940719604 seconds, loss -0.031427949620701244\n",
      "\n",
      "trained 86416 images, use 496.74894547462463 seconds, loss -0.03146774564631494\n",
      "\n",
      "trained 87216 images, use 501.6271481513977 seconds, loss -0.031425839808145194\n",
      "\n",
      "trained 88016 images, use 506.25311493873596 seconds, loss -0.031418970616372104\n",
      "\n",
      "trained 88816 images, use 510.93363642692566 seconds, loss -0.03138722349679427\n",
      "\n",
      "trained 89616 images, use 515.7903687953949 seconds, loss -0.03133841619316673\n",
      "\n",
      "trained 90416 images, use 520.6239614486694 seconds, loss -0.03133615249183508\n",
      "\n",
      "trained 91216 images, use 525.2801592350006 seconds, loss -0.031298599879525255\n",
      "\n",
      "trained 92016 images, use 529.3972871303558 seconds, loss -0.031248325557661053\n",
      "\n",
      "trained 92816 images, use 534.3711521625519 seconds, loss -0.031242006605670655\n",
      "\n",
      "trained 93616 images, use 538.6413197517395 seconds, loss -0.031289463195268256\n",
      "\n",
      "trained 94416 images, use 543.0138499736786 seconds, loss -0.03126112352395322\n",
      "\n",
      "trained 95216 images, use 547.5613415241241 seconds, loss -0.03129121690590968\n",
      "\n",
      "trained 96016 images, use 552.1680066585541 seconds, loss -0.03124487180503744\n",
      "\n",
      "trained 96816 images, use 556.6253187656403 seconds, loss -0.03126888063256812\n",
      "\n",
      "trained 97616 images, use 561.5752861499786 seconds, loss -0.031242460759017637\n",
      "\n",
      "trained 98416 images, use 566.2743241786957 seconds, loss -0.03128001936359106\n",
      "\n",
      "trained 99216 images, use 570.8493571281433 seconds, loss -0.031227818627409285\n",
      "\n",
      "*************Epoch 17 Avrg Training loss -0.031273722579961395 Elapsed 575.1727373600006\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.786061442457698\n",
      "************* Validation: total 99996 precision 0.9694373489225283 avgTime 0.006150020232720014\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 18 started at 1619479488.6903117\n",
      "trained 16 images, use 3.6041784286499023 seconds, loss -0.019441255326000828\n",
      "\n",
      "trained 816 images, use 6.642674684524536 seconds, loss -0.03179305092315259\n",
      "\n",
      "trained 1616 images, use 11.405667304992676 seconds, loss -0.030562690349923143\n",
      "\n",
      "trained 2416 images, use 15.865972757339478 seconds, loss -0.03204282075340583\n",
      "\n",
      "trained 3216 images, use 20.06951117515564 seconds, loss -0.03151584688410115\n",
      "\n",
      "trained 4016 images, use 24.665873765945435 seconds, loss -0.03221742757425148\n",
      "\n",
      "trained 4816 images, use 28.901097536087036 seconds, loss -0.03193427521350051\n",
      "\n",
      "trained 5616 images, use 33.27686071395874 seconds, loss -0.03223590825098199\n",
      "\n",
      "trained 6416 images, use 37.89066767692566 seconds, loss -0.032531583458431844\n",
      "\n",
      "trained 7216 images, use 42.46807646751404 seconds, loss -0.032765911051310104\n",
      "\n",
      "trained 8016 images, use 46.98377752304077 seconds, loss -0.03249090605275802\n",
      "\n",
      "trained 8816 images, use 51.38996887207031 seconds, loss -0.03218070750181289\n",
      "\n",
      "trained 9616 images, use 56.01403880119324 seconds, loss -0.032255209922774926\n",
      "\n",
      "trained 10416 images, use 60.55023670196533 seconds, loss -0.03175006302036236\n",
      "\n",
      "trained 11216 images, use 65.98724937438965 seconds, loss -0.031605945969631725\n",
      "\n",
      "trained 12016 images, use 71.19949722290039 seconds, loss -0.0316964773685014\n",
      "\n",
      "trained 12816 images, use 76.31020259857178 seconds, loss -0.031680156919026696\n",
      "\n",
      "trained 13616 images, use 82.51714277267456 seconds, loss -0.03154199528319595\n",
      "\n",
      "trained 14416 images, use 89.11227011680603 seconds, loss -0.03140509223839471\n",
      "\n",
      "trained 15216 images, use 99.03372001647949 seconds, loss -0.031018340658944616\n",
      "\n",
      "trained 16016 images, use 107.13639545440674 seconds, loss -0.03107978676261193\n",
      "\n",
      "trained 16816 images, use 114.80635666847229 seconds, loss -0.03137929404523175\n",
      "\n",
      "trained 17616 images, use 123.87402319908142 seconds, loss -0.031044295350611744\n",
      "\n",
      "trained 18416 images, use 131.40416622161865 seconds, loss -0.03084922491045007\n",
      "\n",
      "trained 19216 images, use 139.61947441101074 seconds, loss -0.030736256982257557\n",
      "\n",
      "trained 20016 images, use 146.7390205860138 seconds, loss -0.030593609088343666\n",
      "\n",
      "trained 20816 images, use 153.56067299842834 seconds, loss -0.030816939598852677\n",
      "\n",
      "trained 21616 images, use 158.63100743293762 seconds, loss -0.0309663740982719\n",
      "\n",
      "trained 22416 images, use 163.72752118110657 seconds, loss -0.031047203342788834\n",
      "\n",
      "trained 23216 images, use 169.1550326347351 seconds, loss -0.031005700265426078\n",
      "\n",
      "trained 24016 images, use 174.9823100566864 seconds, loss -0.03098734608982667\n",
      "\n",
      "trained 24816 images, use 181.1379051208496 seconds, loss -0.030984953429362746\n",
      "\n",
      "trained 25616 images, use 186.34655332565308 seconds, loss -0.03106122531810047\n",
      "\n",
      "trained 26416 images, use 191.82346773147583 seconds, loss -0.03104934209972718\n",
      "\n",
      "trained 27216 images, use 197.7264907360077 seconds, loss -0.0309728863165801\n",
      "\n",
      "trained 28016 images, use 203.09181785583496 seconds, loss -0.031039338687202163\n",
      "\n",
      "trained 28816 images, use 209.0096082687378 seconds, loss -0.0311896346307944\n",
      "\n",
      "trained 29616 images, use 214.23748302459717 seconds, loss -0.031188821088333107\n",
      "\n",
      "trained 30416 images, use 219.0932171344757 seconds, loss -0.031202543831999698\n",
      "\n",
      "trained 31216 images, use 224.35815143585205 seconds, loss -0.031348363870990416\n",
      "\n",
      "trained 32016 images, use 229.88225173950195 seconds, loss -0.031524867113344984\n",
      "\n",
      "trained 32816 images, use 234.98740553855896 seconds, loss -0.031606464460961554\n",
      "\n",
      "trained 33616 images, use 239.86723041534424 seconds, loss -0.03157372851271358\n",
      "\n",
      "trained 34416 images, use 244.8184108734131 seconds, loss -0.03171366117638508\n",
      "\n",
      "trained 35216 images, use 250.20091843605042 seconds, loss -0.03162932615318274\n",
      "\n",
      "trained 36016 images, use 254.90967655181885 seconds, loss -0.031606261696112165\n",
      "\n",
      "trained 36816 images, use 260.60824036598206 seconds, loss -0.03141609808214097\n",
      "\n",
      "trained 37616 images, use 265.50645208358765 seconds, loss -0.031187858121860805\n",
      "\n",
      "trained 38416 images, use 270.24564385414124 seconds, loss -0.031186256420859468\n",
      "\n",
      "trained 39216 images, use 275.3287937641144 seconds, loss -0.031247261860800558\n",
      "\n",
      "trained 40016 images, use 280.07480096817017 seconds, loss -0.031173694307827144\n",
      "\n",
      "trained 40816 images, use 284.45684719085693 seconds, loss -0.031076349888630287\n",
      "\n",
      "trained 41616 images, use 289.16342544555664 seconds, loss -0.031154977083398018\n",
      "\n",
      "trained 42416 images, use 293.9307267665863 seconds, loss -0.031079689401971037\n",
      "\n",
      "trained 43216 images, use 299.246520280838 seconds, loss -0.03095611788250179\n",
      "\n",
      "trained 44016 images, use 303.90661454200745 seconds, loss -0.030923526520671613\n",
      "\n",
      "trained 44816 images, use 309.299284696579 seconds, loss -0.030967877185911076\n",
      "\n",
      "trained 45616 images, use 313.6823890209198 seconds, loss -0.030966240249822995\n",
      "\n",
      "trained 46416 images, use 318.354453086853 seconds, loss -0.030982211911051154\n",
      "\n",
      "trained 47216 images, use 322.8236994743347 seconds, loss -0.0308651994683545\n",
      "\n",
      "trained 48016 images, use 327.7017078399658 seconds, loss -0.030846386819162613\n",
      "\n",
      "trained 48816 images, use 332.6162579059601 seconds, loss -0.03084741431799068\n",
      "\n",
      "trained 49616 images, use 337.96221685409546 seconds, loss -0.030918437447859465\n",
      "\n",
      "trained 50416 images, use 342.81694531440735 seconds, loss -0.030865566541411753\n",
      "\n",
      "trained 51216 images, use 348.59959387779236 seconds, loss -0.030903944557492985\n",
      "\n",
      "trained 52016 images, use 354.06265211105347 seconds, loss -0.030944508408835534\n",
      "\n",
      "trained 52816 images, use 359.34982442855835 seconds, loss -0.030889793051987767\n",
      "\n",
      "trained 53616 images, use 364.27607464790344 seconds, loss -0.030892142701585655\n",
      "\n",
      "trained 54416 images, use 369.0245530605316 seconds, loss -0.030775430957444568\n",
      "\n",
      "trained 55216 images, use 374.4273841381073 seconds, loss -0.030846009407289137\n",
      "\n",
      "trained 56016 images, use 379.36021518707275 seconds, loss -0.030907194261648268\n",
      "\n",
      "trained 56816 images, use 384.30186104774475 seconds, loss -0.030981530111305545\n",
      "\n",
      "trained 57616 images, use 389.55929827690125 seconds, loss -0.030972385810281434\n",
      "\n",
      "trained 58416 images, use 394.1611371040344 seconds, loss -0.03098169426349425\n",
      "\n",
      "trained 59216 images, use 399.2293245792389 seconds, loss -0.03086011991716717\n",
      "\n",
      "trained 60016 images, use 404.70298290252686 seconds, loss -0.03085563814688566\n",
      "\n",
      "trained 60816 images, use 409.6801300048828 seconds, loss -0.030884612662777425\n",
      "\n",
      "trained 61616 images, use 414.7684621810913 seconds, loss -0.030927325410259453\n",
      "\n",
      "trained 62416 images, use 419.8966429233551 seconds, loss -0.030978725310679005\n",
      "\n",
      "trained 63216 images, use 425.0698244571686 seconds, loss -0.031028843975359113\n",
      "\n",
      "trained 64016 images, use 429.7808213233948 seconds, loss -0.03114345772975411\n",
      "\n",
      "trained 64816 images, use 434.3693561553955 seconds, loss -0.031140869222666328\n",
      "\n",
      "trained 65616 images, use 439.2310571670532 seconds, loss -0.031223382954100938\n",
      "\n",
      "trained 66416 images, use 444.0479066371918 seconds, loss -0.031217612708460754\n",
      "\n",
      "trained 67216 images, use 448.9842073917389 seconds, loss -0.03129612812990696\n",
      "\n",
      "trained 68016 images, use 452.9826729297638 seconds, loss -0.031213156944703908\n",
      "\n",
      "trained 68816 images, use 457.44515585899353 seconds, loss -0.03121489334315596\n",
      "\n",
      "trained 69616 images, use 462.02179169654846 seconds, loss -0.031242772202732114\n",
      "\n",
      "trained 70416 images, use 466.92896032333374 seconds, loss -0.0312182251298888\n",
      "\n",
      "trained 71216 images, use 471.1543848514557 seconds, loss -0.031231533565022476\n",
      "\n",
      "trained 72016 images, use 475.59680914878845 seconds, loss -0.03122621650379405\n",
      "\n",
      "trained 72816 images, use 481.26269030570984 seconds, loss -0.031138233470429873\n",
      "\n",
      "trained 73616 images, use 485.80426120758057 seconds, loss -0.031178198909070316\n",
      "\n",
      "trained 74416 images, use 490.4277470111847 seconds, loss -0.03123307468757461\n",
      "\n",
      "trained 75216 images, use 494.988623380661 seconds, loss -0.031215595608049564\n",
      "\n",
      "trained 76016 images, use 499.72235202789307 seconds, loss -0.03122685762310816\n",
      "\n",
      "trained 76816 images, use 503.8444104194641 seconds, loss -0.03118567152749696\n",
      "\n",
      "trained 77616 images, use 509.05052614212036 seconds, loss -0.031182928931177026\n",
      "\n",
      "trained 78416 images, use 512.930673122406 seconds, loss -0.031154605043259582\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 517.541886806488 seconds, loss -0.031165894061387547\n",
      "\n",
      "trained 80016 images, use 522.1290376186371 seconds, loss -0.03118695819209027\n",
      "\n",
      "trained 80816 images, use 526.5598299503326 seconds, loss -0.031214282374097513\n",
      "\n",
      "trained 81616 images, use 531.5531318187714 seconds, loss -0.03125655834697499\n",
      "\n",
      "trained 82416 images, use 536.2624499797821 seconds, loss -0.031363947102503134\n",
      "\n",
      "trained 83216 images, use 540.7522892951965 seconds, loss -0.031348500344728254\n",
      "\n",
      "trained 84016 images, use 545.4201238155365 seconds, loss -0.031392371962508846\n",
      "\n",
      "trained 84816 images, use 549.8419325351715 seconds, loss -0.03133260514389551\n",
      "\n",
      "trained 85616 images, use 554.0979933738708 seconds, loss -0.03129978982249671\n",
      "\n",
      "trained 86416 images, use 558.9913904666901 seconds, loss -0.0313064839264081\n",
      "\n",
      "trained 87216 images, use 563.4670121669769 seconds, loss -0.0312517569119856\n",
      "\n",
      "trained 88016 images, use 567.7315180301666 seconds, loss -0.031237296211581025\n",
      "\n",
      "trained 88816 images, use 572.02312541008 seconds, loss -0.03127728725581998\n",
      "\n",
      "trained 89616 images, use 577.5160279273987 seconds, loss -0.031252571702861776\n",
      "\n",
      "trained 90416 images, use 581.5503642559052 seconds, loss -0.031214197508948733\n",
      "\n",
      "trained 91216 images, use 586.4166848659515 seconds, loss -0.031241325739405947\n",
      "\n",
      "trained 92016 images, use 590.897337436676 seconds, loss -0.03127188409978548\n",
      "\n",
      "trained 92816 images, use 595.8607623577118 seconds, loss -0.031316905328972945\n",
      "\n",
      "trained 93616 images, use 600.188321352005 seconds, loss -0.03133620375413855\n",
      "\n",
      "trained 94416 images, use 604.7071981430054 seconds, loss -0.03129106944084111\n",
      "\n",
      "trained 95216 images, use 609.3197219371796 seconds, loss -0.031253069704551495\n",
      "\n",
      "trained 96016 images, use 614.1182837486267 seconds, loss -0.031302015388207594\n",
      "\n",
      "trained 96816 images, use 618.825799703598 seconds, loss -0.03128104542994123\n",
      "\n",
      "trained 97616 images, use 623.3846609592438 seconds, loss -0.031317494486521644\n",
      "\n",
      "trained 98416 images, use 627.5797851085663 seconds, loss -0.03131738757212141\n",
      "\n",
      "trained 99216 images, use 631.7900755405426 seconds, loss -0.03132271972085548\n",
      "\n",
      "*************Epoch 18 Avrg Training loss -0.031280873173658984 Elapsed 636.2868721485138\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.785891435657426\n",
      "************* Validation: total 99996 precision 0.9694130622367751 avgTime 0.005927979378677558\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 19 started at 1619480718.793557\n",
      "trained 16 images, use 4.746705532073975 seconds, loss -0.04726985521483584\n",
      "\n",
      "trained 816 images, use 7.78865385055542 seconds, loss -0.034226643785140926\n",
      "\n",
      "trained 1616 images, use 12.27490782737732 seconds, loss -0.0371855959543725\n",
      "\n",
      "trained 2416 images, use 16.799837350845337 seconds, loss -0.034402487807740634\n",
      "\n",
      "trained 3216 images, use 21.220032691955566 seconds, loss -0.031956269650136884\n",
      "\n",
      "trained 4016 images, use 25.655946016311646 seconds, loss -0.03090763065790364\n",
      "\n",
      "trained 4816 images, use 29.985076427459717 seconds, loss -0.02915396035735206\n",
      "\n",
      "trained 5616 images, use 35.20137810707092 seconds, loss -0.029022787315013107\n",
      "\n",
      "trained 6416 images, use 39.69795775413513 seconds, loss -0.0294710778274317\n",
      "\n",
      "trained 7216 images, use 44.614980936050415 seconds, loss -0.028958957871384226\n",
      "\n",
      "trained 8016 images, use 49.38195514678955 seconds, loss -0.029594122193140514\n",
      "\n",
      "trained 8816 images, use 53.638692140579224 seconds, loss -0.030287416933436978\n",
      "\n",
      "trained 9616 images, use 58.452301025390625 seconds, loss -0.030672264885597347\n",
      "\n",
      "trained 10416 images, use 63.01239585876465 seconds, loss -0.03066152677372966\n",
      "\n",
      "trained 11216 images, use 67.81551575660706 seconds, loss -0.030922854961095564\n",
      "\n",
      "trained 12016 images, use 72.16766571998596 seconds, loss -0.0311460774567696\n",
      "\n",
      "trained 12816 images, use 76.55347418785095 seconds, loss -0.030359640095837578\n",
      "\n",
      "trained 13616 images, use 81.38734221458435 seconds, loss -0.030607286589921994\n",
      "\n",
      "trained 14416 images, use 87.33928155899048 seconds, loss -0.030545892054126545\n",
      "\n",
      "trained 15216 images, use 91.67606902122498 seconds, loss -0.030811999985463395\n",
      "\n",
      "trained 16016 images, use 95.81963038444519 seconds, loss -0.031045451913083985\n",
      "\n",
      "trained 16816 images, use 100.28412914276123 seconds, loss -0.031045029558396404\n",
      "\n",
      "trained 17616 images, use 104.6955246925354 seconds, loss -0.03080193169227993\n",
      "\n",
      "trained 18416 images, use 109.0769293308258 seconds, loss -0.0305547871468832\n",
      "\n",
      "trained 19216 images, use 113.45692658424377 seconds, loss -0.030751407524779062\n",
      "\n",
      "trained 20016 images, use 118.0686674118042 seconds, loss -0.030528542590128344\n",
      "\n",
      "trained 20816 images, use 122.61186909675598 seconds, loss -0.0307225670786567\n",
      "\n",
      "trained 21616 images, use 127.64943861961365 seconds, loss -0.030729900987223512\n",
      "\n",
      "trained 22416 images, use 132.24489855766296 seconds, loss -0.03089574672095505\n",
      "\n",
      "trained 23216 images, use 136.32202672958374 seconds, loss -0.03099501639393614\n",
      "\n",
      "trained 24016 images, use 141.1700234413147 seconds, loss -0.031012205352870803\n",
      "\n",
      "trained 24816 images, use 145.5867042541504 seconds, loss -0.031009013815820826\n",
      "\n",
      "trained 25616 images, use 150.31023836135864 seconds, loss -0.030663400542290133\n",
      "\n",
      "trained 26416 images, use 154.7181122303009 seconds, loss -0.030624308224572055\n",
      "\n",
      "trained 27216 images, use 159.37808895111084 seconds, loss -0.030799400995790184\n",
      "\n",
      "trained 28016 images, use 164.0110948085785 seconds, loss -0.030793847897264245\n",
      "\n",
      "trained 28816 images, use 168.659850358963 seconds, loss -0.03073022481186708\n",
      "\n",
      "trained 29616 images, use 173.35980939865112 seconds, loss -0.030785504223678938\n",
      "\n",
      "trained 30416 images, use 177.81705236434937 seconds, loss -0.030821788863294293\n",
      "\n",
      "trained 31216 images, use 182.37856578826904 seconds, loss -0.03074329367107312\n",
      "\n",
      "trained 32016 images, use 187.48588943481445 seconds, loss -0.030855268153862137\n",
      "\n",
      "trained 32816 images, use 191.8471748828888 seconds, loss -0.030848646255115145\n",
      "\n",
      "trained 33616 images, use 196.8631145954132 seconds, loss -0.030670337121668962\n",
      "\n",
      "trained 34416 images, use 200.96061515808105 seconds, loss -0.030789133712843073\n",
      "\n",
      "trained 35216 images, use 205.5638666152954 seconds, loss -0.03069084092915477\n",
      "\n",
      "trained 36016 images, use 210.16264653205872 seconds, loss -0.030795497600970893\n",
      "\n",
      "trained 36816 images, use 214.8476779460907 seconds, loss -0.030797004878391727\n",
      "\n",
      "trained 37616 images, use 219.61465311050415 seconds, loss -0.030903367407479614\n",
      "\n",
      "trained 38416 images, use 224.20674204826355 seconds, loss -0.031076807559320414\n",
      "\n",
      "trained 39216 images, use 231.16548609733582 seconds, loss -0.031176675966212774\n",
      "\n",
      "trained 40016 images, use 239.12114596366882 seconds, loss -0.031436761276629824\n",
      "\n",
      "trained 40816 images, use 246.9098415374756 seconds, loss -0.031445814688234576\n",
      "\n",
      "trained 41616 images, use 254.14675879478455 seconds, loss -0.031542027119902456\n",
      "\n",
      "trained 42416 images, use 262.08457112312317 seconds, loss -0.03160651835808461\n",
      "\n",
      "trained 43216 images, use 268.4448251724243 seconds, loss -0.0315581906290303\n",
      "\n",
      "trained 44016 images, use 274.2213363647461 seconds, loss -0.03162624776600939\n",
      "\n",
      "trained 44816 images, use 279.82612895965576 seconds, loss -0.03159090116444549\n",
      "\n",
      "trained 45616 images, use 285.2692799568176 seconds, loss -0.03157680066378239\n",
      "\n",
      "trained 46416 images, use 290.9579176902771 seconds, loss -0.03147380578772834\n",
      "\n",
      "trained 47216 images, use 296.0143988132477 seconds, loss -0.031450205005458164\n",
      "\n",
      "trained 48016 images, use 301.48251605033875 seconds, loss -0.03154109731836291\n",
      "\n",
      "trained 48816 images, use 306.7626893520355 seconds, loss -0.03148528497379613\n",
      "\n",
      "trained 49616 images, use 312.0485978126526 seconds, loss -0.031521914934468785\n",
      "\n",
      "trained 50416 images, use 316.99721240997314 seconds, loss -0.031634741709087186\n",
      "\n",
      "trained 51216 images, use 322.2011225223541 seconds, loss -0.031554896507180505\n",
      "\n",
      "trained 52016 images, use 327.1802842617035 seconds, loss -0.0315972689009051\n",
      "\n",
      "trained 52816 images, use 332.7837071418762 seconds, loss -0.03146526206869068\n",
      "\n",
      "trained 53616 images, use 337.4135377407074 seconds, loss -0.031497128781510904\n",
      "\n",
      "trained 54416 images, use 343.1637268066406 seconds, loss -0.03136541620464946\n",
      "\n",
      "trained 55216 images, use 348.416522026062 seconds, loss -0.031379455617067\n",
      "\n",
      "trained 56016 images, use 353.5621745586395 seconds, loss -0.0314273865919082\n",
      "\n",
      "trained 56816 images, use 357.85672998428345 seconds, loss -0.031458343541203505\n",
      "\n",
      "trained 57616 images, use 363.5451731681824 seconds, loss -0.03144640059517991\n",
      "\n",
      "trained 58416 images, use 368.64307284355164 seconds, loss -0.03146204556333256\n",
      "\n",
      "trained 59216 images, use 373.2823688983917 seconds, loss -0.03139371641368551\n",
      "\n",
      "trained 60016 images, use 378.9674322605133 seconds, loss -0.03129880499053551\n",
      "\n",
      "trained 60816 images, use 383.2030305862427 seconds, loss -0.031306665332927114\n",
      "\n",
      "trained 61616 images, use 388.12768936157227 seconds, loss -0.03126923516849479\n",
      "\n",
      "trained 62416 images, use 393.220027923584 seconds, loss -0.03131159043001694\n",
      "\n",
      "trained 63216 images, use 399.11963725090027 seconds, loss -0.03135698907395274\n",
      "\n",
      "trained 64016 images, use 404.6375527381897 seconds, loss -0.03134587445942546\n",
      "\n",
      "trained 64816 images, use 410.09710907936096 seconds, loss -0.03141222365297252\n",
      "\n",
      "trained 65616 images, use 416.34056067466736 seconds, loss -0.03136534378399676\n",
      "\n",
      "trained 66416 images, use 421.57981514930725 seconds, loss -0.03141685823616332\n",
      "\n",
      "trained 67216 images, use 427.32644486427307 seconds, loss -0.03141924749634256\n",
      "\n",
      "trained 68016 images, use 432.8223612308502 seconds, loss -0.0314677338774882\n",
      "\n",
      "trained 68816 images, use 439.72648334503174 seconds, loss -0.03140115019101229\n",
      "\n",
      "trained 69616 images, use 445.8318679332733 seconds, loss -0.03136734067607773\n",
      "\n",
      "trained 70416 images, use 451.4287564754486 seconds, loss -0.031394183892873934\n",
      "\n",
      "trained 71216 images, use 457.30966448783875 seconds, loss -0.03142676105252557\n",
      "\n",
      "trained 72016 images, use 462.5753436088562 seconds, loss -0.03145181591037352\n",
      "\n",
      "trained 72816 images, use 468.6426146030426 seconds, loss -0.03145844936128962\n",
      "\n",
      "trained 73616 images, use 474.5260353088379 seconds, loss -0.031365721268530315\n",
      "\n",
      "trained 74416 images, use 479.44758582115173 seconds, loss -0.031324055122947336\n",
      "\n",
      "trained 75216 images, use 484.8873236179352 seconds, loss -0.031321869192622344\n",
      "\n",
      "trained 76016 images, use 490.1109561920166 seconds, loss -0.03130242762538145\n",
      "\n",
      "trained 76816 images, use 495.0915722846985 seconds, loss -0.03125885628836981\n",
      "\n",
      "trained 77616 images, use 500.30322670936584 seconds, loss -0.03121167027513794\n",
      "\n",
      "trained 78416 images, use 505.3255684375763 seconds, loss -0.031200431436082705\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 510.1796712875366 seconds, loss -0.031269306463341286\n",
      "\n",
      "trained 80016 images, use 515.1094207763672 seconds, loss -0.03125597853223864\n",
      "\n",
      "trained 80816 images, use 519.5609436035156 seconds, loss -0.031228876841948465\n",
      "\n",
      "trained 81616 images, use 524.6324617862701 seconds, loss -0.03116496030193916\n",
      "\n",
      "trained 82416 images, use 529.1348407268524 seconds, loss -0.031086696682105973\n",
      "\n",
      "trained 83216 images, use 533.9742488861084 seconds, loss -0.03104948359893623\n",
      "\n",
      "trained 84016 images, use 538.9142513275146 seconds, loss -0.031072754536295547\n",
      "\n",
      "trained 84816 images, use 543.7992193698883 seconds, loss -0.03108920090094024\n",
      "\n",
      "trained 85616 images, use 548.7256190776825 seconds, loss -0.031121478559650095\n",
      "\n",
      "trained 86416 images, use 552.9320814609528 seconds, loss -0.031105472616428858\n",
      "\n",
      "trained 87216 images, use 557.9163978099823 seconds, loss -0.031091572062080887\n",
      "\n",
      "trained 88016 images, use 562.8377647399902 seconds, loss -0.031165544041779816\n",
      "\n",
      "trained 88816 images, use 568.0511169433594 seconds, loss -0.031170593474834734\n",
      "\n",
      "trained 89616 images, use 573.2563188076019 seconds, loss -0.031214843651130437\n",
      "\n",
      "trained 90416 images, use 578.5024540424347 seconds, loss -0.03128182946537724\n",
      "\n",
      "trained 91216 images, use 584.4177782535553 seconds, loss -0.031301642905626814\n",
      "\n",
      "trained 92016 images, use 589.275467634201 seconds, loss -0.03132134668205107\n",
      "\n",
      "trained 92816 images, use 593.9315016269684 seconds, loss -0.031302406871956484\n",
      "\n",
      "trained 93616 images, use 598.6980419158936 seconds, loss -0.031337040169253025\n",
      "\n",
      "trained 94416 images, use 603.4596223831177 seconds, loss -0.031243394319644215\n",
      "\n",
      "trained 95216 images, use 608.7300126552582 seconds, loss -0.031212861437837323\n",
      "\n",
      "trained 96016 images, use 613.6439015865326 seconds, loss -0.031214247446733616\n",
      "\n",
      "trained 96816 images, use 619.0729444026947 seconds, loss -0.031246620242339988\n",
      "\n",
      "trained 97616 images, use 624.2598838806152 seconds, loss -0.031313815145867986\n",
      "\n",
      "trained 98416 images, use 629.4280087947845 seconds, loss -0.03129078079357257\n",
      "\n",
      "trained 99216 images, use 634.4340252876282 seconds, loss -0.031294494192154534\n",
      "\n",
      "*************Epoch 19 Avrg Training loss -0.031306109323243764 Elapsed 639.3848321437836\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.786241449657986\n",
      "************* Validation: total 99996 precision 0.9694630642368551 avgTime 0.005734748654644214\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 20 started at 1619481932.2189982\n",
      "trained 16 images, use 1.4479713439941406 seconds, loss -0.03559540119022131\n",
      "\n",
      "trained 816 images, use 5.758502244949341 seconds, loss -0.034175627472310365\n",
      "\n",
      "trained 1616 images, use 10.63681936264038 seconds, loss -0.03413003681881563\n",
      "\n",
      "trained 2416 images, use 15.034308671951294 seconds, loss -0.033060092420277284\n",
      "\n",
      "trained 3216 images, use 19.519419193267822 seconds, loss -0.03429724703222845\n",
      "\n",
      "trained 4016 images, use 23.652350902557373 seconds, loss -0.034766369835786404\n",
      "\n",
      "trained 4816 images, use 28.06547975540161 seconds, loss -0.0340233237957725\n",
      "\n",
      "trained 5616 images, use 32.86537837982178 seconds, loss -0.03326721289344128\n",
      "\n",
      "trained 6416 images, use 37.58476424217224 seconds, loss -0.033431999732824604\n",
      "\n",
      "trained 7216 images, use 42.76871681213379 seconds, loss -0.032798747113698096\n",
      "\n",
      "trained 8016 images, use 48.11804556846619 seconds, loss -0.03300286670486026\n",
      "\n",
      "trained 8816 images, use 53.323628425598145 seconds, loss -0.03292917565671109\n",
      "\n",
      "trained 9616 images, use 58.58609580993652 seconds, loss -0.033024586858568926\n",
      "\n",
      "trained 10416 images, use 62.939059019088745 seconds, loss -0.03281811424779787\n",
      "\n",
      "trained 11216 images, use 67.51649045944214 seconds, loss -0.03211912301732545\n",
      "\n",
      "trained 12016 images, use 72.08005785942078 seconds, loss -0.031811659982991465\n",
      "\n",
      "trained 12816 images, use 76.58999347686768 seconds, loss -0.03191006316389146\n",
      "\n",
      "trained 13616 images, use 80.89680099487305 seconds, loss -0.03145062126294064\n",
      "\n",
      "trained 14416 images, use 85.62708473205566 seconds, loss -0.031119546597469887\n",
      "\n",
      "trained 15216 images, use 89.93591856956482 seconds, loss -0.03107106315416166\n",
      "\n",
      "trained 16016 images, use 94.62995052337646 seconds, loss -0.031006772294186455\n",
      "\n",
      "trained 16816 images, use 99.47906613349915 seconds, loss -0.030938533504881967\n",
      "\n",
      "trained 17616 images, use 103.59126162528992 seconds, loss -0.030856898551203105\n",
      "\n",
      "trained 18416 images, use 107.95783066749573 seconds, loss -0.030822251340331636\n",
      "\n",
      "trained 19216 images, use 112.40498542785645 seconds, loss -0.03072240616107103\n",
      "\n",
      "trained 20016 images, use 116.9714207649231 seconds, loss -0.03095015388132982\n",
      "\n",
      "trained 20816 images, use 121.01734232902527 seconds, loss -0.030765930220239417\n",
      "\n",
      "trained 21616 images, use 125.59985375404358 seconds, loss -0.030980367050294375\n",
      "\n",
      "trained 22416 images, use 129.80372309684753 seconds, loss -0.03115595937228108\n",
      "\n",
      "trained 23216 images, use 134.1675202846527 seconds, loss -0.031127715659784887\n",
      "\n",
      "trained 24016 images, use 138.8910574913025 seconds, loss -0.031309741258762895\n",
      "\n",
      "trained 24816 images, use 143.7580270767212 seconds, loss -0.03149508288747383\n",
      "\n",
      "trained 25616 images, use 148.34259510040283 seconds, loss -0.031466166145828686\n",
      "\n",
      "trained 26416 images, use 153.24844408035278 seconds, loss -0.03148065233683368\n",
      "\n",
      "trained 27216 images, use 158.36686372756958 seconds, loss -0.03155760262805159\n",
      "\n",
      "trained 28016 images, use 167.07578372955322 seconds, loss -0.031397702957247205\n",
      "\n",
      "trained 28816 images, use 174.39381337165833 seconds, loss -0.03164068763877742\n",
      "\n",
      "trained 29616 images, use 182.13013696670532 seconds, loss -0.03161281152456116\n",
      "\n",
      "trained 30416 images, use 191.69447565078735 seconds, loss -0.0317173901584051\n",
      "\n",
      "trained 31216 images, use 198.68423557281494 seconds, loss -0.031771716079411524\n",
      "\n",
      "trained 32016 images, use 205.7987937927246 seconds, loss -0.03155513831754856\n",
      "\n",
      "trained 32816 images, use 212.09171056747437 seconds, loss -0.03156641667364986\n",
      "\n",
      "trained 33616 images, use 218.42313170433044 seconds, loss -0.031519829088456484\n",
      "\n",
      "trained 34416 images, use 224.35809135437012 seconds, loss -0.031379114139615465\n",
      "\n",
      "trained 35216 images, use 230.0975387096405 seconds, loss -0.03129110020353019\n",
      "\n",
      "trained 36016 images, use 236.0607714653015 seconds, loss -0.031051223319945004\n",
      "\n",
      "trained 36816 images, use 242.09241938591003 seconds, loss -0.0309753479200624\n",
      "\n",
      "trained 37616 images, use 248.45442962646484 seconds, loss -0.03085638648812051\n",
      "\n",
      "trained 38416 images, use 254.13556361198425 seconds, loss -0.030836209866876216\n",
      "\n",
      "trained 39216 images, use 259.67569875717163 seconds, loss -0.030744885613168738\n",
      "\n",
      "trained 40016 images, use 265.8657760620117 seconds, loss -0.030685560982147343\n",
      "\n",
      "trained 40816 images, use 271.38649678230286 seconds, loss -0.03064634807530884\n",
      "\n",
      "trained 41616 images, use 276.78380012512207 seconds, loss -0.030657344826144666\n",
      "\n",
      "trained 42416 images, use 281.95144605636597 seconds, loss -0.03065708579394558\n",
      "\n",
      "trained 43216 images, use 287.4599840641022 seconds, loss -0.030819581283089252\n",
      "\n",
      "trained 44016 images, use 292.3535029888153 seconds, loss -0.03068580329604049\n",
      "\n",
      "trained 44816 images, use 297.50433707237244 seconds, loss -0.030769570469997683\n",
      "\n",
      "trained 45616 images, use 302.5330672264099 seconds, loss -0.03085885730744814\n",
      "\n",
      "trained 46416 images, use 308.40629148483276 seconds, loss -0.030731652089035232\n",
      "\n",
      "trained 47216 images, use 313.6525421142578 seconds, loss -0.030732001424012254\n",
      "\n",
      "trained 48016 images, use 318.36295461654663 seconds, loss -0.03062328608338217\n",
      "\n",
      "trained 48816 images, use 323.2408266067505 seconds, loss -0.030810851300753336\n",
      "\n",
      "trained 49616 images, use 328.2715299129486 seconds, loss -0.030764933017873846\n",
      "\n",
      "trained 50416 images, use 333.348509311676 seconds, loss -0.030881356757678717\n",
      "\n",
      "trained 51216 images, use 338.12271213531494 seconds, loss -0.03102049363534162\n",
      "\n",
      "trained 52016 images, use 342.7765727043152 seconds, loss -0.03096856948209543\n",
      "\n",
      "trained 52816 images, use 347.6250116825104 seconds, loss -0.030943598764169845\n",
      "\n",
      "trained 53616 images, use 352.49805784225464 seconds, loss -0.030899050090742185\n",
      "\n",
      "trained 54416 images, use 357.02525782585144 seconds, loss -0.030813842511203907\n",
      "\n",
      "trained 55216 images, use 361.5918412208557 seconds, loss -0.03074008358385263\n",
      "\n",
      "trained 56016 images, use 365.80128049850464 seconds, loss -0.03073784595940416\n",
      "\n",
      "trained 56816 images, use 372.0995934009552 seconds, loss -0.030676909225785313\n",
      "\n",
      "trained 57616 images, use 377.77583479881287 seconds, loss -0.030668009705507388\n",
      "\n",
      "trained 58416 images, use 382.7046129703522 seconds, loss -0.030764556100124848\n",
      "\n",
      "trained 59216 images, use 388.26238083839417 seconds, loss -0.030726556094849262\n",
      "\n",
      "trained 60016 images, use 393.7001543045044 seconds, loss -0.030843529398571382\n",
      "\n",
      "trained 60816 images, use 398.72712111473083 seconds, loss -0.030955987912865465\n",
      "\n",
      "trained 61616 images, use 404.3931601047516 seconds, loss -0.03100300819136237\n",
      "\n",
      "trained 62416 images, use 409.7430775165558 seconds, loss -0.031022613223984433\n",
      "\n",
      "trained 63216 images, use 415.44647765159607 seconds, loss -0.031003429762617336\n",
      "\n",
      "trained 64016 images, use 420.9369125366211 seconds, loss -0.031014675149274265\n",
      "\n",
      "trained 64816 images, use 427.6400742530823 seconds, loss -0.030989691862983785\n",
      "\n",
      "trained 65616 images, use 431.9511842727661 seconds, loss -0.030929671771970212\n",
      "\n",
      "trained 66416 images, use 436.9703154563904 seconds, loss -0.031003174387602174\n",
      "\n",
      "trained 67216 images, use 442.56024718284607 seconds, loss -0.031017624928438858\n",
      "\n",
      "trained 68016 images, use 449.89875960350037 seconds, loss -0.031016508479407363\n",
      "\n",
      "trained 68816 images, use 453.8590078353882 seconds, loss -0.03103158533138436\n",
      "\n",
      "trained 69616 images, use 459.13995885849 seconds, loss -0.03099096607161363\n",
      "\n",
      "trained 70416 images, use 463.89247393608093 seconds, loss -0.03097922920242298\n",
      "\n",
      "trained 71216 images, use 468.90926814079285 seconds, loss -0.03096141783241664\n",
      "\n",
      "trained 72016 images, use 473.5339341163635 seconds, loss -0.03094454622357218\n",
      "\n",
      "trained 72816 images, use 479.289235830307 seconds, loss -0.030939365081580014\n",
      "\n",
      "trained 73616 images, use 483.8029148578644 seconds, loss -0.031031606901810307\n",
      "\n",
      "trained 74416 images, use 488.7685761451721 seconds, loss -0.030920671482819708\n",
      "\n",
      "trained 75216 images, use 493.4911913871765 seconds, loss -0.031103454099142194\n",
      "\n",
      "trained 76016 images, use 498.0597183704376 seconds, loss -0.03105704252754133\n",
      "\n",
      "trained 76816 images, use 503.1428437232971 seconds, loss -0.03112815162033902\n",
      "\n",
      "trained 77616 images, use 508.1432361602783 seconds, loss -0.031111161851483375\n",
      "\n",
      "trained 78416 images, use 512.4438416957855 seconds, loss -0.03118433243480894\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 517.4958207607269 seconds, loss -0.0313023420097735\n",
      "\n",
      "trained 80016 images, use 521.7362599372864 seconds, loss -0.031248578057053528\n",
      "\n",
      "trained 80816 images, use 526.4465854167938 seconds, loss -0.031221725303564093\n",
      "\n",
      "trained 81616 images, use 531.175891160965 seconds, loss -0.031127349941653\n",
      "\n",
      "trained 82416 images, use 535.7554292678833 seconds, loss -0.031120030462498324\n",
      "\n",
      "trained 83216 images, use 540.9068064689636 seconds, loss -0.031109372012626754\n",
      "\n",
      "trained 84016 images, use 546.3118333816528 seconds, loss -0.031124737150405583\n",
      "\n",
      "trained 84816 images, use 550.6913104057312 seconds, loss -0.031153648645727887\n",
      "\n",
      "trained 85616 images, use 555.2356679439545 seconds, loss -0.031092947320381082\n",
      "\n",
      "trained 86416 images, use 560.3000583648682 seconds, loss -0.031080788598654638\n",
      "\n",
      "trained 87216 images, use 564.9845952987671 seconds, loss -0.031028802120782243\n",
      "\n",
      "trained 88016 images, use 569.65509557724 seconds, loss -0.031128572108156533\n",
      "\n",
      "trained 88816 images, use 574.371435880661 seconds, loss -0.031126242181105056\n",
      "\n",
      "trained 89616 images, use 578.9292938709259 seconds, loss -0.031157651552237754\n",
      "\n",
      "trained 90416 images, use 584.0075497627258 seconds, loss -0.0311541697846495\n",
      "\n",
      "trained 91216 images, use 589.1048672199249 seconds, loss -0.03108781724252165\n",
      "\n",
      "trained 92016 images, use 593.6561543941498 seconds, loss -0.031093885585144965\n",
      "\n",
      "trained 92816 images, use 598.5888721942902 seconds, loss -0.031159382725833837\n",
      "\n",
      "trained 93616 images, use 603.178332567215 seconds, loss -0.031136697825006818\n",
      "\n",
      "trained 94416 images, use 608.3335282802582 seconds, loss -0.031163755601744187\n",
      "\n",
      "trained 95216 images, use 613.1565308570862 seconds, loss -0.03127456388796297\n",
      "\n",
      "trained 96016 images, use 618.6867787837982 seconds, loss -0.031231412196198762\n",
      "\n",
      "trained 96816 images, use 623.2630591392517 seconds, loss -0.03127521801432906\n",
      "\n",
      "trained 97616 images, use 627.6536259651184 seconds, loss -0.03128565754464859\n",
      "\n",
      "trained 98416 images, use 632.604638338089 seconds, loss -0.031274408493717834\n",
      "\n",
      "trained 99216 images, use 637.6727652549744 seconds, loss -0.03132114486867207\n",
      "\n",
      "*************Epoch 20 Avrg Training loss -0.03129500844870181 Elapsed 641.894376039505\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.785541421656866\n",
      "************* Validation: total 99996 precision 0.9693630602366952 avgTime 0.006021329982647243\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 21 started at 1619483177.4148855\n",
      "trained 16 images, use 4.562896728515625 seconds, loss -0.05540172894416173\n",
      "\n",
      "trained 816 images, use 8.034556865692139 seconds, loss -0.030283227083084688\n",
      "\n",
      "trained 1616 images, use 13.250488996505737 seconds, loss -0.030253499762154083\n",
      "\n",
      "trained 2416 images, use 18.35405158996582 seconds, loss -0.03168871602290617\n",
      "\n",
      "trained 3216 images, use 23.30357837677002 seconds, loss -0.031032465858984188\n",
      "\n",
      "trained 4016 images, use 27.68100619316101 seconds, loss -0.03114474239923549\n",
      "\n",
      "trained 4816 images, use 33.00604200363159 seconds, loss -0.030903963734719632\n",
      "\n",
      "trained 5616 images, use 37.82031607627869 seconds, loss -0.03075693855034377\n",
      "\n",
      "trained 6416 images, use 42.93756985664368 seconds, loss -0.03091691491073645\n",
      "\n",
      "trained 7216 images, use 47.9525032043457 seconds, loss -0.031071212815770227\n",
      "\n",
      "trained 8016 images, use 53.267845153808594 seconds, loss -0.03145478580819032\n",
      "\n",
      "trained 8816 images, use 57.86271286010742 seconds, loss -0.031422493146893445\n",
      "\n",
      "trained 9616 images, use 63.50415253639221 seconds, loss -0.03078715297385959\n",
      "\n",
      "trained 10416 images, use 68.62063598632812 seconds, loss -0.03117757423168255\n",
      "\n",
      "trained 11216 images, use 72.96593761444092 seconds, loss -0.03130926558356867\n",
      "\n",
      "trained 12016 images, use 77.63361382484436 seconds, loss -0.030990568942420492\n",
      "\n",
      "trained 12816 images, use 82.68568444252014 seconds, loss -0.03132180754731114\n",
      "\n",
      "trained 13616 images, use 87.34851241111755 seconds, loss -0.03131197933752278\n",
      "\n",
      "trained 14416 images, use 91.61885046958923 seconds, loss -0.031040047639572285\n",
      "\n",
      "trained 15216 images, use 96.7125198841095 seconds, loss -0.031098038551655875\n",
      "\n",
      "trained 16016 images, use 100.95220112800598 seconds, loss -0.031082145729299387\n",
      "\n",
      "trained 16816 images, use 106.01650524139404 seconds, loss -0.03125685777186774\n",
      "\n",
      "trained 17616 images, use 110.57875943183899 seconds, loss -0.031280871858912845\n",
      "\n",
      "trained 18416 images, use 115.0110023021698 seconds, loss -0.0313358000435922\n",
      "\n",
      "trained 19216 images, use 119.72179174423218 seconds, loss -0.031131958034046846\n",
      "\n",
      "trained 20016 images, use 124.15252947807312 seconds, loss -0.03120356826305494\n",
      "\n",
      "trained 20816 images, use 128.68328976631165 seconds, loss -0.03122279180732601\n",
      "\n",
      "trained 21616 images, use 133.5157594680786 seconds, loss -0.03103395215529506\n",
      "\n",
      "trained 22416 images, use 138.41151213645935 seconds, loss -0.03120440339376662\n",
      "\n",
      "trained 23216 images, use 143.5224199295044 seconds, loss -0.030816078794566035\n",
      "\n",
      "trained 24016 images, use 148.21245431900024 seconds, loss -0.030938387015393122\n",
      "\n",
      "trained 24816 images, use 152.91888284683228 seconds, loss -0.030869066653222404\n",
      "\n",
      "trained 25616 images, use 157.4788157939911 seconds, loss -0.03101251315010731\n",
      "\n",
      "trained 26416 images, use 162.4116187095642 seconds, loss -0.031029392945564966\n",
      "\n",
      "trained 27216 images, use 167.0258891582489 seconds, loss -0.030922196142335406\n",
      "\n",
      "trained 28016 images, use 171.67613315582275 seconds, loss -0.030886903681726387\n",
      "\n",
      "trained 28816 images, use 176.50333261489868 seconds, loss -0.03100470931883491\n",
      "\n",
      "trained 29616 images, use 180.8954679965973 seconds, loss -0.031033078196877454\n",
      "\n",
      "trained 30416 images, use 185.6667582988739 seconds, loss -0.030845064774343386\n",
      "\n",
      "trained 31216 images, use 190.5308096408844 seconds, loss -0.03073170264940088\n",
      "\n",
      "trained 32016 images, use 195.29852867126465 seconds, loss -0.03072225004067896\n",
      "\n",
      "trained 32816 images, use 200.10410356521606 seconds, loss -0.030592511597270264\n",
      "\n",
      "trained 33616 images, use 206.49093580245972 seconds, loss -0.030669993778312955\n",
      "\n",
      "trained 34416 images, use 213.3389856815338 seconds, loss -0.0306119292982383\n",
      "\n",
      "trained 35216 images, use 219.96350979804993 seconds, loss -0.030546618589397435\n",
      "\n",
      "trained 36016 images, use 229.18284249305725 seconds, loss -0.030446585910993463\n",
      "\n",
      "trained 36816 images, use 238.64133977890015 seconds, loss -0.030613763955082265\n",
      "\n",
      "trained 37616 images, use 248.17195081710815 seconds, loss -0.03054750753336897\n",
      "\n",
      "trained 38416 images, use 257.9946458339691 seconds, loss -0.030578639965148487\n",
      "\n",
      "trained 39216 images, use 268.0296778678894 seconds, loss -0.030686735311372\n",
      "\n",
      "trained 40016 images, use 275.29975843429565 seconds, loss -0.030627949811185617\n",
      "\n",
      "trained 40816 images, use 281.9885582923889 seconds, loss -0.03055026936799261\n",
      "\n",
      "trained 41616 images, use 289.26865434646606 seconds, loss -0.030572983623277268\n",
      "\n",
      "trained 42416 images, use 295.2328460216522 seconds, loss -0.030463692949134626\n",
      "\n",
      "trained 43216 images, use 303.5907030105591 seconds, loss -0.030455242057865383\n",
      "\n",
      "trained 44016 images, use 308.61980962753296 seconds, loss -0.03043235742519531\n",
      "\n",
      "trained 44816 images, use 314.13770723342896 seconds, loss -0.030598818093304746\n",
      "\n",
      "trained 45616 images, use 319.74260783195496 seconds, loss -0.030626717231125134\n",
      "\n",
      "trained 46416 images, use 325.7630889415741 seconds, loss -0.03077194538674841\n",
      "\n",
      "trained 47216 images, use 331.73942971229553 seconds, loss -0.0308329251975591\n",
      "\n",
      "trained 48016 images, use 337.8131511211395 seconds, loss -0.03084354150366603\n",
      "\n",
      "trained 48816 images, use 342.57353353500366 seconds, loss -0.030808284950082154\n",
      "\n",
      "trained 49616 images, use 347.9226486682892 seconds, loss -0.030936958699624387\n",
      "\n",
      "trained 50416 images, use 353.3921756744385 seconds, loss -0.03091098927369901\n",
      "\n",
      "trained 51216 images, use 358.09280729293823 seconds, loss -0.030841337095595795\n",
      "\n",
      "trained 52016 images, use 363.2101984024048 seconds, loss -0.030838435397559226\n",
      "\n",
      "trained 52816 images, use 368.0957467556 seconds, loss -0.03075546659112282\n",
      "\n",
      "trained 53616 images, use 373.01058173179626 seconds, loss -0.030765798977177416\n",
      "\n",
      "trained 54416 images, use 378.6653575897217 seconds, loss -0.030717355119922542\n",
      "\n",
      "trained 55216 images, use 383.0945785045624 seconds, loss -0.030768979639819043\n",
      "\n",
      "trained 56016 images, use 388.13847947120667 seconds, loss -0.030824026014906455\n",
      "\n",
      "trained 56816 images, use 393.0033483505249 seconds, loss -0.030880577005983963\n",
      "\n",
      "trained 57616 images, use 398.35957646369934 seconds, loss -0.030834776172560394\n",
      "\n",
      "trained 58416 images, use 402.79052996635437 seconds, loss -0.03089000193215479\n",
      "\n",
      "trained 59216 images, use 408.0058572292328 seconds, loss -0.030891487705232114\n",
      "\n",
      "trained 60016 images, use 412.25793981552124 seconds, loss -0.030903174580996468\n",
      "\n",
      "trained 60816 images, use 416.96648025512695 seconds, loss -0.030840412050237204\n",
      "\n",
      "trained 61616 images, use 421.55279517173767 seconds, loss -0.03086238780398178\n",
      "\n",
      "trained 62416 images, use 426.34939670562744 seconds, loss -0.030861684863316568\n",
      "\n",
      "trained 63216 images, use 430.93648982048035 seconds, loss -0.03081533369082496\n",
      "\n",
      "trained 64016 images, use 436.1454119682312 seconds, loss -0.03085087751332049\n",
      "\n",
      "trained 64816 images, use 441.8174521923065 seconds, loss -0.030863265766876178\n",
      "\n",
      "trained 65616 images, use 446.8723692893982 seconds, loss -0.030817906139259842\n",
      "\n",
      "trained 66416 images, use 452.2924485206604 seconds, loss -0.030804968281144804\n",
      "\n",
      "trained 67216 images, use 457.6457214355469 seconds, loss -0.03072043847352693\n",
      "\n",
      "trained 68016 images, use 463.37830328941345 seconds, loss -0.030785988088802552\n",
      "\n",
      "trained 68816 images, use 468.94865894317627 seconds, loss -0.03086615295905184\n",
      "\n",
      "trained 69616 images, use 474.4986298084259 seconds, loss -0.030879640270085912\n",
      "\n",
      "trained 70416 images, use 480.12791895866394 seconds, loss -0.03089827941028819\n",
      "\n",
      "trained 71216 images, use 485.6887333393097 seconds, loss -0.030865456685566194\n",
      "\n",
      "trained 72016 images, use 491.31394934654236 seconds, loss -0.030906555499382114\n",
      "\n",
      "trained 72816 images, use 497.0926444530487 seconds, loss -0.03087354357317754\n",
      "\n",
      "trained 73616 images, use 502.6548550128937 seconds, loss -0.030859641521608357\n",
      "\n",
      "trained 74416 images, use 508.02041578292847 seconds, loss -0.030882770124254177\n",
      "\n",
      "trained 75216 images, use 513.4932668209076 seconds, loss -0.030908431542034206\n",
      "\n",
      "trained 76016 images, use 518.9043121337891 seconds, loss -0.03088136529842413\n",
      "\n",
      "trained 76816 images, use 524.0245959758759 seconds, loss -0.03089811978657167\n",
      "\n",
      "trained 77616 images, use 529.0272765159607 seconds, loss -0.03091858136477784\n",
      "\n",
      "trained 78416 images, use 534.2148082256317 seconds, loss -0.030918240544414676\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 539.3333711624146 seconds, loss -0.030872070025532085\n",
      "\n",
      "trained 80016 images, use 544.598790884018 seconds, loss -0.030910120418815426\n",
      "\n",
      "trained 80816 images, use 549.1358542442322 seconds, loss -0.030998889028612562\n",
      "\n",
      "trained 81616 images, use 554.3559119701385 seconds, loss -0.030973707066788807\n",
      "\n",
      "trained 82416 images, use 559.1040909290314 seconds, loss -0.031028160740703734\n",
      "\n",
      "trained 83216 images, use 564.0747628211975 seconds, loss -0.03108193744958057\n",
      "\n",
      "trained 84016 images, use 568.750580072403 seconds, loss -0.031168559432806383\n",
      "\n",
      "trained 84816 images, use 574.0262842178345 seconds, loss -0.031191674224989162\n",
      "\n",
      "trained 85616 images, use 578.6580951213837 seconds, loss -0.031188328825575012\n",
      "\n",
      "trained 86416 images, use 583.2744553089142 seconds, loss -0.031190700500988933\n",
      "\n",
      "trained 87216 images, use 588.248509645462 seconds, loss -0.03117321475935145\n",
      "\n",
      "trained 88016 images, use 593.0606610774994 seconds, loss -0.031243634454123682\n",
      "\n",
      "trained 88816 images, use 597.5646109580994 seconds, loss -0.0312983291675319\n",
      "\n",
      "trained 89616 images, use 602.5497171878815 seconds, loss -0.031254171608335275\n",
      "\n",
      "trained 90416 images, use 608.161080121994 seconds, loss -0.03129931869969332\n",
      "\n",
      "trained 91216 images, use 613.2133538722992 seconds, loss -0.03128574772150009\n",
      "\n",
      "trained 92016 images, use 618.4820597171783 seconds, loss -0.031248473869093744\n",
      "\n",
      "trained 92816 images, use 623.5401799678802 seconds, loss -0.03125829424441359\n",
      "\n",
      "trained 93616 images, use 628.8465421199799 seconds, loss -0.031247060991773316\n",
      "\n",
      "trained 94416 images, use 633.538901090622 seconds, loss -0.031389969564544325\n",
      "\n",
      "trained 95216 images, use 639.2297375202179 seconds, loss -0.03130611631102485\n",
      "\n",
      "trained 96016 images, use 643.7197687625885 seconds, loss -0.031232880913527807\n",
      "\n",
      "trained 96816 images, use 648.9533293247223 seconds, loss -0.031227571323537283\n",
      "\n",
      "trained 97616 images, use 654.1611971855164 seconds, loss -0.03129009155275517\n",
      "\n",
      "trained 98416 images, use 659.5734367370605 seconds, loss -0.031306554979015015\n",
      "\n",
      "trained 99216 images, use 665.0250978469849 seconds, loss -0.03127992778843324\n",
      "\n",
      "*************Epoch 21 Avrg Training loss -0.031308081634442896 Elapsed 669.8112461566925\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.786011440457618\n",
      "************* Validation: total 99996 precision 0.9694302057796598 avgTime 0.005930003051619715\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 22 started at 1619484441.3931828\n",
      "trained 16 images, use 4.347457408905029 seconds, loss -0.019222758501200587\n",
      "\n",
      "trained 816 images, use 8.61308240890503 seconds, loss -0.021337794359528043\n",
      "\n",
      "trained 1616 images, use 13.696998596191406 seconds, loss -0.030405500933061286\n",
      "\n",
      "trained 2416 images, use 19.42898154258728 seconds, loss -0.03183640508326322\n",
      "\n",
      "trained 3216 images, use 25.88930583000183 seconds, loss -0.031905255177524856\n",
      "\n",
      "trained 4016 images, use 30.709967613220215 seconds, loss -0.03152743293653729\n",
      "\n",
      "trained 4816 images, use 37.162736892700195 seconds, loss -0.03191457912749151\n",
      "\n",
      "trained 5616 images, use 42.15286445617676 seconds, loss -0.031210768011692768\n",
      "\n",
      "trained 6416 images, use 47.38017773628235 seconds, loss -0.030666663489711678\n",
      "\n",
      "trained 7216 images, use 52.28553628921509 seconds, loss -0.030912509065876344\n",
      "\n",
      "trained 8016 images, use 57.51789140701294 seconds, loss -0.03096633693383861\n",
      "\n",
      "trained 8816 images, use 62.66260313987732 seconds, loss -0.030943858849584345\n",
      "\n",
      "trained 9616 images, use 67.99144554138184 seconds, loss -0.030787283416543687\n",
      "\n",
      "trained 10416 images, use 72.68482375144958 seconds, loss -0.03114122296189385\n",
      "\n",
      "trained 11216 images, use 78.04403424263 seconds, loss -0.031235701527577122\n",
      "\n",
      "trained 12016 images, use 82.98690342903137 seconds, loss -0.03122713173356467\n",
      "\n",
      "trained 12816 images, use 87.56645107269287 seconds, loss -0.0311411245729548\n",
      "\n",
      "trained 13616 images, use 92.91553068161011 seconds, loss -0.031313047779221996\n",
      "\n",
      "trained 14416 images, use 97.61495351791382 seconds, loss -0.0315420955229995\n",
      "\n",
      "trained 15216 images, use 102.36980724334717 seconds, loss -0.031381196166771805\n",
      "\n",
      "trained 16016 images, use 107.8897271156311 seconds, loss -0.031706553453755115\n",
      "\n",
      "trained 16816 images, use 112.3066897392273 seconds, loss -0.031744371030194764\n",
      "\n",
      "trained 17616 images, use 117.16417646408081 seconds, loss -0.03150882033601634\n",
      "\n",
      "trained 18416 images, use 121.45790719985962 seconds, loss -0.03184043814554075\n",
      "\n",
      "trained 19216 images, use 126.91764831542969 seconds, loss -0.03198279716159489\n",
      "\n",
      "trained 20016 images, use 131.75061058998108 seconds, loss -0.031572511807548845\n",
      "\n",
      "trained 20816 images, use 136.39231157302856 seconds, loss -0.03145786199336893\n",
      "\n",
      "trained 21616 images, use 141.1946370601654 seconds, loss -0.03131090080853297\n",
      "\n",
      "trained 22416 images, use 146.16370749473572 seconds, loss -0.03155665875167856\n",
      "\n",
      "trained 23216 images, use 150.90719890594482 seconds, loss -0.03183593967465786\n",
      "\n",
      "trained 24016 images, use 155.34510397911072 seconds, loss -0.03186617000503539\n",
      "\n",
      "trained 24816 images, use 160.43967604637146 seconds, loss -0.03192375727461652\n",
      "\n",
      "trained 25616 images, use 165.35157704353333 seconds, loss -0.031916608621384894\n",
      "\n",
      "trained 26416 images, use 170.32210874557495 seconds, loss -0.031668260047831305\n",
      "\n",
      "trained 27216 images, use 175.16727709770203 seconds, loss -0.03179497064888291\n",
      "\n",
      "trained 28016 images, use 180.1003339290619 seconds, loss -0.03179900776950237\n",
      "\n",
      "trained 28816 images, use 184.5763123035431 seconds, loss -0.0317576571176433\n",
      "\n",
      "trained 29616 images, use 189.44649958610535 seconds, loss -0.03171196646592547\n",
      "\n",
      "trained 30416 images, use 193.62916588783264 seconds, loss -0.03165526020749711\n",
      "\n",
      "trained 31216 images, use 198.83521795272827 seconds, loss -0.03151411624607192\n",
      "\n",
      "trained 32016 images, use 203.29613184928894 seconds, loss -0.031456799054549636\n",
      "\n",
      "trained 32816 images, use 208.43008732795715 seconds, loss -0.031398661084277114\n",
      "\n",
      "trained 33616 images, use 213.7078721523285 seconds, loss -0.031456627103926466\n",
      "\n",
      "trained 34416 images, use 220.324565410614 seconds, loss -0.0313564408187042\n",
      "\n",
      "trained 35216 images, use 226.77904725074768 seconds, loss -0.031305726574760495\n",
      "\n",
      "trained 36016 images, use 232.09279775619507 seconds, loss -0.03132955068674906\n",
      "\n",
      "trained 36816 images, use 240.30920886993408 seconds, loss -0.03133073449578709\n",
      "\n",
      "trained 37616 images, use 249.17358827590942 seconds, loss -0.03144482542547398\n",
      "\n",
      "trained 38416 images, use 257.7488942146301 seconds, loss -0.031381114859591004\n",
      "\n",
      "trained 39216 images, use 264.84620904922485 seconds, loss -0.03132005751729352\n",
      "\n",
      "trained 40016 images, use 272.55717253685 seconds, loss -0.031254859710372195\n",
      "\n",
      "trained 40816 images, use 279.5933346748352 seconds, loss -0.03143686457592759\n",
      "\n",
      "trained 41616 images, use 285.40321230888367 seconds, loss -0.03123258309802823\n",
      "\n",
      "trained 42416 images, use 290.90995383262634 seconds, loss -0.0312552962417199\n",
      "\n",
      "trained 43216 images, use 296.28434681892395 seconds, loss -0.03140977429742098\n",
      "\n",
      "trained 44016 images, use 302.5009443759918 seconds, loss -0.03153609588494673\n",
      "\n",
      "trained 44816 images, use 308.0183472633362 seconds, loss -0.03150168741211664\n",
      "\n",
      "trained 45616 images, use 313.4114661216736 seconds, loss -0.03153164731944437\n",
      "\n",
      "trained 46416 images, use 319.2648169994354 seconds, loss -0.03151128076250981\n",
      "\n",
      "trained 47216 images, use 325.6334455013275 seconds, loss -0.03157035529301288\n",
      "\n",
      "trained 48016 images, use 330.4777331352234 seconds, loss -0.03162534516634911\n",
      "\n",
      "trained 48816 images, use 336.10267424583435 seconds, loss -0.031735630065391755\n",
      "\n",
      "trained 49616 images, use 341.6993396282196 seconds, loss -0.03162079660063898\n",
      "\n",
      "trained 50416 images, use 347.0147578716278 seconds, loss -0.0315660685014549\n",
      "\n",
      "trained 51216 images, use 352.03484582901 seconds, loss -0.03156182821105543\n",
      "\n",
      "trained 52016 images, use 356.7795617580414 seconds, loss -0.03147209373266566\n",
      "\n",
      "trained 52816 images, use 361.924870967865 seconds, loss -0.03149803203439976\n",
      "\n",
      "trained 53616 images, use 366.86890935897827 seconds, loss -0.03142829545549077\n",
      "\n",
      "trained 54416 images, use 371.97898864746094 seconds, loss -0.03144758715839622\n",
      "\n",
      "trained 55216 images, use 377.2083101272583 seconds, loss -0.03158460971266759\n",
      "\n",
      "trained 56016 images, use 381.87142395973206 seconds, loss -0.03150675567127736\n",
      "\n",
      "trained 56816 images, use 386.90044260025024 seconds, loss -0.031540797034823424\n",
      "\n",
      "trained 57616 images, use 392.38030648231506 seconds, loss -0.0314957909739812\n",
      "\n",
      "trained 58416 images, use 397.2423417568207 seconds, loss -0.03151456173939053\n",
      "\n",
      "trained 59216 images, use 402.02030658721924 seconds, loss -0.031483671583880955\n",
      "\n",
      "trained 60016 images, use 407.0777506828308 seconds, loss -0.0315322034985438\n",
      "\n",
      "trained 60816 images, use 412.54480385780334 seconds, loss -0.03157574933511464\n",
      "\n",
      "trained 61616 images, use 417.2519521713257 seconds, loss -0.031512457321186516\n",
      "\n",
      "trained 62416 images, use 421.71799492836 seconds, loss -0.03139604084033317\n",
      "\n",
      "trained 63216 images, use 426.7996745109558 seconds, loss -0.03147714353049842\n",
      "\n",
      "trained 64016 images, use 431.43428921699524 seconds, loss -0.03153556500108883\n",
      "\n",
      "trained 64816 images, use 436.4952857494354 seconds, loss -0.03142099295227271\n",
      "\n",
      "trained 65616 images, use 442.51107716560364 seconds, loss -0.03141127106623081\n",
      "\n",
      "trained 66416 images, use 447.7661123275757 seconds, loss -0.03147832067042551\n",
      "\n",
      "trained 67216 images, use 453.4151141643524 seconds, loss -0.0315203526644761\n",
      "\n",
      "trained 68016 images, use 458.8420104980469 seconds, loss -0.0315421237165334\n",
      "\n",
      "trained 68816 images, use 464.23450231552124 seconds, loss -0.03139326884181365\n",
      "\n",
      "trained 69616 images, use 470.1530919075012 seconds, loss -0.031439396625931294\n",
      "\n",
      "trained 70416 images, use 475.08845114707947 seconds, loss -0.03149600199280163\n",
      "\n",
      "trained 71216 images, use 481.09056305885315 seconds, loss -0.03150387999863911\n",
      "\n",
      "trained 72016 images, use 486.35839104652405 seconds, loss -0.03154725893221947\n",
      "\n",
      "trained 72816 images, use 491.3290750980377 seconds, loss -0.0316253399717235\n",
      "\n",
      "trained 73616 images, use 497.1429052352905 seconds, loss -0.03149781067888579\n",
      "\n",
      "trained 74416 images, use 503.21097135543823 seconds, loss -0.031450800401881654\n",
      "\n",
      "trained 75216 images, use 508.5201995372772 seconds, loss -0.03133836888168005\n",
      "\n",
      "trained 76016 images, use 513.9533488750458 seconds, loss -0.03130330345948909\n",
      "\n",
      "trained 76816 images, use 519.9597773551941 seconds, loss -0.03124630249751144\n",
      "\n",
      "trained 77616 images, use 524.9555213451385 seconds, loss -0.03112537835276785\n",
      "\n",
      "trained 78416 images, use 529.9836783409119 seconds, loss -0.031158287550745355\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 536.0910978317261 seconds, loss -0.031213129909955367\n",
      "\n",
      "trained 80016 images, use 541.1250841617584 seconds, loss -0.03122551593704081\n",
      "\n",
      "trained 80816 images, use 546.6084496974945 seconds, loss -0.031188471989851686\n",
      "\n",
      "trained 81616 images, use 551.3157527446747 seconds, loss -0.03127121415083958\n",
      "\n",
      "trained 82416 images, use 556.1303915977478 seconds, loss -0.031213591599396427\n",
      "\n",
      "trained 83216 images, use 561.2230496406555 seconds, loss -0.03128201384143546\n",
      "\n",
      "trained 84016 images, use 566.4151825904846 seconds, loss -0.03131931917058502\n",
      "\n",
      "trained 84816 images, use 571.452189207077 seconds, loss -0.031308337468499106\n",
      "\n",
      "trained 85616 images, use 576.1767666339874 seconds, loss -0.03131730755539846\n",
      "\n",
      "trained 86416 images, use 581.7381446361542 seconds, loss -0.031284197111812906\n",
      "\n",
      "trained 87216 images, use 585.6568388938904 seconds, loss -0.03125961802865002\n",
      "\n",
      "trained 88016 images, use 590.615914106369 seconds, loss -0.031277748945804575\n",
      "\n",
      "trained 88816 images, use 595.4741342067719 seconds, loss -0.03127353716784263\n",
      "\n",
      "trained 89616 images, use 600.501323223114 seconds, loss -0.03124533424914\n",
      "\n",
      "trained 90416 images, use 605.1912324428558 seconds, loss -0.031189118767937427\n",
      "\n",
      "trained 91216 images, use 610.1056790351868 seconds, loss -0.031238204375636652\n",
      "\n",
      "trained 92016 images, use 614.9310655593872 seconds, loss -0.031222762511709756\n",
      "\n",
      "trained 92816 images, use 620.4536321163177 seconds, loss -0.03117901886286275\n",
      "\n",
      "trained 93616 images, use 625.3357520103455 seconds, loss -0.031113210176705826\n",
      "\n",
      "trained 94416 images, use 630.5190641880035 seconds, loss -0.031155340082466797\n",
      "\n",
      "trained 95216 images, use 635.8955359458923 seconds, loss -0.03115826115961692\n",
      "\n",
      "trained 96016 images, use 640.4738962650299 seconds, loss -0.031194155505917393\n",
      "\n",
      "trained 96816 images, use 645.637957572937 seconds, loss -0.031243458224047272\n",
      "\n",
      "trained 97616 images, use 651.0991139411926 seconds, loss -0.03126860281266542\n",
      "\n",
      "trained 98416 images, use 656.1231851577759 seconds, loss -0.03127363700162488\n",
      "\n",
      "trained 99216 images, use 661.32692527771 seconds, loss -0.03126659448822121\n",
      "\n",
      "*************Epoch 22 Avrg Training loss -0.03132634736449967 Elapsed 666.8439462184906\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.7860514420576825\n",
      "************* Validation: total 99996 precision 0.9694359202939546 avgTime 0.006086588838137724\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 23 started at 1619485717.836554\n",
      "trained 16 images, use 4.80774450302124 seconds, loss -0.023844284130973392\n",
      "\n",
      "trained 816 images, use 9.181671857833862 seconds, loss -0.031428611439878296\n",
      "\n",
      "trained 1616 images, use 14.262789487838745 seconds, loss -0.0325103361251422\n",
      "\n",
      "trained 2416 images, use 19.843409776687622 seconds, loss -0.032835594793497375\n",
      "\n",
      "trained 3216 images, use 25.14587140083313 seconds, loss -0.03236137176053724\n",
      "\n",
      "trained 4016 images, use 30.83867907524109 seconds, loss -0.03185205893296262\n",
      "\n",
      "trained 4816 images, use 36.390212535858154 seconds, loss -0.03221496484083134\n",
      "\n",
      "trained 5616 images, use 41.47697377204895 seconds, loss -0.03146747077032459\n",
      "\n",
      "trained 6416 images, use 46.86349368095398 seconds, loss -0.030907707023246966\n",
      "\n",
      "trained 7216 images, use 52.11771559715271 seconds, loss -0.029601026494866605\n",
      "\n",
      "trained 8016 images, use 56.97782373428345 seconds, loss -0.0310049206812444\n",
      "\n",
      "trained 8816 images, use 61.958197832107544 seconds, loss -0.03061210404325391\n",
      "\n",
      "trained 9616 images, use 66.84298896789551 seconds, loss -0.0309812962079862\n",
      "\n",
      "trained 10416 images, use 71.84032678604126 seconds, loss -0.03145722862124528\n",
      "\n",
      "trained 11216 images, use 76.72571229934692 seconds, loss -0.03156938888105643\n",
      "\n",
      "trained 12016 images, use 81.42881774902344 seconds, loss -0.03194453058476231\n",
      "\n",
      "trained 12816 images, use 87.5315887928009 seconds, loss -0.03185943633439721\n",
      "\n",
      "trained 13616 images, use 92.01960182189941 seconds, loss -0.031694090313887764\n",
      "\n",
      "trained 14416 images, use 97.29848551750183 seconds, loss -0.03158857580004697\n",
      "\n",
      "trained 15216 images, use 102.55508232116699 seconds, loss -0.03125741899567137\n",
      "\n",
      "trained 16016 images, use 107.62119317054749 seconds, loss -0.031715906885869845\n",
      "\n",
      "trained 16816 images, use 112.08458685874939 seconds, loss -0.031719130509358005\n",
      "\n",
      "trained 17616 images, use 116.90591979026794 seconds, loss -0.031597992795640885\n",
      "\n",
      "trained 18416 images, use 122.14881610870361 seconds, loss -0.03177200722059088\n",
      "\n",
      "trained 19216 images, use 127.40635299682617 seconds, loss -0.03198852792408715\n",
      "\n",
      "trained 20016 images, use 131.85336470603943 seconds, loss -0.03196656524706147\n",
      "\n",
      "trained 20816 images, use 136.6516728401184 seconds, loss -0.03220152193461977\n",
      "\n",
      "trained 21616 images, use 141.09228110313416 seconds, loss -0.03257331499297919\n",
      "\n",
      "trained 22416 images, use 145.81325697898865 seconds, loss -0.03250742855746706\n",
      "\n",
      "trained 23216 images, use 150.48116660118103 seconds, loss -0.032443381044580236\n",
      "\n",
      "trained 24016 images, use 155.500958442688 seconds, loss -0.03263990253837765\n",
      "\n",
      "trained 24816 images, use 160.71918153762817 seconds, loss -0.03239010040089325\n",
      "\n",
      "trained 25616 images, use 165.12325429916382 seconds, loss -0.03223754067411679\n",
      "\n",
      "trained 26416 images, use 169.78162932395935 seconds, loss -0.03218991021986664\n",
      "\n",
      "trained 27216 images, use 174.6972291469574 seconds, loss -0.032371938012585755\n",
      "\n",
      "trained 28016 images, use 178.86351013183594 seconds, loss -0.03217521571159889\n",
      "\n",
      "trained 28816 images, use 183.7224006652832 seconds, loss -0.031841782002622575\n",
      "\n",
      "trained 29616 images, use 188.36824464797974 seconds, loss -0.03184720706945913\n",
      "\n",
      "trained 30416 images, use 193.11587858200073 seconds, loss -0.03184804111147745\n",
      "\n",
      "trained 31216 images, use 198.27344751358032 seconds, loss -0.03163984748492824\n",
      "\n",
      "trained 32016 images, use 203.54007744789124 seconds, loss -0.031414359565460716\n",
      "\n",
      "trained 32816 images, use 210.28980040550232 seconds, loss -0.03150868875647289\n",
      "\n",
      "trained 33616 images, use 216.4615695476532 seconds, loss -0.03137544625285139\n",
      "\n",
      "trained 34416 images, use 222.96853351593018 seconds, loss -0.031411520612639875\n",
      "\n",
      "trained 35216 images, use 232.01088285446167 seconds, loss -0.031335851251319095\n",
      "\n",
      "trained 36016 images, use 241.68636441230774 seconds, loss -0.031357667860116324\n",
      "\n",
      "trained 36816 images, use 249.29725074768066 seconds, loss -0.03124843151732633\n",
      "\n",
      "trained 37616 images, use 258.18531703948975 seconds, loss -0.03132643599588748\n",
      "\n",
      "trained 38416 images, use 267.04322385787964 seconds, loss -0.031348558277031875\n",
      "\n",
      "trained 39216 images, use 274.2486250400543 seconds, loss -0.03144468185600237\n",
      "\n",
      "trained 40016 images, use 281.12096309661865 seconds, loss -0.03134108261132161\n",
      "\n",
      "trained 40816 images, use 287.4004580974579 seconds, loss -0.03129979949670725\n",
      "\n",
      "trained 41616 images, use 292.7390282154083 seconds, loss -0.03147624458386938\n",
      "\n",
      "trained 42416 images, use 299.8467593193054 seconds, loss -0.03152377384737969\n",
      "\n",
      "trained 43216 images, use 305.21922039985657 seconds, loss -0.03166119742625405\n",
      "\n",
      "trained 44016 images, use 311.7713119983673 seconds, loss -0.03161570525227938\n",
      "\n",
      "trained 44816 images, use 317.2849407196045 seconds, loss -0.0314938975627499\n",
      "\n",
      "trained 45616 images, use 322.8338420391083 seconds, loss -0.031561384307530596\n",
      "\n",
      "trained 46416 images, use 328.76979899406433 seconds, loss -0.03153539971110287\n",
      "\n",
      "trained 47216 images, use 334.4868047237396 seconds, loss -0.031567971622721576\n",
      "\n",
      "trained 48016 images, use 340.58912777900696 seconds, loss -0.03157427611420095\n",
      "\n",
      "trained 48816 images, use 346.4317305088043 seconds, loss -0.03157533006201437\n",
      "\n",
      "trained 49616 images, use 352.3466114997864 seconds, loss -0.0315220748936804\n",
      "\n",
      "trained 50416 images, use 357.38338112831116 seconds, loss -0.03144572072808945\n",
      "\n",
      "trained 51216 images, use 362.3450541496277 seconds, loss -0.03153399100186612\n",
      "\n",
      "trained 52016 images, use 367.8339774608612 seconds, loss -0.031473291961551214\n",
      "\n",
      "trained 52816 images, use 372.8247797489166 seconds, loss -0.031505248463058855\n",
      "\n",
      "trained 53616 images, use 378.0331857204437 seconds, loss -0.03145189106779894\n",
      "\n",
      "trained 54416 images, use 383.63079500198364 seconds, loss -0.031467976972896966\n",
      "\n",
      "trained 55216 images, use 388.60124802589417 seconds, loss -0.0314545357834702\n",
      "\n",
      "trained 56016 images, use 394.08704137802124 seconds, loss -0.03144484511151756\n",
      "\n",
      "trained 56816 images, use 399.2759029865265 seconds, loss -0.03144268672731954\n",
      "\n",
      "trained 57616 images, use 403.6934311389923 seconds, loss -0.031350317084753214\n",
      "\n",
      "trained 58416 images, use 409.3172426223755 seconds, loss -0.031389621192017575\n",
      "\n",
      "trained 59216 images, use 414.2323899269104 seconds, loss -0.03136048512319906\n",
      "\n",
      "trained 60016 images, use 419.3679566383362 seconds, loss -0.03133926382500896\n",
      "\n",
      "trained 60816 images, use 424.10163044929504 seconds, loss -0.03131340747779572\n",
      "\n",
      "trained 61616 images, use 429.22059392929077 seconds, loss -0.0312988950303123\n",
      "\n",
      "trained 62416 images, use 434.18924355506897 seconds, loss -0.03129253156090382\n",
      "\n",
      "trained 63216 images, use 438.96699810028076 seconds, loss -0.03130116981802609\n",
      "\n",
      "trained 64016 images, use 444.82743644714355 seconds, loss -0.031217122179247252\n",
      "\n",
      "trained 64816 images, use 450.2274124622345 seconds, loss -0.031189593742225734\n",
      "\n",
      "trained 65616 images, use 455.7132525444031 seconds, loss -0.031198537760857285\n",
      "\n",
      "trained 66416 images, use 460.8815758228302 seconds, loss -0.031238589855382068\n",
      "\n",
      "trained 67216 images, use 466.6252226829529 seconds, loss -0.031289117931160015\n",
      "\n",
      "trained 68016 images, use 472.40835523605347 seconds, loss -0.031269842998952746\n",
      "\n",
      "trained 68816 images, use 478.0720582008362 seconds, loss -0.031333817701557035\n",
      "\n",
      "trained 69616 images, use 484.02963042259216 seconds, loss -0.031333150766888127\n",
      "\n",
      "trained 70416 images, use 488.94776153564453 seconds, loss -0.031277970020973885\n",
      "\n",
      "trained 71216 images, use 494.01716685295105 seconds, loss -0.031340032951268214\n",
      "\n",
      "trained 72016 images, use 499.58186960220337 seconds, loss -0.03139513381790029\n",
      "\n",
      "trained 72816 images, use 506.12049436569214 seconds, loss -0.031347712452947464\n",
      "\n",
      "trained 73616 images, use 511.99681758880615 seconds, loss -0.031379430117687616\n",
      "\n",
      "trained 74416 images, use 516.7042169570923 seconds, loss -0.03136140909283405\n",
      "\n",
      "trained 75216 images, use 522.1221194267273 seconds, loss -0.031366763707627504\n",
      "\n",
      "trained 76016 images, use 527.4208402633667 seconds, loss -0.03127730776078701\n",
      "\n",
      "trained 76816 images, use 532.3470234870911 seconds, loss -0.03133272798055271\n",
      "\n",
      "trained 77616 images, use 537.2103133201599 seconds, loss -0.031264182102482566\n",
      "\n",
      "trained 78416 images, use 542.6240291595459 seconds, loss -0.03125530841641845\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 547.4533803462982 seconds, loss -0.031238136696971435\n",
      "\n",
      "trained 80016 images, use 552.2603166103363 seconds, loss -0.03127412342871685\n",
      "\n",
      "trained 80816 images, use 557.243273973465 seconds, loss -0.03136455355708536\n",
      "\n",
      "trained 81616 images, use 562.1132709980011 seconds, loss -0.03140323355065819\n",
      "\n",
      "trained 82416 images, use 567.3969261646271 seconds, loss -0.031377534035137516\n",
      "\n",
      "trained 83216 images, use 572.1306788921356 seconds, loss -0.031375172816144915\n",
      "\n",
      "trained 84016 images, use 577.9761815071106 seconds, loss -0.03134186628824396\n",
      "\n",
      "trained 84816 images, use 582.7408502101898 seconds, loss -0.03128470128312763\n",
      "\n",
      "trained 85616 images, use 587.6718258857727 seconds, loss -0.03129106581514942\n",
      "\n",
      "trained 86416 images, use 592.6417992115021 seconds, loss -0.0313324454024043\n",
      "\n",
      "trained 87216 images, use 597.5333595275879 seconds, loss -0.031312208464237795\n",
      "\n",
      "trained 88016 images, use 602.186888217926 seconds, loss -0.03134551772142364\n",
      "\n",
      "trained 88816 images, use 607.4249062538147 seconds, loss -0.03136111762576971\n",
      "\n",
      "trained 89616 images, use 612.366977930069 seconds, loss -0.0313464188248479\n",
      "\n",
      "trained 90416 images, use 617.116828918457 seconds, loss -0.03133835592220576\n",
      "\n",
      "trained 91216 images, use 622.4004259109497 seconds, loss -0.031318601512807534\n",
      "\n",
      "trained 92016 images, use 626.8724563121796 seconds, loss -0.031233371078437492\n",
      "\n",
      "trained 92816 images, use 631.9089238643646 seconds, loss -0.031256296211563235\n",
      "\n",
      "trained 93616 images, use 636.741632938385 seconds, loss -0.031299605095537364\n",
      "\n",
      "trained 94416 images, use 641.8625826835632 seconds, loss -0.031298091961460064\n",
      "\n",
      "trained 95216 images, use 646.5554440021515 seconds, loss -0.03131678854130711\n",
      "\n",
      "trained 96016 images, use 651.9851140975952 seconds, loss -0.031279303395809074\n",
      "\n",
      "trained 96816 images, use 656.2357182502747 seconds, loss -0.03134365851991531\n",
      "\n",
      "trained 97616 images, use 661.0099546909332 seconds, loss -0.03127271101003849\n",
      "\n",
      "trained 98416 images, use 666.0432422161102 seconds, loss -0.03131406380119267\n",
      "\n",
      "trained 99216 images, use 670.8766224384308 seconds, loss -0.031325295027106986\n",
      "\n",
      "*************Epoch 23 Avrg Training loss -0.0313021936116229 Elapsed 675.5793616771698\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n",
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.78578143125725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Validation: total 99996 precision 0.9693973473224643 avgTime 0.005767898157294395\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 24 started at 1619486970.6912198\n",
      "trained 16 images, use 1.9155433177947998 seconds, loss 8.117530114759575e-06\n",
      "\n",
      "trained 816 images, use 5.433964967727661 seconds, loss -0.03704752957014534\n",
      "\n",
      "trained 1616 images, use 9.820500373840332 seconds, loss -0.032863736725403214\n",
      "\n",
      "trained 2416 images, use 14.549960136413574 seconds, loss -0.03416108189684876\n",
      "\n",
      "trained 3216 images, use 18.946959495544434 seconds, loss -0.032937526001165174\n",
      "\n",
      "trained 4016 images, use 23.567243099212646 seconds, loss -0.03333551243084667\n",
      "\n",
      "trained 4816 images, use 27.984566688537598 seconds, loss -0.03243613735968295\n",
      "\n",
      "trained 5616 images, use 32.88604187965393 seconds, loss -0.033052858904686004\n",
      "\n",
      "trained 6416 images, use 37.21368908882141 seconds, loss -0.0331430358640927\n",
      "\n",
      "trained 7216 images, use 41.75812077522278 seconds, loss -0.03215034427520312\n",
      "\n",
      "trained 8016 images, use 46.433279275894165 seconds, loss -0.03258765654296726\n",
      "\n",
      "trained 8816 images, use 51.17307639122009 seconds, loss -0.032689945951850354\n",
      "\n",
      "trained 9616 images, use 55.47663140296936 seconds, loss -0.03336718374727142\n",
      "\n",
      "trained 10416 images, use 60.44550585746765 seconds, loss -0.03360366417753517\n",
      "\n",
      "trained 11216 images, use 65.31319117546082 seconds, loss -0.03372104732202492\n",
      "\n",
      "trained 12016 images, use 70.07231450080872 seconds, loss -0.033757123466569554\n",
      "\n",
      "trained 12816 images, use 75.01053142547607 seconds, loss -0.03366204083407811\n",
      "\n",
      "trained 13616 images, use 79.48293662071228 seconds, loss -0.03313339906228499\n",
      "\n",
      "trained 14416 images, use 84.28838562965393 seconds, loss -0.033091835302615995\n",
      "\n",
      "trained 15216 images, use 88.91462874412537 seconds, loss -0.033433013268586075\n",
      "\n",
      "trained 16016 images, use 93.94449710845947 seconds, loss -0.03360376630464221\n",
      "\n",
      "trained 16816 images, use 98.48584842681885 seconds, loss -0.03369260019546662\n",
      "\n",
      "trained 17616 images, use 103.52527475357056 seconds, loss -0.03354778626174525\n",
      "\n",
      "trained 18416 images, use 108.310213804245 seconds, loss -0.033518218517818985\n",
      "\n",
      "trained 19216 images, use 113.0839033126831 seconds, loss -0.03362893132730573\n",
      "\n",
      "trained 20016 images, use 117.59427213668823 seconds, loss -0.03351705509767351\n",
      "\n",
      "trained 20816 images, use 122.13323521614075 seconds, loss -0.03312416762708293\n",
      "\n",
      "trained 21616 images, use 126.77737784385681 seconds, loss -0.03307805616295285\n",
      "\n",
      "trained 22416 images, use 131.70084261894226 seconds, loss -0.03312283252767941\n",
      "\n",
      "trained 23216 images, use 136.33739924430847 seconds, loss -0.03288496805037548\n",
      "\n",
      "trained 24016 images, use 140.71351099014282 seconds, loss -0.03286075030434062\n",
      "\n",
      "trained 24816 images, use 145.56501007080078 seconds, loss -0.032800953508691416\n",
      "\n",
      "trained 25616 images, use 150.04208827018738 seconds, loss -0.03260713894134311\n",
      "\n",
      "trained 26416 images, use 154.9249758720398 seconds, loss -0.03259387756873572\n",
      "\n",
      "trained 27216 images, use 159.76110816001892 seconds, loss -0.03264521749345628\n",
      "\n",
      "trained 28016 images, use 164.35858964920044 seconds, loss -0.032458960028190875\n",
      "\n",
      "trained 28816 images, use 169.32667636871338 seconds, loss -0.03244547065503424\n",
      "\n",
      "trained 29616 images, use 174.60338616371155 seconds, loss -0.032567046361799155\n",
      "\n",
      "trained 30416 images, use 179.4989297389984 seconds, loss -0.03269892954735459\n",
      "\n",
      "trained 31216 images, use 184.16335797309875 seconds, loss -0.03280667559226179\n",
      "\n",
      "trained 32016 images, use 189.15606331825256 seconds, loss -0.03273187494050047\n",
      "\n",
      "trained 32816 images, use 193.00771713256836 seconds, loss -0.03263308660431611\n",
      "\n",
      "trained 33616 images, use 197.610826253891 seconds, loss -0.032557948712531044\n",
      "\n",
      "trained 34416 images, use 202.34711384773254 seconds, loss -0.032644938243505166\n",
      "\n",
      "trained 35216 images, use 207.16922855377197 seconds, loss -0.03290231181904831\n",
      "\n",
      "trained 36016 images, use 212.392719745636 seconds, loss -0.032783718826231614\n",
      "\n",
      "trained 36816 images, use 217.07731103897095 seconds, loss -0.03259784658982418\n",
      "\n",
      "trained 37616 images, use 221.58676886558533 seconds, loss -0.03238006008259606\n",
      "\n",
      "trained 38416 images, use 226.2499418258667 seconds, loss -0.03240544098196409\n",
      "\n",
      "trained 39216 images, use 231.1467523574829 seconds, loss -0.03226927641622116\n",
      "\n",
      "trained 40016 images, use 236.1924180984497 seconds, loss -0.032423073421809556\n",
      "\n",
      "trained 40816 images, use 241.28977918624878 seconds, loss -0.03243964466187233\n",
      "\n",
      "trained 41616 images, use 246.03034663200378 seconds, loss -0.032319183318182704\n",
      "\n",
      "trained 42416 images, use 250.59636998176575 seconds, loss -0.03236630183728604\n",
      "\n",
      "trained 43216 images, use 255.69124913215637 seconds, loss -0.032384239228779296\n",
      "\n",
      "trained 44016 images, use 260.43453216552734 seconds, loss -0.03217145226228425\n",
      "\n",
      "trained 44816 images, use 265.2039978504181 seconds, loss -0.032252411895888164\n",
      "\n",
      "trained 45616 images, use 270.29597902297974 seconds, loss -0.0322699376870424\n",
      "\n",
      "trained 46416 images, use 274.6382222175598 seconds, loss -0.032424525777450475\n",
      "\n",
      "trained 47216 images, use 279.2847034931183 seconds, loss -0.03245947454563602\n",
      "\n",
      "trained 48016 images, use 284.3152072429657 seconds, loss -0.032332761391126785\n",
      "\n",
      "trained 48816 images, use 289.0770275592804 seconds, loss -0.03231917975762427\n",
      "\n",
      "trained 49616 images, use 294.1957838535309 seconds, loss -0.03236796551628481\n",
      "\n",
      "trained 50416 images, use 299.52984952926636 seconds, loss -0.03225832636648399\n",
      "\n",
      "trained 51216 images, use 305.96834206581116 seconds, loss -0.03213913389979419\n",
      "\n",
      "trained 52016 images, use 316.269651889801 seconds, loss -0.03214096309519834\n",
      "\n",
      "trained 52816 images, use 325.0737237930298 seconds, loss -0.03215193129536115\n",
      "\n",
      "trained 53616 images, use 332.69642996788025 seconds, loss -0.03209923558973548\n",
      "\n",
      "trained 54416 images, use 342.0080280303955 seconds, loss -0.03203342780538583\n",
      "\n",
      "trained 55216 images, use 349.16847825050354 seconds, loss -0.03206329015103807\n",
      "\n",
      "trained 56016 images, use 357.7539165019989 seconds, loss -0.03191970849570628\n",
      "\n",
      "trained 56816 images, use 363.3897624015808 seconds, loss -0.03189511476559051\n",
      "\n",
      "trained 57616 images, use 370.0345401763916 seconds, loss -0.03189727162574408\n",
      "\n",
      "trained 58416 images, use 377.12937784194946 seconds, loss -0.031921606191761646\n",
      "\n",
      "trained 59216 images, use 383.5859537124634 seconds, loss -0.03204549461761508\n",
      "\n",
      "trained 60016 images, use 392.96701526641846 seconds, loss -0.03215583420445721\n",
      "\n",
      "trained 60816 images, use 402.17693185806274 seconds, loss -0.03212842967384759\n",
      "\n",
      "trained 61616 images, use 408.836398601532 seconds, loss -0.03199644114438557\n",
      "\n",
      "trained 62416 images, use 414.30642437934875 seconds, loss -0.032107233259287146\n",
      "\n",
      "trained 63216 images, use 420.5248203277588 seconds, loss -0.03212015808737279\n",
      "\n",
      "trained 64016 images, use 426.565997838974 seconds, loss -0.032109010020139626\n",
      "\n",
      "trained 64816 images, use 431.87834072113037 seconds, loss -0.03199967084593724\n",
      "\n",
      "trained 65616 images, use 437.34555315971375 seconds, loss -0.03198401205135474\n",
      "\n",
      "trained 66416 images, use 442.4745440483093 seconds, loss -0.03194774391980252\n",
      "\n",
      "trained 67216 images, use 447.5647747516632 seconds, loss -0.0319159557248071\n",
      "\n",
      "trained 68016 images, use 453.18238139152527 seconds, loss -0.03181116276535481\n",
      "\n",
      "trained 68816 images, use 458.8047766685486 seconds, loss -0.03183901514134331\n",
      "\n",
      "trained 69616 images, use 463.81150555610657 seconds, loss -0.03181246182721122\n",
      "\n",
      "trained 70416 images, use 468.944397687912 seconds, loss -0.031803043706280926\n",
      "\n",
      "trained 71216 images, use 475.6506106853485 seconds, loss -0.03179277229597485\n",
      "\n",
      "trained 72016 images, use 480.6554329395294 seconds, loss -0.03177859646511376\n",
      "\n",
      "trained 72816 images, use 486.4945635795593 seconds, loss -0.031811757033130675\n",
      "\n",
      "trained 73616 images, use 491.18819427490234 seconds, loss -0.03170112808826807\n",
      "\n",
      "trained 74416 images, use 496.3535325527191 seconds, loss -0.03166304821462357\n",
      "\n",
      "trained 75216 images, use 501.5262701511383 seconds, loss -0.03165615492669325\n",
      "\n",
      "trained 76016 images, use 507.5249824523926 seconds, loss -0.031616405740488795\n",
      "\n",
      "trained 76816 images, use 512.9165172576904 seconds, loss -0.031566428048168664\n",
      "\n",
      "trained 77616 images, use 517.945140838623 seconds, loss -0.031552512194118504\n",
      "\n",
      "trained 78416 images, use 523.0018978118896 seconds, loss -0.03157122356883861\n",
      "\n",
      "trained 79216 images, use 528.0354354381561 seconds, loss -0.03158499481701217\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 80016 images, use 532.6375160217285 seconds, loss -0.03165768151540529\n",
      "\n",
      "trained 80816 images, use 537.4319622516632 seconds, loss -0.0317120560458583\n",
      "\n",
      "trained 81616 images, use 543.4381263256073 seconds, loss -0.03173566780889373\n",
      "\n",
      "trained 82416 images, use 548.9181895256042 seconds, loss -0.03175641633091806\n",
      "\n",
      "trained 83216 images, use 553.5993354320526 seconds, loss -0.031642383583584816\n",
      "\n",
      "trained 84016 images, use 558.1785023212433 seconds, loss -0.03154980131362092\n",
      "\n",
      "trained 84816 images, use 563.2921946048737 seconds, loss -0.03149311715441359\n",
      "\n",
      "trained 85616 images, use 568.967159986496 seconds, loss -0.03144013054046527\n",
      "\n",
      "trained 86416 images, use 574.1944930553436 seconds, loss -0.03140961933374053\n",
      "\n",
      "trained 87216 images, use 579.6008415222168 seconds, loss -0.031427791406259786\n",
      "\n",
      "trained 88016 images, use 585.2111325263977 seconds, loss -0.031458331388577405\n",
      "\n",
      "trained 88816 images, use 590.2467694282532 seconds, loss -0.03143761580971166\n",
      "\n",
      "trained 89616 images, use 595.2494485378265 seconds, loss -0.03142607782044309\n",
      "\n",
      "trained 90416 images, use 600.4458250999451 seconds, loss -0.031388220695182434\n",
      "\n",
      "trained 91216 images, use 604.9682188034058 seconds, loss -0.03137977747019393\n",
      "\n",
      "trained 92016 images, use 610.3656985759735 seconds, loss -0.03136540589527098\n",
      "\n",
      "trained 92816 images, use 615.1119892597198 seconds, loss -0.03132869612739212\n",
      "\n",
      "trained 93616 images, use 620.2724299430847 seconds, loss -0.031318480807088954\n",
      "\n",
      "trained 94416 images, use 625.5870015621185 seconds, loss -0.031263504802566386\n",
      "\n",
      "trained 95216 images, use 630.8330535888672 seconds, loss -0.03129463490146546\n",
      "\n",
      "trained 96016 images, use 635.0828478336334 seconds, loss -0.03130423765702394\n",
      "\n",
      "trained 96816 images, use 640.2609012126923 seconds, loss -0.03133540345541171\n",
      "\n",
      "trained 97616 images, use 645.5307421684265 seconds, loss -0.03137874433798459\n",
      "\n",
      "trained 98416 images, use 650.1830770969391 seconds, loss -0.03137785097942691\n",
      "\n",
      "trained 99216 images, use 654.9031386375427 seconds, loss -0.03133671896922688\n",
      "\n",
      "*************Epoch 24 Avrg Training loss -0.03132459750752474 Elapsed 659.5180666446686\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.7859514380575225\n",
      "************* Validation: total 99996 precision 0.9694216340082175 avgTime 0.0060432889999506535\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 25 started at 1619488235.0036972\n",
      "trained 16 images, use 1.329399585723877 seconds, loss -0.020120915651204996\n",
      "\n",
      "trained 816 images, use 6.389668703079224 seconds, loss -0.02256348336256381\n",
      "\n",
      "trained 1616 images, use 10.443688869476318 seconds, loss -0.027013673849428058\n",
      "\n",
      "trained 2416 images, use 14.942880392074585 seconds, loss -0.029879314167555106\n",
      "\n",
      "trained 3216 images, use 19.279833555221558 seconds, loss -0.03218040812261941\n",
      "\n",
      "trained 4016 images, use 23.75511074066162 seconds, loss -0.03219972618343479\n",
      "\n",
      "trained 4816 images, use 28.415035486221313 seconds, loss -0.03231419453198813\n",
      "\n",
      "trained 5616 images, use 32.95101833343506 seconds, loss -0.031988963209286035\n",
      "\n",
      "trained 6416 images, use 37.51871919631958 seconds, loss -0.03170284850094036\n",
      "\n",
      "trained 7216 images, use 42.13018822669983 seconds, loss -0.030277750864295246\n",
      "\n",
      "trained 8016 images, use 47.01676082611084 seconds, loss -0.0305187132389488\n",
      "\n",
      "trained 8816 images, use 51.58478045463562 seconds, loss -0.03056132015578163\n",
      "\n",
      "trained 9616 images, use 56.38759136199951 seconds, loss -0.03097681284589233\n",
      "\n",
      "trained 10416 images, use 60.83190941810608 seconds, loss -0.031393730053637964\n",
      "\n",
      "trained 11216 images, use 65.51735186576843 seconds, loss -0.031269763624321906\n",
      "\n",
      "trained 12016 images, use 69.74855470657349 seconds, loss -0.031378078501881436\n",
      "\n",
      "trained 12816 images, use 75.41593384742737 seconds, loss -0.031163155421555608\n",
      "\n",
      "trained 13616 images, use 80.97925758361816 seconds, loss -0.031094436542669784\n",
      "\n",
      "trained 14416 images, use 85.284494638443 seconds, loss -0.03118526971320484\n",
      "\n",
      "trained 15216 images, use 90.0359137058258 seconds, loss -0.03064982327211898\n",
      "\n",
      "trained 16016 images, use 95.49255299568176 seconds, loss -0.03050302313684591\n",
      "\n",
      "trained 16816 images, use 100.18599200248718 seconds, loss -0.030866777372212283\n",
      "\n",
      "trained 17616 images, use 105.26073718070984 seconds, loss -0.031083142595634078\n",
      "\n",
      "trained 18416 images, use 110.05517029762268 seconds, loss -0.031307079655986475\n",
      "\n",
      "trained 19216 images, use 114.6820342540741 seconds, loss -0.031271131845618395\n",
      "\n",
      "trained 20016 images, use 119.64695143699646 seconds, loss -0.03137227753827516\n",
      "\n",
      "trained 20816 images, use 124.46903133392334 seconds, loss -0.031437740150026976\n",
      "\n",
      "trained 21616 images, use 129.7786147594452 seconds, loss -0.031545827161317756\n",
      "\n",
      "trained 22416 images, use 134.59950709342957 seconds, loss -0.031538805162203316\n",
      "\n",
      "trained 23216 images, use 138.87438917160034 seconds, loss -0.03158089781091495\n",
      "\n",
      "trained 24016 images, use 143.7857310771942 seconds, loss -0.03178830513166085\n",
      "\n",
      "trained 24816 images, use 148.83410096168518 seconds, loss -0.03146541732656567\n",
      "\n",
      "trained 25616 images, use 153.7853512763977 seconds, loss -0.03143451488858432\n",
      "\n",
      "trained 26416 images, use 158.52204704284668 seconds, loss -0.03173138377090498\n",
      "\n",
      "trained 27216 images, use 163.37164545059204 seconds, loss -0.0319444955252595\n",
      "\n",
      "trained 28016 images, use 167.93616843223572 seconds, loss -0.031874390870708084\n",
      "\n",
      "trained 28816 images, use 172.78838849067688 seconds, loss -0.03161553406523207\n",
      "\n",
      "trained 29616 images, use 177.2216157913208 seconds, loss -0.03175673868490612\n",
      "\n",
      "trained 30416 images, use 182.18603658676147 seconds, loss -0.03161404944761803\n",
      "\n",
      "trained 31216 images, use 186.42952418327332 seconds, loss -0.031636713132289475\n",
      "\n",
      "trained 32016 images, use 191.34294533729553 seconds, loss -0.031737191821738786\n",
      "\n",
      "trained 32816 images, use 196.2751910686493 seconds, loss -0.03162248352529136\n",
      "\n",
      "trained 33616 images, use 201.20801544189453 seconds, loss -0.031715407130206555\n",
      "\n",
      "trained 34416 images, use 205.47147822380066 seconds, loss -0.03161572029563511\n",
      "\n",
      "trained 35216 images, use 210.25938820838928 seconds, loss -0.031480239198393704\n",
      "\n",
      "trained 36016 images, use 215.52093124389648 seconds, loss -0.03163260551037829\n",
      "\n",
      "trained 36816 images, use 220.06465458869934 seconds, loss -0.03160876522037809\n",
      "\n",
      "trained 37616 images, use 224.28442573547363 seconds, loss -0.031605938048880886\n",
      "\n",
      "trained 38416 images, use 228.81675100326538 seconds, loss -0.031748959493116825\n",
      "\n",
      "trained 39216 images, use 233.31048488616943 seconds, loss -0.03168462590415459\n",
      "\n",
      "trained 40016 images, use 237.65235567092896 seconds, loss -0.03160837804767803\n",
      "\n",
      "trained 40816 images, use 242.46874451637268 seconds, loss -0.03170618380573459\n",
      "\n",
      "trained 41616 images, use 247.3678913116455 seconds, loss -0.03157076711369746\n",
      "\n",
      "trained 42416 images, use 251.37991523742676 seconds, loss -0.03153741842978617\n",
      "\n",
      "trained 43216 images, use 255.7443995475769 seconds, loss -0.031478702699854734\n",
      "\n",
      "trained 44016 images, use 260.0264616012573 seconds, loss -0.03152150938151811\n",
      "\n",
      "trained 44816 images, use 264.2564594745636 seconds, loss -0.031572170551539915\n",
      "\n",
      "trained 45616 images, use 268.98506236076355 seconds, loss -0.031500792263172296\n",
      "\n",
      "trained 46416 images, use 273.51231145858765 seconds, loss -0.03145261790380982\n",
      "\n",
      "trained 47216 images, use 277.6869502067566 seconds, loss -0.0315670968636951\n",
      "\n",
      "trained 48016 images, use 282.17638754844666 seconds, loss -0.03156565768161813\n",
      "\n",
      "trained 48816 images, use 286.53125834465027 seconds, loss -0.031519880396543125\n",
      "\n",
      "trained 49616 images, use 290.84268712997437 seconds, loss -0.03149653093343458\n",
      "\n",
      "trained 50416 images, use 296.09013175964355 seconds, loss -0.03161024114798569\n",
      "\n",
      "trained 51216 images, use 300.3927116394043 seconds, loss -0.03154982470062925\n",
      "\n",
      "trained 52016 images, use 305.2444911003113 seconds, loss -0.031454303436208114\n",
      "\n",
      "trained 52816 images, use 309.71003818511963 seconds, loss -0.031344941391927554\n",
      "\n",
      "trained 53616 images, use 314.2765381336212 seconds, loss -0.031392428359434586\n",
      "\n",
      "trained 54416 images, use 318.5555987358093 seconds, loss -0.03134682689735573\n",
      "\n",
      "trained 55216 images, use 323.19487380981445 seconds, loss -0.03133161339588511\n",
      "\n",
      "trained 56016 images, use 327.74130964279175 seconds, loss -0.031247204639159722\n",
      "\n",
      "trained 56816 images, use 332.1855208873749 seconds, loss -0.031208020349240615\n",
      "\n",
      "trained 57616 images, use 336.8282721042633 seconds, loss -0.03125632981515607\n",
      "\n",
      "trained 58416 images, use 341.9545202255249 seconds, loss -0.03121223740910218\n",
      "\n",
      "trained 59216 images, use 346.0665633678436 seconds, loss -0.031112924370802653\n",
      "\n",
      "trained 60016 images, use 351.0408010482788 seconds, loss -0.031144266713453304\n",
      "\n",
      "trained 60816 images, use 355.2641303539276 seconds, loss -0.03111795564094787\n",
      "\n",
      "trained 61616 images, use 359.9121923446655 seconds, loss -0.031204895175074226\n",
      "\n",
      "trained 62416 images, use 364.23760294914246 seconds, loss -0.03121267825824153\n",
      "\n",
      "trained 63216 images, use 368.6906147003174 seconds, loss -0.031219923291060513\n",
      "\n",
      "trained 64016 images, use 373.55428075790405 seconds, loss -0.03127015563367907\n",
      "\n",
      "trained 64816 images, use 377.87439131736755 seconds, loss -0.03127523417654325\n",
      "\n",
      "trained 65616 images, use 382.9917857646942 seconds, loss -0.031293074416092276\n",
      "\n",
      "trained 66416 images, use 387.1634497642517 seconds, loss -0.03125918238310768\n",
      "\n",
      "trained 67216 images, use 391.4656138420105 seconds, loss -0.031181176321810864\n",
      "\n",
      "trained 68016 images, use 396.3113224506378 seconds, loss -0.03111953930491086\n",
      "\n",
      "trained 68816 images, use 400.65485310554504 seconds, loss -0.031137357727090198\n",
      "\n",
      "trained 69616 images, use 405.4845380783081 seconds, loss -0.03107360798803845\n",
      "\n",
      "trained 70416 images, use 409.6034688949585 seconds, loss -0.031127169337443084\n",
      "\n",
      "trained 71216 images, use 414.40231919288635 seconds, loss -0.031175149810177584\n",
      "\n",
      "trained 72016 images, use 418.5656774044037 seconds, loss -0.03109408221378844\n",
      "\n",
      "trained 72816 images, use 423.16727018356323 seconds, loss -0.03116077205018297\n",
      "\n",
      "trained 73616 images, use 427.6365294456482 seconds, loss -0.03111038084663311\n",
      "\n",
      "trained 74416 images, use 431.9019477367401 seconds, loss -0.03113180184730492\n",
      "\n",
      "trained 75216 images, use 436.74797344207764 seconds, loss -0.03120468868039456\n",
      "\n",
      "trained 76016 images, use 440.81756925582886 seconds, loss -0.03116559001950834\n",
      "\n",
      "trained 76816 images, use 445.51301884651184 seconds, loss -0.03127967294263207\n",
      "\n",
      "trained 77616 images, use 449.76847529411316 seconds, loss -0.03126314266935456\n",
      "\n",
      "trained 78416 images, use 454.15640473365784 seconds, loss -0.03132253309189376\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 458.7530255317688 seconds, loss -0.031257870932300855\n",
      "\n",
      "trained 80016 images, use 463.22569251060486 seconds, loss -0.031204900418557172\n",
      "\n",
      "trained 80816 images, use 467.83356833457947 seconds, loss -0.031244197584891897\n",
      "\n",
      "trained 81616 images, use 472.6362133026123 seconds, loss -0.0312930918046506\n",
      "\n",
      "trained 82416 images, use 476.83703351020813 seconds, loss -0.03127889021627755\n",
      "\n",
      "trained 83216 images, use 481.01330375671387 seconds, loss -0.0312921364454727\n",
      "\n",
      "trained 84016 images, use 485.8789048194885 seconds, loss -0.03134553580476332\n",
      "\n",
      "trained 84816 images, use 490.67529368400574 seconds, loss -0.031304455535979665\n",
      "\n",
      "trained 85616 images, use 494.79760694503784 seconds, loss -0.03129524408554771\n",
      "\n",
      "trained 86416 images, use 501.2990667819977 seconds, loss -0.03130708992515202\n",
      "\n",
      "trained 87216 images, use 505.54791164398193 seconds, loss -0.03130277778842695\n",
      "\n",
      "trained 88016 images, use 510.2985427379608 seconds, loss -0.03126756944659335\n",
      "\n",
      "trained 88816 images, use 515.1505692005157 seconds, loss -0.03131181287232414\n",
      "\n",
      "trained 89616 images, use 519.9430470466614 seconds, loss -0.031347768654113185\n",
      "\n",
      "trained 90416 images, use 524.828515291214 seconds, loss -0.03132333497317101\n",
      "\n",
      "trained 91216 images, use 529.158495426178 seconds, loss -0.03131393009471036\n",
      "\n",
      "trained 92016 images, use 533.8382904529572 seconds, loss -0.031371708110275405\n",
      "\n",
      "trained 92816 images, use 538.5148477554321 seconds, loss -0.031393730114093785\n",
      "\n",
      "trained 93616 images, use 543.1660614013672 seconds, loss -0.031439238109121456\n",
      "\n",
      "trained 94416 images, use 547.92449259758 seconds, loss -0.0314519289950917\n",
      "\n",
      "trained 95216 images, use 553.0831513404846 seconds, loss -0.031444558512064194\n",
      "\n",
      "trained 96016 images, use 557.537059545517 seconds, loss -0.03143291037736321\n",
      "\n",
      "trained 96816 images, use 562.5447013378143 seconds, loss -0.031383875933216954\n",
      "\n",
      "trained 97616 images, use 566.8820350170135 seconds, loss -0.03138986795271094\n",
      "\n",
      "trained 98416 images, use 571.2518417835236 seconds, loss -0.0313509815496178\n",
      "\n",
      "trained 99216 images, use 576.1249177455902 seconds, loss -0.03136484984606071\n",
      "\n",
      "*************Epoch 25 Avrg Training loss -0.0313114793304912 Elapsed 580.3724999427795\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.7856314252570105\n",
      "************* Validation: total 99996 precision 0.9693759178938587 avgTime 0.005949607717642294\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 26 started at 1619489411.080494\n",
      "trained 16 images, use 1.8697781562805176 seconds, loss -0.05210151709616184\n",
      "\n",
      "trained 816 images, use 5.988823175430298 seconds, loss -0.027685571778245224\n",
      "\n",
      "trained 1616 images, use 10.57232403755188 seconds, loss -0.026391279525506774\n",
      "\n",
      "trained 2416 images, use 14.917451620101929 seconds, loss -0.02683974649904473\n",
      "\n",
      "trained 3216 images, use 19.55244016647339 seconds, loss -0.030229008164759187\n",
      "\n",
      "trained 4016 images, use 24.279269695281982 seconds, loss -0.030430031405824284\n",
      "\n",
      "trained 4816 images, use 28.746193647384644 seconds, loss -0.030602509340438934\n",
      "\n",
      "trained 5616 images, use 33.581528186798096 seconds, loss -0.030189908179223644\n",
      "\n",
      "trained 6416 images, use 38.479573488235474 seconds, loss -0.03020703942554881\n",
      "\n",
      "trained 7216 images, use 43.18873929977417 seconds, loss -0.03099350374594477\n",
      "\n",
      "trained 8016 images, use 47.621787548065186 seconds, loss -0.03131856016830306\n",
      "\n",
      "trained 8816 images, use 52.656394243240356 seconds, loss -0.031264763163400044\n",
      "\n",
      "trained 9616 images, use 57.05545973777771 seconds, loss -0.030891032763196657\n",
      "\n",
      "trained 10416 images, use 61.49873638153076 seconds, loss -0.030834148356620482\n",
      "\n",
      "trained 11216 images, use 65.84410738945007 seconds, loss -0.030935389947575668\n",
      "\n",
      "trained 12016 images, use 70.76617002487183 seconds, loss -0.031089282929966815\n",
      "\n",
      "trained 12816 images, use 75.0772864818573 seconds, loss -0.03113108371002496\n",
      "\n",
      "trained 13616 images, use 80.00998425483704 seconds, loss -0.031442622746823856\n",
      "\n",
      "trained 14416 images, use 84.4386055469513 seconds, loss -0.03200974659226382\n",
      "\n",
      "trained 15216 images, use 88.9973931312561 seconds, loss -0.031500710552970025\n",
      "\n",
      "trained 16016 images, use 93.47823715209961 seconds, loss -0.031357010273015753\n",
      "\n",
      "trained 16816 images, use 98.24805927276611 seconds, loss -0.03156829791113867\n",
      "\n",
      "trained 17616 images, use 102.49383997917175 seconds, loss -0.03164312454308705\n",
      "\n",
      "trained 18416 images, use 107.55168914794922 seconds, loss -0.03179372757760884\n",
      "\n",
      "trained 19216 images, use 111.91878318786621 seconds, loss -0.03135614046053371\n",
      "\n",
      "trained 20016 images, use 116.15396094322205 seconds, loss -0.03134090018177056\n",
      "\n",
      "trained 20816 images, use 121.41611051559448 seconds, loss -0.031307309284286544\n",
      "\n",
      "trained 21616 images, use 125.6205666065216 seconds, loss -0.031109211032871887\n",
      "\n",
      "trained 22416 images, use 129.86428928375244 seconds, loss -0.03134016764269506\n",
      "\n",
      "trained 23216 images, use 134.9115653038025 seconds, loss -0.03114050041000915\n",
      "\n",
      "trained 24016 images, use 139.1725833415985 seconds, loss -0.031178987251125948\n",
      "\n",
      "trained 24816 images, use 143.60807704925537 seconds, loss -0.031111513897762896\n",
      "\n",
      "trained 25616 images, use 148.05558729171753 seconds, loss -0.03112498775903808\n",
      "\n",
      "trained 26416 images, use 152.37076926231384 seconds, loss -0.03114832044988971\n",
      "\n",
      "trained 27216 images, use 156.76742362976074 seconds, loss -0.031368275618394864\n",
      "\n",
      "trained 28016 images, use 161.00384306907654 seconds, loss -0.031303085117140986\n",
      "\n",
      "trained 28816 images, use 166.4069218635559 seconds, loss -0.031369411740320326\n",
      "\n",
      "trained 29616 images, use 170.56686067581177 seconds, loss -0.031340857879251234\n",
      "\n",
      "trained 30416 images, use 175.32279920578003 seconds, loss -0.031356684493718485\n",
      "\n",
      "trained 31216 images, use 179.70625066757202 seconds, loss -0.03109890700578351\n",
      "\n",
      "trained 32016 images, use 184.1118450164795 seconds, loss -0.030953834402323327\n",
      "\n",
      "trained 32816 images, use 188.25330018997192 seconds, loss -0.031027409797652655\n",
      "\n",
      "trained 33616 images, use 192.8514280319214 seconds, loss -0.031211907765814464\n",
      "\n",
      "trained 34416 images, use 197.51792287826538 seconds, loss -0.03132229790781985\n",
      "\n",
      "trained 35216 images, use 201.61051511764526 seconds, loss -0.0311688255255042\n",
      "\n",
      "trained 36016 images, use 206.25941491127014 seconds, loss -0.031050221286519207\n",
      "\n",
      "trained 36816 images, use 210.68684220314026 seconds, loss -0.03117506261810989\n",
      "\n",
      "trained 37616 images, use 215.12770009040833 seconds, loss -0.031084573934048402\n",
      "\n",
      "trained 38416 images, use 220.0552840232849 seconds, loss -0.031150837477550396\n",
      "\n",
      "trained 39216 images, use 224.55285906791687 seconds, loss -0.031002488857563577\n",
      "\n",
      "trained 40016 images, use 229.10173773765564 seconds, loss -0.030947731122255424\n",
      "\n",
      "trained 40816 images, use 233.51134514808655 seconds, loss -0.030941184168764024\n",
      "\n",
      "trained 41616 images, use 237.8677613735199 seconds, loss -0.03089045091337731\n",
      "\n",
      "trained 42416 images, use 242.66556549072266 seconds, loss -0.030947397746389393\n",
      "\n",
      "trained 43216 images, use 247.25101947784424 seconds, loss -0.03096045836602202\n",
      "\n",
      "trained 44016 images, use 252.03384733200073 seconds, loss -0.030981054494256356\n",
      "\n",
      "trained 44816 images, use 256.4316499233246 seconds, loss -0.030967171025364636\n",
      "\n",
      "trained 45616 images, use 260.814377784729 seconds, loss -0.030987287356625436\n",
      "\n",
      "trained 46416 images, use 265.53474831581116 seconds, loss -0.031013149808151445\n",
      "\n",
      "trained 47216 images, use 270.13877058029175 seconds, loss -0.030913139363304136\n",
      "\n",
      "trained 48016 images, use 274.45954942703247 seconds, loss -0.030988326354870272\n",
      "\n",
      "trained 48816 images, use 278.71817684173584 seconds, loss -0.030979571617606467\n",
      "\n",
      "trained 49616 images, use 283.1438798904419 seconds, loss -0.030936140382925324\n",
      "\n",
      "trained 50416 images, use 287.81824135780334 seconds, loss -0.0308509247481538\n",
      "\n",
      "trained 51216 images, use 292.12303590774536 seconds, loss -0.030973014766287825\n",
      "\n",
      "trained 52016 images, use 296.57575583457947 seconds, loss -0.03092868136330366\n",
      "\n",
      "trained 52816 images, use 301.4871175289154 seconds, loss -0.03087782756789797\n",
      "\n",
      "trained 53616 images, use 305.57413053512573 seconds, loss -0.030926805960302936\n",
      "\n",
      "trained 54416 images, use 310.04235672950745 seconds, loss -0.03089343584564177\n",
      "\n",
      "trained 55216 images, use 314.78806471824646 seconds, loss -0.030861513704541398\n",
      "\n",
      "trained 56016 images, use 319.084636926651 seconds, loss -0.031032829105969516\n",
      "\n",
      "trained 56816 images, use 324.09744453430176 seconds, loss -0.030948589327930074\n",
      "\n",
      "trained 57616 images, use 328.45744824409485 seconds, loss -0.030953573735793938\n",
      "\n",
      "trained 58416 images, use 333.52487564086914 seconds, loss -0.03104930097284687\n",
      "\n",
      "trained 59216 images, use 337.92087984085083 seconds, loss -0.031122227471317616\n",
      "\n",
      "trained 60016 images, use 342.2494604587555 seconds, loss -0.03098034028693367\n",
      "\n",
      "trained 60816 images, use 346.84625935554504 seconds, loss -0.03091136268064282\n",
      "\n",
      "trained 61616 images, use 351.28636026382446 seconds, loss -0.031020885451685857\n",
      "\n",
      "trained 62416 images, use 355.96538066864014 seconds, loss -0.030990151840667418\n",
      "\n",
      "trained 63216 images, use 360.5723056793213 seconds, loss -0.03094739366808683\n",
      "\n",
      "trained 64016 images, use 365.0756905078888 seconds, loss -0.03090565979655087\n",
      "\n",
      "trained 64816 images, use 370.01754784584045 seconds, loss -0.03100425737896623\n",
      "\n",
      "trained 65616 images, use 374.49250078201294 seconds, loss -0.031039295313295214\n",
      "\n",
      "trained 66416 images, use 380.01995062828064 seconds, loss -0.030920410121390844\n",
      "\n",
      "trained 67216 images, use 384.55333399772644 seconds, loss -0.030917858846257397\n",
      "\n",
      "trained 68016 images, use 389.6082651615143 seconds, loss -0.03092458471196136\n",
      "\n",
      "trained 68816 images, use 394.12575578689575 seconds, loss -0.030868421233698474\n",
      "\n",
      "trained 69616 images, use 398.62601232528687 seconds, loss -0.03081248642971189\n",
      "\n",
      "trained 70416 images, use 403.5118486881256 seconds, loss -0.03084859005465212\n",
      "\n",
      "trained 71216 images, use 408.2882034778595 seconds, loss -0.03079951337451333\n",
      "\n",
      "trained 72016 images, use 412.55492186546326 seconds, loss -0.030790961316678137\n",
      "\n",
      "trained 72816 images, use 416.9301497936249 seconds, loss -0.030780472655337947\n",
      "\n",
      "trained 73616 images, use 421.4384469985962 seconds, loss -0.030865469249989504\n",
      "\n",
      "trained 74416 images, use 426.2786681652069 seconds, loss -0.030960911214966632\n",
      "\n",
      "trained 75216 images, use 430.88248229026794 seconds, loss -0.031014789081449452\n",
      "\n",
      "trained 76016 images, use 435.07587909698486 seconds, loss -0.031053827785875135\n",
      "\n",
      "trained 76816 images, use 439.74233293533325 seconds, loss -0.031156430988404225\n",
      "\n",
      "trained 77616 images, use 444.17919421195984 seconds, loss -0.031109864671301193\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 78416 images, use 448.572297334671 seconds, loss -0.031141329943005783\n",
      "\n",
      "trained 79216 images, use 453.2992172241211 seconds, loss -0.03115785302714114\n",
      "\n",
      "trained 80016 images, use 457.97351813316345 seconds, loss -0.03117487754911772\n",
      "\n",
      "trained 80816 images, use 462.59683442115784 seconds, loss -0.031133856317762613\n",
      "\n",
      "trained 81616 images, use 467.1509692668915 seconds, loss -0.03115905768345364\n",
      "\n",
      "trained 82416 images, use 471.36296248435974 seconds, loss -0.031124583379260204\n",
      "\n",
      "trained 83216 images, use 476.09803652763367 seconds, loss -0.031193028310024\n",
      "\n",
      "trained 84016 images, use 480.75362157821655 seconds, loss -0.031110343858448262\n",
      "\n",
      "trained 84816 images, use 485.3653576374054 seconds, loss -0.03116328015588556\n",
      "\n",
      "trained 85616 images, use 489.60689902305603 seconds, loss -0.031125789888436756\n",
      "\n",
      "trained 86416 images, use 493.83914971351624 seconds, loss -0.03110227791477996\n",
      "\n",
      "trained 87216 images, use 498.12807059288025 seconds, loss -0.031093564819586444\n",
      "\n",
      "trained 88016 images, use 503.31417632102966 seconds, loss -0.03109146784057931\n",
      "\n",
      "trained 88816 images, use 507.49649596214294 seconds, loss -0.03107256672353275\n",
      "\n",
      "trained 89616 images, use 511.86003255844116 seconds, loss -0.031116115152857598\n",
      "\n",
      "trained 90416 images, use 518.2850797176361 seconds, loss -0.03111978557962764\n",
      "\n",
      "trained 91216 images, use 522.4493100643158 seconds, loss -0.03114798683090671\n",
      "\n",
      "trained 92016 images, use 526.7116332054138 seconds, loss -0.031107226844703056\n",
      "\n",
      "trained 92816 images, use 531.1095900535583 seconds, loss -0.031118598521189426\n",
      "\n",
      "trained 93616 images, use 535.609870672226 seconds, loss -0.031137844111501313\n",
      "\n",
      "trained 94416 images, use 540.4838054180145 seconds, loss -0.031129987069395543\n",
      "\n",
      "trained 95216 images, use 545.206166267395 seconds, loss -0.03117207659824775\n",
      "\n",
      "trained 96016 images, use 549.5949685573578 seconds, loss -0.031149023897346105\n",
      "\n",
      "trained 96816 images, use 554.2147040367126 seconds, loss -0.031226990453639015\n",
      "\n",
      "trained 97616 images, use 558.895977973938 seconds, loss -0.031220694531408535\n",
      "\n",
      "trained 98416 images, use 563.3832521438599 seconds, loss -0.03128991236916173\n",
      "\n",
      "trained 99216 images, use 567.6268599033356 seconds, loss -0.03126959524345542\n",
      "\n",
      "*************Epoch 26 Avrg Training loss -0.031308171427816014 Elapsed 572.0079965591431\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.78583143325733\n",
      "************* Validation: total 99996 precision 0.969404490465333 avgTime 0.005999082734362689\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 27 started at 1619490583.7472212\n",
      "trained 16 images, use 3.1727023124694824 seconds, loss -0.0396367609500885\n",
      "\n",
      "trained 816 images, use 6.826038837432861 seconds, loss -0.028383305546657748\n",
      "\n",
      "trained 1616 images, use 11.36976933479309 seconds, loss -0.03281429932277723\n",
      "\n",
      "trained 2416 images, use 15.898374557495117 seconds, loss -0.02995723329844156\n",
      "\n",
      "trained 3216 images, use 20.81499671936035 seconds, loss -0.029866568455708425\n",
      "\n",
      "trained 4016 images, use 25.301154613494873 seconds, loss -0.03000953873777415\n",
      "\n",
      "trained 4816 images, use 30.15051579475403 seconds, loss -0.03015691180287783\n",
      "\n",
      "trained 5616 images, use 34.93209147453308 seconds, loss -0.029833929935744085\n",
      "\n",
      "trained 6416 images, use 39.38892912864685 seconds, loss -0.02995622247133507\n",
      "\n",
      "trained 7216 images, use 43.71999788284302 seconds, loss -0.030804155976898877\n",
      "\n",
      "trained 8016 images, use 48.18209981918335 seconds, loss -0.0310113723878694\n",
      "\n",
      "trained 8816 images, use 53.31649303436279 seconds, loss -0.03154960027273671\n",
      "\n",
      "trained 9616 images, use 58.302332401275635 seconds, loss -0.0309918402782852\n",
      "\n",
      "trained 10416 images, use 62.974422216415405 seconds, loss -0.030823956708507\n",
      "\n",
      "trained 11216 images, use 67.30316996574402 seconds, loss -0.03134271640784907\n",
      "\n",
      "trained 12016 images, use 71.74114274978638 seconds, loss -0.031017312911265006\n",
      "\n",
      "trained 12816 images, use 76.10928964614868 seconds, loss -0.030717091101153816\n",
      "\n",
      "trained 13616 images, use 80.43480396270752 seconds, loss -0.03091675669528134\n",
      "\n",
      "trained 14416 images, use 85.06345653533936 seconds, loss -0.03051009388587508\n",
      "\n",
      "trained 15216 images, use 90.10110831260681 seconds, loss -0.030942351759206458\n",
      "\n",
      "trained 16016 images, use 94.6583526134491 seconds, loss -0.03098358630515673\n",
      "\n",
      "trained 16816 images, use 98.98653554916382 seconds, loss -0.03133012243722792\n",
      "\n",
      "trained 17616 images, use 104.09411287307739 seconds, loss -0.031126856535413187\n",
      "\n",
      "trained 18416 images, use 108.84806728363037 seconds, loss -0.030951416676083216\n",
      "\n",
      "trained 19216 images, use 113.17891454696655 seconds, loss -0.0307361442553338\n",
      "\n",
      "trained 20016 images, use 117.55931735038757 seconds, loss -0.030687317214906883\n",
      "\n",
      "trained 20816 images, use 122.26165914535522 seconds, loss -0.030704652507292724\n",
      "\n",
      "trained 21616 images, use 127.28893971443176 seconds, loss -0.030798332219945778\n",
      "\n",
      "trained 22416 images, use 131.5015516281128 seconds, loss -0.031124564264772902\n",
      "\n",
      "trained 23216 images, use 136.1052565574646 seconds, loss -0.031089205252241858\n",
      "\n",
      "trained 24016 images, use 141.0596158504486 seconds, loss -0.03125917687903535\n",
      "\n",
      "trained 24816 images, use 145.5700421333313 seconds, loss -0.031313086778035557\n",
      "\n",
      "trained 25616 images, use 149.7165822982788 seconds, loss -0.03148762655112517\n",
      "\n",
      "trained 26416 images, use 154.8054575920105 seconds, loss -0.031567973690543795\n",
      "\n",
      "trained 27216 images, use 159.32109808921814 seconds, loss -0.031669641975137636\n",
      "\n",
      "trained 28016 images, use 164.14698886871338 seconds, loss -0.03176849960297623\n",
      "\n",
      "trained 28816 images, use 168.49364233016968 seconds, loss -0.03163009399338812\n",
      "\n",
      "trained 29616 images, use 173.33522582054138 seconds, loss -0.03172943621671561\n",
      "\n",
      "trained 30416 images, use 177.76971864700317 seconds, loss -0.031660421240858355\n",
      "\n",
      "trained 31216 images, use 182.15893959999084 seconds, loss -0.031525702297511005\n",
      "\n",
      "trained 32016 images, use 186.91260719299316 seconds, loss -0.03147949673744417\n",
      "\n",
      "trained 32816 images, use 191.7603793144226 seconds, loss -0.03150807799225267\n",
      "\n",
      "trained 33616 images, use 196.06706261634827 seconds, loss -0.03139191467737501\n",
      "\n",
      "trained 34416 images, use 200.9449167251587 seconds, loss -0.03152580279165512\n",
      "\n",
      "trained 35216 images, use 205.35905241966248 seconds, loss -0.03147898427148452\n",
      "\n",
      "trained 36016 images, use 210.12418818473816 seconds, loss -0.03156532172805955\n",
      "\n",
      "trained 36816 images, use 214.39451122283936 seconds, loss -0.03174511675498087\n",
      "\n",
      "trained 37616 images, use 218.76025557518005 seconds, loss -0.03155419905002454\n",
      "\n",
      "trained 38416 images, use 223.9339759349823 seconds, loss -0.03150569647078314\n",
      "\n",
      "trained 39216 images, use 228.3075032234192 seconds, loss -0.03141295881054569\n",
      "\n",
      "trained 40016 images, use 233.7041301727295 seconds, loss -0.031462580608169886\n",
      "\n",
      "trained 40816 images, use 237.95166158676147 seconds, loss -0.03148478056498731\n",
      "\n",
      "trained 41616 images, use 242.48824071884155 seconds, loss -0.03159117291122105\n",
      "\n",
      "trained 42416 images, use 247.0343997478485 seconds, loss -0.03149739882329565\n",
      "\n",
      "trained 43216 images, use 251.12886834144592 seconds, loss -0.03132085067248371\n",
      "\n",
      "trained 44016 images, use 255.78889727592468 seconds, loss -0.031484315631967685\n",
      "\n",
      "trained 44816 images, use 260.5352303981781 seconds, loss -0.031558660437026174\n",
      "\n",
      "trained 45616 images, use 265.01775646209717 seconds, loss -0.03153927026499998\n",
      "\n",
      "trained 46416 images, use 269.4149160385132 seconds, loss -0.03154812749440913\n",
      "\n",
      "trained 47216 images, use 273.76275396347046 seconds, loss -0.031634243501826545\n",
      "\n",
      "trained 48016 images, use 278.42929673194885 seconds, loss -0.03155690736635698\n",
      "\n",
      "trained 48816 images, use 282.73304653167725 seconds, loss -0.031533753959765036\n",
      "\n",
      "trained 49616 images, use 287.4952292442322 seconds, loss -0.03150460561827272\n",
      "\n",
      "trained 50416 images, use 292.7057225704193 seconds, loss -0.0313512261421358\n",
      "\n",
      "trained 51216 images, use 297.04951071739197 seconds, loss -0.03134899228000674\n",
      "\n",
      "trained 52016 images, use 301.2575101852417 seconds, loss -0.03127684512201831\n",
      "\n",
      "trained 52816 images, use 305.93844056129456 seconds, loss -0.031297477965412594\n",
      "\n",
      "trained 53616 images, use 310.2997078895569 seconds, loss -0.031362927356610795\n",
      "\n",
      "trained 54416 images, use 314.87212085723877 seconds, loss -0.0314884675445374\n",
      "\n",
      "trained 55216 images, use 319.23358392715454 seconds, loss -0.03159600152256319\n",
      "\n",
      "trained 56016 images, use 323.5679793357849 seconds, loss -0.0316822905267003\n",
      "\n",
      "trained 56816 images, use 327.87485790252686 seconds, loss -0.031617090635883596\n",
      "\n",
      "trained 57616 images, use 332.72781682014465 seconds, loss -0.0315833595627528\n",
      "\n",
      "trained 58416 images, use 337.58140778541565 seconds, loss -0.031495755270755016\n",
      "\n",
      "trained 59216 images, use 341.9437253475189 seconds, loss -0.031514503729188736\n",
      "\n",
      "trained 60016 images, use 346.51937556266785 seconds, loss -0.03152541751493879\n",
      "\n",
      "trained 60816 images, use 351.3417022228241 seconds, loss -0.031454696386256885\n",
      "\n",
      "trained 61616 images, use 356.0864291191101 seconds, loss -0.03142107625230224\n",
      "\n",
      "trained 62416 images, use 360.9349961280823 seconds, loss -0.031356951852348956\n",
      "\n",
      "trained 63216 images, use 365.4560670852661 seconds, loss -0.031345500611090066\n",
      "\n",
      "trained 64016 images, use 370.28669810295105 seconds, loss -0.031344124850974826\n",
      "\n",
      "trained 64816 images, use 374.79906940460205 seconds, loss -0.031378930848215775\n",
      "\n",
      "trained 65616 images, use 378.8988859653473 seconds, loss -0.03145578415171557\n",
      "\n",
      "trained 66416 images, use 383.7893295288086 seconds, loss -0.03140634378826218\n",
      "\n",
      "trained 67216 images, use 388.0993847846985 seconds, loss -0.03137521721421702\n",
      "\n",
      "trained 68016 images, use 393.3370509147644 seconds, loss -0.03139454534848193\n",
      "\n",
      "trained 68816 images, use 397.3094928264618 seconds, loss -0.03130539731516045\n",
      "\n",
      "trained 69616 images, use 401.69609451293945 seconds, loss -0.031218596112761315\n",
      "\n",
      "trained 70416 images, use 406.2229554653168 seconds, loss -0.031155163150465\n",
      "\n",
      "trained 71216 images, use 410.69244480133057 seconds, loss -0.031144250919504977\n",
      "\n",
      "trained 72016 images, use 415.08059096336365 seconds, loss -0.031166200364386647\n",
      "\n",
      "trained 72816 images, use 419.3595681190491 seconds, loss -0.031108218463349577\n",
      "\n",
      "trained 73616 images, use 423.7326228618622 seconds, loss -0.031183784457140613\n",
      "\n",
      "trained 74416 images, use 428.80675172805786 seconds, loss -0.03116657785364508\n",
      "\n",
      "trained 75216 images, use 433.50627875328064 seconds, loss -0.031101531894404396\n",
      "\n",
      "trained 76016 images, use 438.1634602546692 seconds, loss -0.03128592867676248\n",
      "\n",
      "trained 76816 images, use 442.97660636901855 seconds, loss -0.031248610425040964\n",
      "\n",
      "trained 77616 images, use 446.9350094795227 seconds, loss -0.031205600139663406\n",
      "\n",
      "trained 78416 images, use 451.42636275291443 seconds, loss -0.03130259525818861\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 79216 images, use 455.5623345375061 seconds, loss -0.03128577397171009\n",
      "\n",
      "trained 80016 images, use 459.8112528324127 seconds, loss -0.03125103133437578\n",
      "\n",
      "trained 80816 images, use 464.58806443214417 seconds, loss -0.031235645488681484\n",
      "\n",
      "trained 81616 images, use 469.24447679519653 seconds, loss -0.031203611139479115\n",
      "\n",
      "trained 82416 images, use 473.6983325481415 seconds, loss -0.03120391082591479\n",
      "\n",
      "trained 83216 images, use 478.2393915653229 seconds, loss -0.031338144618900436\n",
      "\n",
      "trained 84016 images, use 482.76177763938904 seconds, loss -0.03137372935029194\n",
      "\n",
      "trained 84816 images, use 487.1358075141907 seconds, loss -0.031402044599451256\n",
      "\n",
      "trained 85616 images, use 491.72887206077576 seconds, loss -0.031420723718412855\n",
      "\n",
      "trained 86416 images, use 496.59616684913635 seconds, loss -0.0313755733098567\n",
      "\n",
      "trained 87216 images, use 501.22045135498047 seconds, loss -0.031337084056071864\n",
      "\n",
      "trained 88016 images, use 505.66284346580505 seconds, loss -0.03138851318466921\n",
      "\n",
      "trained 88816 images, use 510.3337378501892 seconds, loss -0.031324568680320894\n",
      "\n",
      "trained 89616 images, use 515.0317678451538 seconds, loss -0.03133591122340234\n",
      "\n",
      "trained 90416 images, use 520.1264164447784 seconds, loss -0.0314440417275185\n",
      "\n",
      "trained 91216 images, use 524.2468690872192 seconds, loss -0.03142214059248324\n",
      "\n",
      "trained 92016 images, use 528.6407699584961 seconds, loss -0.031412734341902636\n",
      "\n",
      "trained 92816 images, use 533.6053097248077 seconds, loss -0.03133290504806485\n",
      "\n",
      "trained 93616 images, use 538.0260426998138 seconds, loss -0.0313733544025542\n",
      "\n",
      "trained 94416 images, use 542.1309418678284 seconds, loss -0.03128975609399369\n",
      "\n",
      "trained 95216 images, use 546.8621201515198 seconds, loss -0.03126376041351165\n",
      "\n",
      "trained 96016 images, use 550.7100093364716 seconds, loss -0.03120109679744427\n",
      "\n",
      "trained 96816 images, use 555.7623267173767 seconds, loss -0.03130848007920608\n",
      "\n",
      "trained 97616 images, use 560.0148658752441 seconds, loss -0.0313214436485179\n",
      "\n",
      "trained 98416 images, use 564.1469020843506 seconds, loss -0.031291325371984584\n",
      "\n",
      "trained 99216 images, use 568.5638904571533 seconds, loss -0.03128324588439591\n",
      "\n",
      "*************Epoch 27 Avrg Training loss -0.031295004736220544 Elapsed 572.6059319972992\n",
      "\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n",
      "[\u001b[37;1mINFO\u001b[0m] -- image: 99996, inst:6.7860514420576825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 800064 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Validation: total 99996 precision 0.9694359202939546 avgTime 0.005644330156198038\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Epoch 28 started at 1619491721.7726653\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d6c0d403c15a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"Start training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m model = train_model(model=model, trainloader=trainloader, criterion=criterion, optimizer=optimizer,\n\u001b[0;32m---> 32\u001b[0;31m             batchSize=BATCHSIZE, testDirs=VALTXT,storeName='./weight/crnn.pth', num_epochs=EPOCH, logFile=\"./train_log.txt\")\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-53067b8aa9c8>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, trainloader, criterion, optimizer, batchSize, testDirs, storeName, num_epochs, logFile)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"Epoch {} started at {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXI\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tradt/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tradt/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tradt/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tradt/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tradt/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tradt/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tradt/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tradt/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "# training \n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "TRAINDIR = ['CCPD2019/train']\n",
    "TESTDIR = ['CCPD2019/test']\n",
    "VALDIR = ['CCPD2019/val']\n",
    "\n",
    "LR = 0.001\n",
    "PLATESIZE = (100,32)#(256,96)\n",
    "BATCHSIZE = 16\n",
    "EPOCH = 300\n",
    "\n",
    "\n",
    "# model = DigitRecog(PLATESIZE).cuda()\n",
    "model = CRNN(imgH=32, nc=1, nclass=NUM_CHAR, nh=256, n_rnn=2, leakyRelu=False).cuda()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.CTCLoss(blank=NUM_CHAR-1,reduction='mean').cuda()\n",
    "optimizer = optim.Adam(model.parameters(),lr=LR)\n",
    "# lrScheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "# optimizer_conv = optim.RMSprop(model_conv.parameters(), lr=0.01, momentum=0.9)\n",
    "# optimizer_conv = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "print(debug.INFO+\"Start loading dataset...\")\n",
    "# dst = labelFpsDataLoader(TRAINDIR, PLATESIZE)\n",
    "dst = labelFpsPathDataLoader(TRAINTXT,\"CCPD2019\", PLATESIZE)\n",
    "print(debug.INFO+\"Got dataset size %d\"%len(dst))\n",
    "trainloader = Data.DataLoader(dst, batch_size=BATCHSIZE, shuffle=True, num_workers=8)\n",
    "print(debug.INFO+\"Done loading dataset\")\n",
    "\n",
    "print(debug.INFO+\"Start training\")\n",
    "model = train_model(model=model, trainloader=trainloader, criterion=criterion, optimizer=optimizer,\n",
    "            batchSize=BATCHSIZE, testDirs=VALTXT,storeName='./weight/crnn.pth', num_epochs=EPOCH, logFile=\"./train_log.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## num_parameters = (3*3)*(3*64+64*64+64*128+128*128+128*256+256*256+256*256+256*256+256*512+512*512+512*512+512*512+512*512+512*512+512*512+512*512)+(64+64+128+128+256+256+256+256+512+512+512+512+512+512+512+512)+7*(24*512*4096+4096*4096+4096+4096)+(7*4096+1)*(NUM_PROV+NUM_ALPB+5*NUM_ADS)\n",
    "num_variables = BATCHSIZE*(256*96*(3+64+64)+128*48*(128+128)+64*24*(256+256+256+256)+32*12*(512+512+512+512)+16*6*(512+512+512+512)+7*(4096+4096)+(NUM_PROV+NUM_ALPB+5*NUM_ADS))\n",
    "model_size = num_parameters + 2*num_variables\n",
    "print(\"number of parameters: %d floating-point\"%num_parameters)\n",
    "print(\"%d Bytes\"%(num_parameters*4))\n",
    "print(\"%0.2f MB\"%(num_parameters*4/1024/1024))\n",
    "print(\"%0.2f GB\"%(num_parameters*4/1024/1024/1024))\n",
    "print(\"number of variables: %d floating-point\"%num_variables)\n",
    "print(\"%d Bytes\"%(num_variables*4))\n",
    "print(\"%0.2f MB\"%(num_variables*4/1024/1024))\n",
    "print(\"%0.2f GB\"%(num_variables*4/1024/1024/1024))\n",
    "print(\"number of variables: %d floating-point\"%model_size)\n",
    "print(\"%d Bytes\"%(model_size*4))\n",
    "print(\"%0.2f MB\"%(model_size*4/1024/1024))\n",
    "print(\"%0.2f GB\"%(model_size*4/1024/1024/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._resume_backend at 0x7f9272db88c8> (for pre_run_cell):\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/tradt/lib/python3.6/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tradt/lib/python3.6/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jupyter_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tradt/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tradt/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[400. 483.]\n",
      " [296. 478.]\n",
      " [298. 442.]\n",
      " [402. 447.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CRNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f2fac787e313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# model = DigitRecog(PLATESIZE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnclass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CHAR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleakyRelu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;31m# model.load_state_dict(torch.load(\"weight/DigitRecog.pth14\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight/crnn.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CRNN' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x7f9272db81e0> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/tradt/lib/python3.6/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tradt/lib/python3.6/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tradt/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tradt/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    }
   ],
   "source": [
    "# quick test\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "TRAINDIR = ['CCPD2019/train']\n",
    "TESTDIR = ['CCPD2019/test']\n",
    "VALDIR = ['CCPD2019/val']\n",
    "\n",
    "LR = 0.001\n",
    "PLATESIZE = (192,64) #(100,32)#(256,96)\n",
    "BATCHSIZE = 16\n",
    "EPOCH = 300\n",
    "\n",
    "img_name = \"CCPD2019/val/00348898467433-91_88-293&438_400&480-400&483_296&478_\"+\"298&442_402&447-0_0_8_32_22_27_24-115-7.jpg\"\n",
    "img = cv2.imread(img_name,cv2.IMREAD_GRAYSCALE)\n",
    "lbl = img_name.split('/')[-1].rsplit('.', 1)[0].split('-')[-3]\n",
    "iname = img_name.rsplit('/', 1)[-1].rsplit('.', 1)[0].split('-')\n",
    "# corners = np.array(eval(\"[(\" + iname[3].replace(\"&\", \",\").replace(\"_\", \"),(\") + \")]\"), np.float32) # [0] BR, [1] BL, [2] TL, [3] TR \n",
    "# print(corners) \n",
    "corners = np.array([[int(eel) for eel in el.split('&')] for el in iname[3].split('_')], np.float32)\n",
    "print(corners)\n",
    "\n",
    "\n",
    "resizedImage = persp_crop(img, corners, PLATESIZE[1],PLATESIZE[0])\n",
    "[leftUp, rightDown] = [[int(eel) for eel in el.split('&')] for el in iname[2].split('_')]\n",
    "# croppedImage = img[leftUp[1]:rightDown[1],leftUp[0]:rightDown[0]]\n",
    "# resizedImage = cv2.resize(croppedImage, PLATESIZE)\n",
    "# resizedImage = np.transpose(resizedImage, (2,0,1))\n",
    "resizedImage = resizedImage.astype('float32')\n",
    "resizedImage /= 255.0\n",
    "XI = torch.tensor([[resizedImage]])\n",
    "x = Variable(XI.cuda())\n",
    "YI = torch.IntTensor([label_trans(el.split('_')[:7]) for el in [lbl]]).cuda()\n",
    "\n",
    "plt.imshow(np.transpose([resizedImage,resizedImage,resizedImage],(1,2,0)))\n",
    "plt.show()\n",
    "# resizedImage = cv2.resize(resizedImage, (48,16))\n",
    "# resizedImage = cv2.resize(resizedImage, PLATESIZE)\n",
    "# plt.imshow(np.transpose([resizedImage,resizedImage,resizedImage],(1,2,0)))\n",
    "# plt.show()\n",
    "# input()\n",
    "#     print(img)\n",
    "print(\"loading model...\")\n",
    "# model = DigitRecog(PLATESIZE)\n",
    "model = CRNN(imgH=32, nc=1, nclass=NUM_CHAR, nh=256, n_rnn=2, leakyRelu=False)\n",
    "# model.load_state_dict(torch.load(\"weight/DigitRecog.pth14\"))\n",
    "model.load_state_dict(torch.load(\"weight/crnn.pth\"))\n",
    "\n",
    "model.cuda()\n",
    "# model.eval()\n",
    "model.train()\n",
    "\n",
    "criterion = nn.CTCLoss(blank=NUM_CHAR-1,reduction='mean')\n",
    "\n",
    "print(\"evaluating...\")\n",
    "print(debug.INFO+\"input shape {}\".format(x.shape))\n",
    "y_pred = model(x)\n",
    "print(debug.INFO+\"output size:\",y_pred.shape)\n",
    "# input()\n",
    "# print(\"y_pred\",y_pred)\n",
    "\n",
    "n_correct=0\n",
    "_, preds = y_pred.max(2)\n",
    "print(\"preds\",preds.shape)\n",
    "# preds = preds.squeeze(2)\n",
    "# print(\"preds\",preds.shape)\n",
    "# print(\"preds\",preds)\n",
    "preds = preds.transpose(1, 0).contiguous()\n",
    "print(\"preds\",preds.shape)\n",
    "\n",
    "print([chars[x] for x in YI[0].data])\n",
    "print([chars[x] for x in preds[0]])\n",
    "for i in range(YI.shape[0]):\n",
    "    sim_preds, _ = decode(preds[i].data)\n",
    "    print(sim_preds,YI[i].data)\n",
    "    for pred, target in zip(sim_preds, YI[i].data):\n",
    "        if pred == target:\n",
    "            n_correct += 1\n",
    "            \n",
    "print(n_correct)\n",
    "# print(\"preds\",preds)\n",
    "y_pred = F.log_softmax(y_pred,dim=2)\n",
    "preds_size = Variable(torch.IntTensor([y_pred.size(0)] * 1))\n",
    "tars_size = Variable(torch.IntTensor([7] * 1))\n",
    "# print(\"loss input\",y_pred,YI,preds_size,tars_size)\n",
    "loss  = criterion(y_pred,YI,preds_size,tars_size)\n",
    "print(loss)\n",
    "# outputY = [el.data.cpu().numpy().tolist() for el in y_pred]\n",
    "# try: \n",
    "#     print(outputY.shape)\n",
    "# except:\n",
    "#     pass \n",
    "\n",
    "# labelGT = np.array([[int(ee) for ee in el.split('_')[:7]] for el in [lbl]])\n",
    "# labelPred = np.array([np.argmax(branch, axis=1) for branch in outputY])\n",
    "# print(labelPred)\n",
    "# scoreboard = (labelPred.T == labelGT)\n",
    "# corr_eachinst = np.sum(scoreboard, axis=1)\n",
    "# corr_eachchar = np.sum(scoreboard, axis=0)\n",
    "\n",
    "# count, correct, error, precision, avgTime = eval(model=model, test_dirs=VALDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n",
      "evaluating...\n",
      "[\u001b[37;1mINFO\u001b[0m] -- Loading data under CCPD2019/splits/val.txt\n",
      "init\n",
      "[2, 3, 2, 2, 3, 2, 2, 2, 3, 2, 1, 3, 2, 2, 1, 2] 16\n",
      "[2, 2, 3, 3, 3, 2, 3, 3, 2, 2, 2, 3, 3, 2, 2, 2] 16\n",
      "[2, 3, 2, 2, 2, 4, 3, 3, 2, 2, 2, 2, 2, 2, 1, 2] 16\n",
      "[1, 2, 3, 2, 1, 2, 2, 1, 2, 2, 2, 3, 2, 3, 2, 3] 16\n",
      "[3, 2, 3, 2, 3, 2, 2, 3, 2, 2, 2, 1, 2, 4, 2, 3] 16\n",
      "[4, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 2, 2, 2] 16\n",
      "[2, 3, 2, 2, 1, 3, 2, 0, 2, 2, 2, 2, 2, 3, 2, 2] 16\n",
      "[3, 2, 2, 4, 2, 2, 3, 2, 3, 3, 2, 2, 3, 2, 2, 2] 16\n",
      "[2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3] 16\n",
      "[0, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 1, 2, 2, 2, 2] 16\n",
      "[2, 2, 2, 3, 3, 2, 2, 2, 2, 1, 2, 2, 2, 1, 4, 2] 16\n",
      "[2, 2, 2, 1, 2, 1, 2, 3, 4, 2, 2, 2, 2, 1, 2, 2] 16\n",
      "[3, 2, 3, 2, 0, 2, 2, 2, 3, 2, 2, 2, 3, 3, 2, 2] 16\n",
      "[2, 3, 2, 3, 3, 2, 2, 3, 2, 2, 2, 3, 3, 2, 2, 2] 16\n",
      "[2, 1, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] 16\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 3, 2, 2, 3, 4, 2] 16\n",
      "[3, 2, 2, 3, 3, 2, 2, 2, 3, 2, 2, 2, 3, 3, 4, 2] 16\n",
      "[3, 4, 4, 2, 2, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2] 16\n",
      "[3, 2, 1, 3, 2, 2, 4, 2, 2, 2, 2, 2, 2, 3, 4, 2] 16\n",
      "[3, 2, 1, 2, 2, 3, 0, 2, 2, 2, 2, 2, 2, 2, 4, 3] 16\n",
      "[2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 1, 4, 2, 3, 2] 16\n",
      "[1, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3] 16\n",
      "[2, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2] 16\n",
      "[2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 0] 16\n",
      "[3, 2, 2, 3, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2] 16\n",
      "[2, 2, 2, 3, 3, 3, 2, 3, 3, 2, 2, 3, 3, 3, 2, 3] 16\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 2, 2, 3, 3, 2] 16\n",
      "[2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 1, 2] 16\n",
      "[3, 3, 2, 3, 0, 2, 2, 2, 1, 3, 2, 3, 2, 2, 2, 3] 16\n",
      "[4, 2, 2, 2, 3, 2, 4, 3, 2, 2, 3, 2, 2, 2, 2, 2] 16\n",
      "[2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 3, 2, 2, 2, 2, 2] 16\n",
      "[3, 2, 2, 2, 2, 4, 3, 0, 3, 2, 2, 2, 2, 3, 2, 2] 16\n",
      "[3, 3, 2, 2, 3, 3, 3, 1, 2, 2, 4, 2, 2, 2, 2, 2] 16\n",
      "[2, 2, 3, 2, 2, 2, 3, 2, 3, 2, 4, 2, 2, 2, 2, 2] 16\n",
      "[2, 2, 2, 3, 2, 0, 3, 1, 2, 3, 2, 0, 2, 3, 2, 3] 16\n",
      "[2, 2, 2, 4, 2, 2, 0, 2, 2, 2, 2, 2, 3, 3, 2, 2] 16\n",
      "[1, 1, 2, 2, 3, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 3] 16\n",
      "[2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 3, 2, 2, 2, 1, 2] 16\n",
      "[2, 3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2] 16\n",
      "[2, 1, 3, 2, 2, 2, 2, 2, 2, 0, 3, 1, 1, 3, 2, 2] 16\n",
      "[2, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2] 16\n",
      "[2, 0, 3, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 4, 2] 16\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2] 16\n",
      "[2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 3, 2, 1, 3, 2] 16\n",
      "[2, 3, 3, 2, 3, 4, 1, 2, 3, 3, 2, 2, 2, 2, 0, 1] 16\n",
      "[3, 1, 2, 2, 2, 2, 2, 2, 3, 1, 2, 2, 0, 2, 2, 2] 16\n",
      "[2, 3, 3, 1, 1, 2, 2, 2, 3, 2, 2, 2, 3, 1, 1, 3] 16\n",
      "[2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 3, 0] 16\n",
      "[3, 2, 3, 3, 2, 2, 1, 3, 2, 2, 2, 2, 2, 0, 2, 3] 16\n",
      "[2, 2, 3, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2] 16\n",
      "[2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 0, 2, 3, 2] 16\n",
      "[2, 3, 3, 3, 2, 1, 2, 1, 2, 2, 2, 2, 3, 2, 3, 2] 16\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 2, 2, 2, 2] 16\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] 16\n",
      "[2, 3, 2, 3, 0, 3, 0, 4, 2, 2, 3, 2, 2, 3, 1, 2] 16\n",
      "[2, 2, 2, 3, 2, 3, 2, 2, 2, 0, 2, 3, 2, 2, 3, 3] 16\n",
      "[2, 2, 2, 2, 2, 3, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2] 16\n",
      "[2, 0, 4, 4, 3, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 3] 16\n",
      "[2, 1, 2, 2, 3, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2, 1] 16\n",
      "[3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 3, 2, 4, 3, 3, 2] 16\n",
      "[3, 2, 2, 2, 0, 3, 2, 2, 2, 2, 2, 3, 2, 1, 2, 2] 16\n",
      "[2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2] 16\n",
      "[3, 4, 2, 2, 2, 2, 2, 2] 8\n"
     ]
    }
   ],
   "source": [
    "# test on val dataset\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# wandb.init(project='DigitRecog',settings=wandb.Settings(start_method=\"fork\"))\n",
    "# PLATESIZE = (256,96)\n",
    "print(\"loading model...\")\n",
    "model = CRNN(imgH=32, nc=1, nclass=NUM_CHAR, nh=256, n_rnn=2, leakyRelu=False)\n",
    "model.load_state_dict(torch.load(\"weight/crnn.pth\"))\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "print(\"evaluating...\")\n",
    "count, corrs_inst, precision, avgTime = eval(model=model, test_tar=\"CCPD2019/splits/val.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DigitRecog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-3baf30c20735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mPLATESIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDigitRecog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPLATESIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight/DigitRecog.pth14\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DigitRecog' is not defined"
     ]
    }
   ],
   "source": [
    "# test on val dataset\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# wandb.init(project='DigitRecog',settings=wandb.Settings(start_method=\"fork\"))\n",
    "# PLATESIZE = (256,96)\n",
    "print(\"loading model...\")\n",
    "model = DigitRecog(PLATESIZE)\n",
    "model.load_state_dict(torch.load(\"weight/DigitRecog.pth14\"))\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "print(\"evaluating...\")\n",
    "count, corrs_inst, corrs_char, avgTime = eval(model=model, test_tar=\"CCPD2019/splits/val.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on val dataset\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# wandb.init(project='DigitRecog',settings=wandb.Settings(start_method=\"fork\"))\n",
    "# PLATESIZE = (100,32)\n",
    "print(\"loading model...\")\n",
    "model = CRNN(imgH=32, nc=1, nclass=NUM_CHAR, nh=256, n_rnn=2, leakyRelu=False)\n",
    "model.load_state_dict(torch.load(\"weight/crnn.pth\"))\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "print(\"evaluating...\")\n",
    "count, corrs_inst, corrs_char, avgTime = eval(model=model, test_tar=\"CCPD2019/splits/val.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dst = labelFpsPathDataLoader(\"CCPD2019/splits/val.txt\",\"CCPD2019\", PLATESIZE)\n",
    "bsz = 8\n",
    "testloader = Data.DataLoader(dst, batch_size=bsz, shuffle=True, num_workers=8)\n",
    "plt.imshow(list(testloader)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4481879275171 [0.98340934 0.98539942 0.03967159 0.07424297 0.68791752 0.73018921\n",
      " 0.94735789]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(corrs_inst), corrs_char/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct# 0 0.0\n",
      "correct# 1 52.0\n",
      "correct# 2 1192.0\n",
      "correct# 3 28647.0\n",
      "correct# 4 156392.0\n",
      "correct# 5 229045.0\n",
      "correct# 6 28500.0\n",
      "correct# 7 973.0\n",
      "[98337. 98536.  3967.  7424. 68789. 73016. 94732.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(\"correct# %d\"%i,(corrs_inst[corrs_inst==i]).sum())\n",
    "print(corrs_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = np.random.randn(32)\n",
    "im2 = np.random.randn(30)\n",
    "len(list(zip(im,im2)))\n",
    "# print(im.shape)\n",
    "# im = np.expand_dims(im,2)\n",
    "# print(im.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tradt",
   "language": "python",
   "name": "tradt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
